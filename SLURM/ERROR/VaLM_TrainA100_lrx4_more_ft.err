[2024-04-12 15:12:25,219] torch.distributed.run: [WARNING] 
[2024-04-12 15:12:25,219] torch.distributed.run: [WARNING] *****************************************
[2024-04-12 15:12:25,219] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-12 15:12:25,219] torch.distributed.run: [WARNING] *****************************************
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
wandb: Currently logged in as: paula-ontalvilla (paulaixa). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /ikerlariak/pontalvilla001/VaLM/wandb/run-20240412_151259-5qg12yu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run checkpoint_valmA100_40600upd_lrx4_more_5000upd1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/paulaixa/VaLM-baseline
wandb: üöÄ View run at https://wandb.ai/paulaixa/VaLM-baseline/runs/5qg12yu9
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 6466 ON localhost CANCELLED AT 2024-04-12T15:18:33 ***
slurmstepd: error: *** STEP 6466.0 ON localhost CANCELLED AT 2024-04-12T15:18:33 ***
[2024-04-12 15:18:33,382] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-04-12 15:18:33,383] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 946088 closing signal SIGTERM
[2024-04-12 15:18:33,383] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 946089 closing signal SIGTERM
