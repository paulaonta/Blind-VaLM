Hasi da
2024-02-22 09:31:20 | INFO | fairseq.distributed.utils | setting CUDA device=2 on rank 2
2024-02-22 09:31:20 | INFO | fairseq.distributed.utils | setting CUDA device=3 on rank 3
2024-02-22 09:31:20 | INFO | fairseq.distributed.utils | setting CUDA device=1 on rank 1
2024-02-22 09:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-02-22 09:31:20 | INFO | fairseq.distributed.utils | initialized host durunda as rank 0
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | initialized host durunda as rank 1
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | initialized host durunda as rank 3
2024-02-22 09:31:21 | INFO | fairseq.distributed.utils | initialized host durunda as rank 2
NCCL version 2.18.1+cuda12.1
2024-02-22 09:31:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'VaLM-baseline', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 65536, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 65536, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40600, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './CHECKPOINTS/checkpoint_valmA100_40600upd', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 12, 'decoder_attention_heads': 12, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False, 'use_knn_datastore': True, 'load_knn_datastore': False, 'dstore_fp16': False, 'use_gpu_to_search': False, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 8, 'probe': 32, 'dstore_filename': 'data/datastore', 'use_joint_attention': True, 'joint_layer_index': 2}, 'task': {'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-02-22 09:31:31 | INFO | fairseq.tasks.language_modeling | dictionary: 49412 types
2024-02-22 09:31:35 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(49412, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-9): 10 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerwithJointAttention(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_k_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_v_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=49412, bias=False)
  )
)
2024-02-22 09:31:35 | INFO | fairseq_cli.train | task: LanguageModelingTask
2024-02-22 09:31:35 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2024-02-22 09:31:35 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2024-02-22 09:31:35 | INFO | fairseq_cli.train | num. shared model params: 124,187,136 (num. trained: 124,187,136)
2024-02-22 09:31:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-02-22 09:31:35 | INFO | fairseq.data.data_utils | loaded 5,000 examples from: ./data/data-bin/0/valid
2024-02-22 09:31:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-22 09:31:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-02-22 09:31:44 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-02-22 09:31:44 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-02-22 09:31:44 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-02-22 09:31:44 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-02-22 09:31:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-02-22 09:31:44 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2024-02-22 09:31:44 | INFO | fairseq_cli.train | max tokens per device = 65536 and max sentences per device = None
2024-02-22 09:31:44 | INFO | fairseq.trainer | Preparing to load checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_last.pt
2024-02-22 09:31:44 | INFO | fairseq.trainer | No existing checkpoint found ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_last.pt
2024-02-22 09:31:44 | INFO | fairseq.trainer | loading train data for epoch 1
2024-02-22 09:31:45 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-02-22 09:31:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-02-22 09:31:48 | INFO | fairseq.trainer | begin training epoch 1
2024-02-22 09:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-22 09:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2024-02-22 09:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2024-02-22 09:32:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-02-22 09:32:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-02-22 09:33:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-22 09:52:27 | INFO | train_inner | epoch 001:    105 / 6796 loss=12.437, ppl=5545.05, wps=22545.3, ups=0.09, wpb=262144, bsz=512, num_updates=100, lr=0.000125098, gnorm=10.364, clip=75, loss_scale=4, train_wall=1239, gb_free=10.7, wall=1244
2024-02-22 10:12:16 | INFO | train_inner | epoch 001:    205 / 6796 loss=8.995, ppl=510.39, wps=22054.8, ups=0.08, wpb=262144, bsz=512, num_updates=200, lr=0.000250095, gnorm=1.767, clip=32, loss_scale=4, train_wall=1188, gb_free=10.7, wall=2432
2024-02-22 10:32:12 | INFO | train_inner | epoch 001:    305 / 6796 loss=8.235, ppl=301.22, wps=21909.3, ups=0.08, wpb=262144, bsz=512, num_updates=300, lr=0.000375093, gnorm=2.138, clip=59, loss_scale=4, train_wall=1196, gb_free=10.7, wall=3629
2024-02-22 10:52:07 | INFO | train_inner | epoch 001:    405 / 6796 loss=7.76, ppl=216.78, wps=21938.9, ups=0.08, wpb=262144, bsz=512, num_updates=400, lr=0.00050009, gnorm=1.904, clip=35, loss_scale=4, train_wall=1195, gb_free=10.7, wall=4824
2024-02-22 11:11:56 | INFO | train_inner | epoch 001:    505 / 6796 loss=7.333, ppl=161.24, wps=22047.4, ups=0.08, wpb=262144, bsz=512, num_updates=500, lr=0.000625087, gnorm=1.54, clip=15, loss_scale=4, train_wall=1189, gb_free=10.7, wall=6013
2024-02-22 11:31:46 | INFO | train_inner | epoch 001:    605 / 6796 loss=6.981, ppl=126.29, wps=22038.9, ups=0.08, wpb=262144, bsz=512, num_updates=600, lr=0.000750085, gnorm=1.389, clip=3, loss_scale=4, train_wall=1189, gb_free=10.7, wall=7202
2024-02-22 11:51:39 | INFO | train_inner | epoch 001:    705 / 6796 loss=6.702, ppl=104.13, wps=21911.8, ups=0.08, wpb=261530, bsz=510.8, num_updates=700, lr=0.000875082, gnorm=1.213, clip=2, loss_scale=4, train_wall=1193, gb_free=10.7, wall=8396
2024-02-22 12:11:08 | INFO | train_inner | epoch 001:    805 / 6796 loss=6.483, ppl=89.47, wps=22436.4, ups=0.09, wpb=262144, bsz=512, num_updates=800, lr=0.00100008, gnorm=1.11, clip=5, loss_scale=4, train_wall=1168, gb_free=10.7, wall=9564
2024-02-22 12:30:57 | INFO | train_inner | epoch 001:    905 / 6796 loss=6.298, ppl=78.67, wps=22041.6, ups=0.08, wpb=262144, bsz=512, num_updates=900, lr=0.00112508, gnorm=1.052, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=10753
2024-02-22 12:51:27 | INFO | train_inner | epoch 001:   1005 / 6796 loss=6.135, ppl=70.27, wps=21314.1, ups=0.08, wpb=262144, bsz=512, num_updates=1000, lr=0.00125008, gnorm=0.964, clip=0, loss_scale=4, train_wall=1230, gb_free=10.7, wall=11983
2024-02-22 13:12:06 | INFO | train_inner | epoch 001:   1105 / 6796 loss=6.014, ppl=64.62, wps=21161.9, ups=0.08, wpb=262144, bsz=512, num_updates=1100, lr=0.00137507, gnorm=0.889, clip=0, loss_scale=4, train_wall=1239, gb_free=10.7, wall=13222
2024-02-22 13:32:00 | INFO | train_inner | epoch 001:   1205 / 6796 loss=5.927, ppl=60.86, wps=21938.9, ups=0.08, wpb=262144, bsz=512, num_updates=1200, lr=0.00150007, gnorm=0.929, clip=1, loss_scale=4, train_wall=1195, gb_free=10.7, wall=14417
2024-02-22 13:51:47 | INFO | train_inner | epoch 001:   1305 / 6796 loss=5.872, ppl=58.56, wps=22097.5, ups=0.08, wpb=262144, bsz=512, num_updates=1300, lr=0.00162507, gnorm=0.816, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=15603
2024-02-22 14:11:34 | INFO | train_inner | epoch 001:   1405 / 6796 loss=5.803, ppl=55.82, wps=22086, ups=0.08, wpb=262144, bsz=512, num_updates=1400, lr=0.00175007, gnorm=0.805, clip=0, loss_scale=4, train_wall=1187, gb_free=10.7, wall=16790
2024-02-22 14:31:49 | INFO | train_inner | epoch 001:   1505 / 6796 loss=5.743, ppl=53.55, wps=21573.3, ups=0.08, wpb=262144, bsz=512, num_updates=1500, lr=0.00187506, gnorm=0.745, clip=0, loss_scale=4, train_wall=1215, gb_free=10.7, wall=18005
2024-02-22 14:51:55 | INFO | train_inner | epoch 001:   1605 / 6796 loss=5.705, ppl=52.15, wps=21730.2, ups=0.08, wpb=262144, bsz=512, num_updates=1600, lr=0.00200006, gnorm=0.744, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=19212
2024-02-22 15:12:09 | INFO | train_inner | epoch 001:   1705 / 6796 loss=5.664, ppl=50.72, wps=21594.2, ups=0.08, wpb=262144, bsz=512, num_updates=1700, lr=0.00212506, gnorm=0.718, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=20426
2024-02-22 15:32:01 | INFO | train_inner | epoch 001:   1805 / 6796 loss=5.634, ppl=49.66, wps=21987.5, ups=0.08, wpb=262144, bsz=512, num_updates=1800, lr=0.00225005, gnorm=0.71, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=21618
2024-02-22 15:52:01 | INFO | train_inner | epoch 001:   1905 / 6796 loss=5.6, ppl=48.49, wps=21844.2, ups=0.08, wpb=262144, bsz=512, num_updates=1900, lr=0.00237505, gnorm=0.686, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=22818
2024-02-22 16:11:59 | INFO | train_inner | epoch 001:   2005 / 6796 loss=5.581, ppl=47.85, wps=21880.7, ups=0.08, wpb=262144, bsz=512, num_updates=2000, lr=0.00250005, gnorm=0.674, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=24016
2024-02-22 16:32:12 | INFO | train_inner | epoch 001:   2105 / 6796 loss=5.55, ppl=46.86, wps=21618, ups=0.08, wpb=262144, bsz=512, num_updates=2100, lr=0.00262505, gnorm=0.643, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=25229
2024-02-22 16:52:40 | INFO | train_inner | epoch 001:   2205 / 6796 loss=5.532, ppl=46.28, wps=21341.2, ups=0.08, wpb=262144, bsz=512, num_updates=2200, lr=0.00275005, gnorm=0.624, clip=0, loss_scale=4, train_wall=1228, gb_free=10.7, wall=26457
2024-02-22 17:12:39 | INFO | train_inner | epoch 001:   2305 / 6796 loss=5.512, ppl=45.64, wps=21879.3, ups=0.08, wpb=262144, bsz=512, num_updates=2300, lr=0.00287504, gnorm=0.583, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=27655
2024-02-22 17:32:33 | INFO | train_inner | epoch 001:   2405 / 6796 loss=5.491, ppl=44.97, wps=21946.9, ups=0.08, wpb=262144, bsz=512, num_updates=2400, lr=0.00300004, gnorm=0.572, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=28849
2024-02-22 17:52:26 | INFO | train_inner | epoch 001:   2505 / 6796 loss=5.474, ppl=44.45, wps=21966.4, ups=0.08, wpb=262144, bsz=512, num_updates=2500, lr=0.00312504, gnorm=0.553, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=30043
2024-02-22 18:12:25 | INFO | train_inner | epoch 001:   2605 / 6796 loss=5.459, ppl=43.99, wps=21874.2, ups=0.08, wpb=262144, bsz=512, num_updates=2600, lr=0.00325004, gnorm=0.523, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=31241
2024-02-22 18:32:19 | INFO | train_inner | epoch 001:   2705 / 6796 loss=5.444, ppl=43.52, wps=21950.5, ups=0.08, wpb=262144, bsz=512, num_updates=2700, lr=0.00337503, gnorm=0.509, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=32436
2024-02-22 18:52:20 | INFO | train_inner | epoch 001:   2805 / 6796 loss=5.434, ppl=43.24, wps=21824.4, ups=0.08, wpb=262144, bsz=512, num_updates=2800, lr=0.00350003, gnorm=0.488, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=33637
2024-02-22 19:12:18 | INFO | train_inner | epoch 001:   2905 / 6796 loss=5.419, ppl=42.8, wps=21882.3, ups=0.08, wpb=262144, bsz=512, num_updates=2900, lr=0.00362503, gnorm=0.462, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=34835
2024-02-22 19:32:06 | INFO | train_inner | epoch 001:   3005 / 6796 loss=5.402, ppl=42.3, wps=22068.9, ups=0.08, wpb=262144, bsz=512, num_updates=3000, lr=0.00375003, gnorm=0.452, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=36023
2024-02-22 19:52:16 | INFO | train_inner | epoch 001:   3105 / 6796 loss=5.393, ppl=42.02, wps=21659.6, ups=0.08, wpb=262144, bsz=512, num_updates=3100, lr=0.00387502, gnorm=0.442, clip=0, loss_scale=4, train_wall=1210, gb_free=10.7, wall=37233
2024-02-22 20:11:50 | INFO | train_inner | epoch 001:   3205 / 6796 loss=5.382, ppl=41.71, wps=22340, ups=0.09, wpb=262144, bsz=512, num_updates=3200, lr=0.00400002, gnorm=0.426, clip=0, loss_scale=4, train_wall=1173, gb_free=10.7, wall=38406
2024-02-22 20:31:23 | INFO | train_inner | epoch 001:   3305 / 6796 loss=5.367, ppl=41.28, wps=22341.4, ups=0.09, wpb=262144, bsz=512, num_updates=3300, lr=0.00412502, gnorm=0.406, clip=0, loss_scale=4, train_wall=1173, gb_free=10.7, wall=39580
2024-02-22 20:51:22 | INFO | train_inner | epoch 001:   3405 / 6796 loss=5.36, ppl=41.08, wps=21862.7, ups=0.08, wpb=262144, bsz=512, num_updates=3400, lr=0.00425002, gnorm=0.406, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=40779
2024-02-22 21:11:25 | INFO | train_inner | epoch 001:   3505 / 6796 loss=5.357, ppl=40.98, wps=21797.8, ups=0.08, wpb=262144, bsz=512, num_updates=3500, lr=0.00437501, gnorm=0.396, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=41981
2024-02-22 21:31:15 | INFO | train_inner | epoch 001:   3605 / 6796 loss=5.346, ppl=40.68, wps=22028.3, ups=0.08, wpb=262144, bsz=512, num_updates=3600, lr=0.00450001, gnorm=0.407, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=43171
2024-02-22 21:51:22 | INFO | train_inner | epoch 001:   3705 / 6796 loss=5.335, ppl=40.36, wps=21716.1, ups=0.08, wpb=262144, bsz=512, num_updates=3700, lr=0.00462501, gnorm=0.393, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=44378
2024-02-22 22:11:01 | INFO | train_inner | epoch 001:   3805 / 6796 loss=5.327, ppl=40.15, wps=22236, ups=0.08, wpb=262141, bsz=512, num_updates=3800, lr=0.00475001, gnorm=0.401, clip=0, loss_scale=4, train_wall=1179, gb_free=10.7, wall=45557
2024-02-22 22:30:51 | INFO | train_inner | epoch 001:   3905 / 6796 loss=5.321, ppl=39.98, wps=22026.6, ups=0.08, wpb=262144, bsz=512, num_updates=3900, lr=0.004875, gnorm=0.395, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=46747
2024-02-22 22:50:48 | INFO | train_inner | epoch 001:   4005 / 6796 loss=5.31, ppl=39.67, wps=21893.6, ups=0.08, wpb=262144, bsz=512, num_updates=4000, lr=0.005, gnorm=0.41, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=47945
2024-02-22 23:10:52 | INFO | train_inner | epoch 001:   4105 / 6796 loss=5.297, ppl=39.3, wps=21780.9, ups=0.08, wpb=262144, bsz=512, num_updates=4100, lr=0.00493865, gnorm=0.403, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=49148
2024-02-22 23:30:51 | INFO | train_inner | epoch 001:   4205 / 6796 loss=5.287, ppl=39.05, wps=21852.9, ups=0.08, wpb=262144, bsz=512, num_updates=4200, lr=0.0048795, gnorm=0.393, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=50348
2024-02-22 23:38:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-22 23:51:08 | INFO | train_inner | epoch 001:   4306 / 6796 loss=5.276, ppl=38.74, wps=21553.1, ups=0.08, wpb=262144, bsz=512, num_updates=4300, lr=0.00482243, gnorm=0.384, clip=0, loss_scale=4, train_wall=1216, gb_free=10.7, wall=51564
2024-02-23 00:11:03 | INFO | train_inner | epoch 001:   4406 / 6796 loss=5.261, ppl=38.34, wps=21935.3, ups=0.08, wpb=262144, bsz=512, num_updates=4400, lr=0.00476731, gnorm=0.385, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=52759
2024-02-23 00:30:54 | INFO | train_inner | epoch 001:   4506 / 6796 loss=5.247, ppl=37.96, wps=22002.2, ups=0.08, wpb=262144, bsz=512, num_updates=4500, lr=0.00471405, gnorm=0.407, clip=0, loss_scale=4, train_wall=1191, gb_free=10.7, wall=53951
2024-02-23 00:50:46 | INFO | train_inner | epoch 001:   4606 / 6796 loss=5.242, ppl=37.84, wps=22002.6, ups=0.08, wpb=262144, bsz=512, num_updates=4600, lr=0.00466252, gnorm=0.398, clip=0, loss_scale=4, train_wall=1191, gb_free=10.7, wall=55142
2024-02-23 01:10:50 | INFO | train_inner | epoch 001:   4706 / 6796 loss=5.232, ppl=37.59, wps=21763.9, ups=0.08, wpb=262144, bsz=512, num_updates=4700, lr=0.00461266, gnorm=0.388, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=56347
2024-02-23 01:30:49 | INFO | train_inner | epoch 001:   4806 / 6796 loss=5.219, ppl=37.25, wps=21862.6, ups=0.08, wpb=262144, bsz=512, num_updates=4800, lr=0.00456435, gnorm=0.374, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=57546
2024-02-23 01:50:39 | INFO | train_inner | epoch 001:   4906 / 6796 loss=5.213, ppl=37.1, wps=22030.8, ups=0.08, wpb=262144, bsz=512, num_updates=4900, lr=0.00451754, gnorm=0.393, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=58736
2024-02-23 02:10:40 | INFO | train_inner | epoch 001:   5006 / 6796 loss=5.199, ppl=36.72, wps=21822.9, ups=0.08, wpb=262144, bsz=512, num_updates=5000, lr=0.00447214, gnorm=0.4, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=59937
2024-02-23 02:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 5000 updates
2024-02-23 02:10:40 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_1_5000.pt
2024-02-23 02:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_1_5000.pt
2024-02-23 02:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score None) (writing took 58.81579987308942 seconds)
2024-02-23 02:31:37 | INFO | train_inner | epoch 001:   5106 / 6796 loss=5.19, ppl=36.49, wps=20859.1, ups=0.08, wpb=262144, bsz=512, num_updates=5100, lr=0.00442807, gnorm=0.411, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=61194
2024-02-23 02:51:33 | INFO | train_inner | epoch 001:   5206 / 6796 loss=5.184, ppl=36.35, wps=21920.2, ups=0.08, wpb=262144, bsz=512, num_updates=5200, lr=0.00438529, gnorm=0.359, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=62390
2024-02-23 03:11:44 | INFO | train_inner | epoch 001:   5306 / 6796 loss=5.175, ppl=36.12, wps=21638.8, ups=0.08, wpb=262144, bsz=512, num_updates=5300, lr=0.00434372, gnorm=0.411, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=63601
2024-02-23 03:31:40 | INFO | train_inner | epoch 001:   5406 / 6796 loss=5.175, ppl=36.13, wps=21926.8, ups=0.08, wpb=262144, bsz=512, num_updates=5400, lr=0.00430331, gnorm=0.391, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=64797
2024-02-23 03:51:39 | INFO | train_inner | epoch 001:   5506 / 6796 loss=5.161, ppl=35.77, wps=21861.8, ups=0.08, wpb=262144, bsz=512, num_updates=5500, lr=0.00426401, gnorm=0.4, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=65996
2024-02-23 04:11:46 | INFO | train_inner | epoch 001:   5606 / 6796 loss=5.157, ppl=35.68, wps=21723.1, ups=0.08, wpb=262144, bsz=512, num_updates=5600, lr=0.00422577, gnorm=0.427, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=67202
2024-02-23 04:31:56 | INFO | train_inner | epoch 001:   5706 / 6796 loss=5.148, ppl=35.47, wps=21661.9, ups=0.08, wpb=262144, bsz=512, num_updates=5700, lr=0.00418854, gnorm=0.377, clip=0, loss_scale=4, train_wall=1210, gb_free=10.7, wall=68413
2024-02-23 04:51:49 | INFO | train_inner | epoch 001:   5806 / 6796 loss=5.144, ppl=35.35, wps=21926.6, ups=0.08, wpb=261524, bsz=510.8, num_updates=5800, lr=0.00415227, gnorm=0.39, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=69605
2024-02-23 05:11:57 | INFO | train_inner | epoch 001:   5906 / 6796 loss=5.136, ppl=35.18, wps=21700.4, ups=0.08, wpb=262144, bsz=512, num_updates=5900, lr=0.00411693, gnorm=0.374, clip=0, loss_scale=4, train_wall=1208, gb_free=10.7, wall=70813
2024-02-23 05:31:57 | INFO | train_inner | epoch 001:   6006 / 6796 loss=5.132, ppl=35.06, wps=21846.2, ups=0.08, wpb=262144, bsz=512, num_updates=6000, lr=0.00408248, gnorm=0.413, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=72013
2024-02-23 05:51:42 | INFO | train_inner | epoch 001:   6106 / 6796 loss=5.124, ppl=34.88, wps=22125.1, ups=0.08, wpb=262144, bsz=512, num_updates=6100, lr=0.00404888, gnorm=0.429, clip=0, loss_scale=4, train_wall=1185, gb_free=10.7, wall=73198
2024-02-23 06:11:38 | INFO | train_inner | epoch 001:   6206 / 6796 loss=5.119, ppl=34.76, wps=21910.6, ups=0.08, wpb=262144, bsz=512, num_updates=6200, lr=0.0040161, gnorm=0.399, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=74394
2024-02-23 06:31:31 | INFO | train_inner | epoch 001:   6306 / 6796 loss=5.117, ppl=34.69, wps=21970.3, ups=0.08, wpb=262144, bsz=512, num_updates=6300, lr=0.0039841, gnorm=0.405, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=75588
2024-02-23 06:51:30 | INFO | train_inner | epoch 001:   6406 / 6796 loss=5.105, ppl=34.42, wps=21862.1, ups=0.08, wpb=262144, bsz=512, num_updates=6400, lr=0.00395285, gnorm=0.417, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=76787
2024-02-23 07:11:48 | INFO | train_inner | epoch 001:   6506 / 6796 loss=5.101, ppl=34.31, wps=21522.5, ups=0.08, wpb=262144, bsz=512, num_updates=6500, lr=0.00392232, gnorm=0.433, clip=0, loss_scale=4, train_wall=1218, gb_free=10.7, wall=78005
2024-02-23 07:31:52 | INFO | train_inner | epoch 001:   6606 / 6796 loss=5.102, ppl=34.35, wps=21782.8, ups=0.08, wpb=262144, bsz=512, num_updates=6600, lr=0.00389249, gnorm=0.421, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=79208
2024-02-23 07:51:39 | INFO | train_inner | epoch 001:   6706 / 6796 loss=5.096, ppl=34.21, wps=22086.1, ups=0.08, wpb=262144, bsz=512, num_updates=6700, lr=0.00386334, gnorm=0.382, clip=0, loss_scale=4, train_wall=1187, gb_free=10.7, wall=80395
2024-02-23 08:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6790 updates
2024-02-23 08:09:45 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint1.pt
2024-02-23 08:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint1.pt
2024-02-23 08:10:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint1.pt (epoch 1 @ 6790 updates, score None) (writing took 74.30471760395449 seconds)
2024-02-23 08:10:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-02-23 08:10:59 | INFO | train | epoch 001 | loss 5.708 | ppl 52.26 | wps 21844.3 | ups 0.08 | wpb 262116 | bsz 511.9 | num_updates 6790 | lr 0.00383765 | gnorm 0.763 | clip 3.3 | loss_scale 4 | train_wall 81403 | gb_free 10.7 | wall 81556
2024-02-23 08:10:59 | INFO | fairseq.trainer | loading train data for epoch 2
2024-02-23 08:11:00 | INFO | fairseq.data.data_utils | loaded 52,734,000 examples from: ./data/data-bin/1/train
2024-02-23 08:11:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6776
2024-02-23 08:11:01 | INFO | fairseq.trainer | begin training epoch 2
2024-02-23 08:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-23 08:13:01 | INFO | train_inner | epoch 002:     10 / 6776 loss=5.092, ppl=34.11, wps=20395.8, ups=0.08, wpb=261489, bsz=510.7, num_updates=6800, lr=0.00383482, gnorm=0.414, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=81677
2024-02-23 08:33:08 | INFO | train_inner | epoch 002:    110 / 6776 loss=5.086, ppl=33.97, wps=21706.9, ups=0.08, wpb=262144, bsz=512, num_updates=6900, lr=0.00380693, gnorm=0.419, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=82885
2024-02-23 08:53:13 | INFO | train_inner | epoch 002:    210 / 6776 loss=5.083, ppl=33.89, wps=21769.5, ups=0.08, wpb=262144, bsz=512, num_updates=7000, lr=0.00377964, gnorm=0.43, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=84089
2024-02-23 09:13:26 | INFO | train_inner | epoch 002:    310 / 6776 loss=5.077, ppl=33.76, wps=21594.8, ups=0.08, wpb=262144, bsz=512, num_updates=7100, lr=0.00375293, gnorm=0.428, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=85303
2024-02-23 09:33:34 | INFO | train_inner | epoch 002:    410 / 6776 loss=5.074, ppl=33.68, wps=21701.9, ups=0.08, wpb=262144, bsz=512, num_updates=7200, lr=0.00372678, gnorm=0.416, clip=0, loss_scale=4, train_wall=1208, gb_free=10.7, wall=86511
2024-02-23 09:53:51 | INFO | train_inner | epoch 002:    510 / 6776 loss=5.075, ppl=33.72, wps=21549.1, ups=0.08, wpb=262144, bsz=512, num_updates=7300, lr=0.00370117, gnorm=0.44, clip=0, loss_scale=4, train_wall=1216, gb_free=10.7, wall=87727
2024-02-23 10:13:49 | INFO | train_inner | epoch 002:    610 / 6776 loss=5.067, ppl=33.53, wps=21882.4, ups=0.08, wpb=262144, bsz=512, num_updates=7400, lr=0.00367607, gnorm=0.42, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=88925
2024-02-23 10:34:05 | INFO | train_inner | epoch 002:    710 / 6776 loss=5.061, ppl=33.38, wps=21559, ups=0.08, wpb=262144, bsz=512, num_updates=7500, lr=0.00365148, gnorm=0.44, clip=0, loss_scale=4, train_wall=1216, gb_free=10.7, wall=90141
2024-02-23 10:54:11 | INFO | train_inner | epoch 002:    810 / 6776 loss=5.056, ppl=33.27, wps=21727, ups=0.08, wpb=262144, bsz=512, num_updates=7600, lr=0.00362738, gnorm=0.434, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=91348
2024-02-23 11:14:41 | INFO | train_inner | epoch 002:    910 / 6776 loss=5.053, ppl=33.21, wps=21320.8, ups=0.08, wpb=262144, bsz=512, num_updates=7700, lr=0.00360375, gnorm=0.411, clip=0, loss_scale=4, train_wall=1229, gb_free=10.7, wall=92577
2024-02-23 11:34:48 | INFO | train_inner | epoch 002:   1010 / 6776 loss=5.052, ppl=33.18, wps=21723.5, ups=0.08, wpb=262144, bsz=512, num_updates=7800, lr=0.00358057, gnorm=0.462, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=93784
2024-02-23 11:54:42 | INFO | train_inner | epoch 002:   1110 / 6776 loss=5.049, ppl=33.1, wps=21943, ups=0.08, wpb=262144, bsz=512, num_updates=7900, lr=0.00355784, gnorm=0.407, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=94979
2024-02-23 12:15:11 | INFO | train_inner | epoch 002:   1210 / 6776 loss=5.044, ppl=32.99, wps=21337.7, ups=0.08, wpb=262144, bsz=512, num_updates=8000, lr=0.00353553, gnorm=0.464, clip=0, loss_scale=4, train_wall=1228, gb_free=10.7, wall=96207
2024-02-23 12:35:14 | INFO | train_inner | epoch 002:   1310 / 6776 loss=5.04, ppl=32.91, wps=21792.3, ups=0.08, wpb=262144, bsz=512, num_updates=8100, lr=0.00351364, gnorm=0.414, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=97410
2024-02-23 12:55:33 | INFO | train_inner | epoch 002:   1410 / 6776 loss=5.037, ppl=32.84, wps=21492, ups=0.08, wpb=262144, bsz=512, num_updates=8200, lr=0.00349215, gnorm=0.417, clip=0, loss_scale=4, train_wall=1219, gb_free=10.7, wall=98630
2024-02-23 13:16:02 | INFO | train_inner | epoch 002:   1510 / 6776 loss=5.036, ppl=32.82, wps=21336.9, ups=0.08, wpb=262144, bsz=512, num_updates=8300, lr=0.00347105, gnorm=0.455, clip=0, loss_scale=4, train_wall=1228, gb_free=10.7, wall=99859
2024-02-23 13:31:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-23 13:36:14 | INFO | train_inner | epoch 002:   1611 / 6776 loss=5.034, ppl=32.76, wps=21629.5, ups=0.08, wpb=262144, bsz=512, num_updates=8400, lr=0.00345033, gnorm=0.421, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=101071
2024-02-23 13:56:08 | INFO | train_inner | epoch 002:   1711 / 6776 loss=5.033, ppl=32.73, wps=21954.2, ups=0.08, wpb=262144, bsz=512, num_updates=8500, lr=0.00342997, gnorm=0.414, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=102265
2024-02-23 14:16:08 | INFO | train_inner | epoch 002:   1811 / 6776 loss=5.028, ppl=32.63, wps=21853.7, ups=0.08, wpb=262144, bsz=512, num_updates=8600, lr=0.00340997, gnorm=0.439, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=103464
2024-02-23 14:36:28 | INFO | train_inner | epoch 002:   1911 / 6776 loss=5.031, ppl=32.69, wps=21484.5, ups=0.08, wpb=262144, bsz=512, num_updates=8700, lr=0.00339032, gnorm=0.442, clip=0, loss_scale=4, train_wall=1220, gb_free=10.7, wall=104684
2024-02-23 14:56:42 | INFO | train_inner | epoch 002:   2011 / 6776 loss=5.023, ppl=32.52, wps=21592.1, ups=0.08, wpb=262144, bsz=512, num_updates=8800, lr=0.003371, gnorm=0.436, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=105898
2024-02-23 15:16:45 | INFO | train_inner | epoch 002:   2111 / 6776 loss=5.022, ppl=32.49, wps=21789.6, ups=0.08, wpb=262144, bsz=512, num_updates=8900, lr=0.00335201, gnorm=0.43, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=107101
2024-02-23 15:36:42 | INFO | train_inner | epoch 002:   2211 / 6776 loss=5.019, ppl=32.43, wps=21906.4, ups=0.08, wpb=262144, bsz=512, num_updates=9000, lr=0.00333333, gnorm=0.461, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=108298
2024-02-23 15:56:33 | INFO | train_inner | epoch 002:   2311 / 6776 loss=5.014, ppl=32.31, wps=22009.1, ups=0.08, wpb=262144, bsz=512, num_updates=9100, lr=0.00331497, gnorm=0.428, clip=0, loss_scale=4, train_wall=1191, gb_free=10.7, wall=109489
2024-02-23 16:16:32 | INFO | train_inner | epoch 002:   2411 / 6776 loss=5.011, ppl=32.24, wps=21849.9, ups=0.08, wpb=262144, bsz=512, num_updates=9200, lr=0.0032969, gnorm=0.417, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=110689
2024-02-23 16:36:45 | INFO | train_inner | epoch 002:   2511 / 6776 loss=5.01, ppl=32.21, wps=21615, ups=0.08, wpb=262144, bsz=512, num_updates=9300, lr=0.00327913, gnorm=0.441, clip=0, loss_scale=4, train_wall=1213, gb_free=10.7, wall=111902
2024-02-23 16:56:50 | INFO | train_inner | epoch 002:   2611 / 6776 loss=5.009, ppl=32.19, wps=21753.4, ups=0.08, wpb=262144, bsz=512, num_updates=9400, lr=0.00326164, gnorm=0.412, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=113107
2024-02-23 17:16:50 | INFO | train_inner | epoch 002:   2711 / 6776 loss=5.009, ppl=32.2, wps=21855.4, ups=0.08, wpb=262144, bsz=512, num_updates=9500, lr=0.00324443, gnorm=0.449, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=114306
2024-02-23 17:36:54 | INFO | train_inner | epoch 002:   2811 / 6776 loss=5.005, ppl=32.11, wps=21767.7, ups=0.08, wpb=262144, bsz=512, num_updates=9600, lr=0.00322749, gnorm=0.455, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=115510
2024-02-23 17:57:05 | INFO | train_inner | epoch 002:   2911 / 6776 loss=5.003, ppl=32.06, wps=21651.8, ups=0.08, wpb=262144, bsz=512, num_updates=9700, lr=0.00321081, gnorm=0.435, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=116721
2024-02-23 18:17:01 | INFO | train_inner | epoch 002:   3011 / 6776 loss=4.999, ppl=31.99, wps=21908.9, ups=0.08, wpb=262144, bsz=512, num_updates=9800, lr=0.00319438, gnorm=0.447, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=117918
2024-02-23 18:36:41 | INFO | train_inner | epoch 002:   3111 / 6776 loss=5.002, ppl=32.05, wps=22221.9, ups=0.08, wpb=262144, bsz=512, num_updates=9900, lr=0.00317821, gnorm=0.393, clip=0, loss_scale=4, train_wall=1179, gb_free=10.7, wall=119097
2024-02-23 18:56:19 | INFO | train_inner | epoch 002:   3211 / 6776 loss=4.999, ppl=31.98, wps=22256.3, ups=0.08, wpb=262144, bsz=512, num_updates=10000, lr=0.00316228, gnorm=0.435, clip=0, loss_scale=4, train_wall=1178, gb_free=10.7, wall=120275
2024-02-23 18:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 10000 updates
2024-02-23 18:56:19 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_2_10000.pt
2024-02-23 18:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_2_10000.pt
2024-02-23 18:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score None) (writing took 44.687483783927746 seconds)
2024-02-23 19:16:44 | INFO | train_inner | epoch 002:   3311 / 6776 loss=4.993, ppl=31.85, wps=21387.6, ups=0.08, wpb=262144, bsz=512, num_updates=10100, lr=0.00314658, gnorm=0.429, clip=0, loss_scale=4, train_wall=1181, gb_free=10.7, wall=121501
2024-02-23 19:36:21 | INFO | train_inner | epoch 002:   3411 / 6776 loss=4.989, ppl=31.77, wps=22286.3, ups=0.09, wpb=262144, bsz=512, num_updates=10200, lr=0.00313112, gnorm=0.44, clip=0, loss_scale=4, train_wall=1176, gb_free=10.7, wall=122677
2024-02-23 19:55:59 | INFO | train_inner | epoch 002:   3511 / 6776 loss=4.992, ppl=31.82, wps=22256.9, ups=0.08, wpb=262144, bsz=512, num_updates=10300, lr=0.00311588, gnorm=0.428, clip=0, loss_scale=4, train_wall=1178, gb_free=10.7, wall=123855
2024-02-23 20:15:47 | INFO | train_inner | epoch 002:   3611 / 6776 loss=4.99, ppl=31.79, wps=22059.2, ups=0.08, wpb=262144, bsz=512, num_updates=10400, lr=0.00310087, gnorm=0.44, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=125043
2024-02-23 20:35:35 | INFO | train_inner | epoch 002:   3711 / 6776 loss=4.986, ppl=31.7, wps=22055.8, ups=0.08, wpb=262142, bsz=512, num_updates=10500, lr=0.00308607, gnorm=0.443, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=126232
2024-02-23 20:55:21 | INFO | train_inner | epoch 002:   3811 / 6776 loss=4.989, ppl=31.75, wps=22110.9, ups=0.08, wpb=262144, bsz=512, num_updates=10600, lr=0.00307148, gnorm=0.442, clip=0, loss_scale=4, train_wall=1185, gb_free=10.7, wall=127417
2024-02-23 21:15:07 | INFO | train_inner | epoch 002:   3911 / 6776 loss=4.984, ppl=31.64, wps=22097.5, ups=0.08, wpb=262144, bsz=512, num_updates=10700, lr=0.00305709, gnorm=0.452, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=128604
2024-02-23 21:34:47 | INFO | train_inner | epoch 002:   4011 / 6776 loss=4.983, ppl=31.63, wps=22228.1, ups=0.08, wpb=262144, bsz=512, num_updates=10800, lr=0.0030429, gnorm=0.446, clip=0, loss_scale=4, train_wall=1179, gb_free=10.7, wall=129783
2024-02-23 21:54:45 | INFO | train_inner | epoch 002:   4111 / 6776 loss=4.976, ppl=31.48, wps=21883.3, ups=0.08, wpb=262144, bsz=512, num_updates=10900, lr=0.00302891, gnorm=0.432, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=130981
2024-02-23 22:14:46 | INFO | train_inner | epoch 002:   4211 / 6776 loss=4.983, ppl=31.62, wps=21823.8, ups=0.08, wpb=262144, bsz=512, num_updates=11000, lr=0.00301511, gnorm=0.439, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=132182
2024-02-23 22:34:42 | INFO | train_inner | epoch 002:   4311 / 6776 loss=4.974, ppl=31.43, wps=21914.4, ups=0.08, wpb=262144, bsz=512, num_updates=11100, lr=0.0030015, gnorm=0.444, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=133378
2024-02-23 22:54:47 | INFO | train_inner | epoch 002:   4411 / 6776 loss=4.973, ppl=31.42, wps=21750.4, ups=0.08, wpb=262144, bsz=512, num_updates=11200, lr=0.00298807, gnorm=0.409, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=134584
2024-02-23 23:14:48 | INFO | train_inner | epoch 002:   4511 / 6776 loss=4.968, ppl=31.3, wps=21830.2, ups=0.08, wpb=262144, bsz=512, num_updates=11300, lr=0.00297482, gnorm=0.441, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=135785
2024-02-23 23:34:41 | INFO | train_inner | epoch 002:   4611 / 6776 loss=4.967, ppl=31.28, wps=21969, ups=0.08, wpb=262144, bsz=512, num_updates=11400, lr=0.00296174, gnorm=0.421, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=136978
2024-02-23 23:54:31 | INFO | train_inner | epoch 002:   4711 / 6776 loss=4.966, ppl=31.26, wps=22041.3, ups=0.08, wpb=262144, bsz=512, num_updates=11500, lr=0.00294884, gnorm=0.446, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=138167
2024-02-24 00:14:29 | INFO | train_inner | epoch 002:   4811 / 6776 loss=4.97, ppl=31.33, wps=21872, ups=0.08, wpb=262144, bsz=512, num_updates=11600, lr=0.0029361, gnorm=0.419, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=139366
2024-02-24 00:34:14 | INFO | train_inner | epoch 002:   4911 / 6776 loss=4.962, ppl=31.17, wps=22132.6, ups=0.08, wpb=262144, bsz=512, num_updates=11700, lr=0.00292353, gnorm=0.405, clip=0, loss_scale=4, train_wall=1184, gb_free=10.7, wall=140550
2024-02-24 00:53:55 | INFO | train_inner | epoch 002:   5011 / 6776 loss=4.962, ppl=31.17, wps=22188.6, ups=0.08, wpb=262144, bsz=512, num_updates=11800, lr=0.00291111, gnorm=0.441, clip=0, loss_scale=4, train_wall=1181, gb_free=10.7, wall=141732
2024-02-24 01:13:40 | INFO | train_inner | epoch 002:   5111 / 6776 loss=4.964, ppl=31.22, wps=22120.1, ups=0.08, wpb=262144, bsz=512, num_updates=11900, lr=0.00289886, gnorm=0.435, clip=0, loss_scale=4, train_wall=1185, gb_free=10.7, wall=142917
2024-02-24 01:33:45 | INFO | train_inner | epoch 002:   5211 / 6776 loss=4.961, ppl=31.16, wps=21758, ups=0.08, wpb=262144, bsz=512, num_updates=12000, lr=0.00288675, gnorm=0.506, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=144121
2024-02-24 01:53:28 | INFO | train_inner | epoch 002:   5311 / 6776 loss=4.964, ppl=31.2, wps=22164.6, ups=0.08, wpb=262144, bsz=512, num_updates=12100, lr=0.0028748, gnorm=0.454, clip=0, loss_scale=4, train_wall=1183, gb_free=10.7, wall=145304
2024-02-24 02:13:00 | INFO | train_inner | epoch 002:   5411 / 6776 loss=4.96, ppl=31.12, wps=22355.2, ups=0.09, wpb=262144, bsz=512, num_updates=12200, lr=0.00286299, gnorm=0.435, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=146477
2024-02-24 02:32:31 | INFO | train_inner | epoch 002:   5511 / 6776 loss=4.955, ppl=31.03, wps=22394.2, ups=0.09, wpb=262144, bsz=512, num_updates=12300, lr=0.00285133, gnorm=0.421, clip=0, loss_scale=4, train_wall=1170, gb_free=10.7, wall=147647
2024-02-24 02:52:34 | INFO | train_inner | epoch 002:   5611 / 6776 loss=4.954, ppl=30.99, wps=21796.1, ups=0.08, wpb=262144, bsz=512, num_updates=12400, lr=0.00283981, gnorm=0.42, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=148850
2024-02-24 03:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-24 03:12:47 | INFO | train_inner | epoch 002:   5712 / 6776 loss=4.953, ppl=30.98, wps=21598.4, ups=0.08, wpb=262144, bsz=512, num_updates=12500, lr=0.00282843, gnorm=0.458, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=150064
2024-02-24 03:32:40 | INFO | train_inner | epoch 002:   5812 / 6776 loss=4.954, ppl=30.99, wps=21979.5, ups=0.08, wpb=262144, bsz=512, num_updates=12600, lr=0.00281718, gnorm=0.425, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=151256
2024-02-24 03:52:20 | INFO | train_inner | epoch 002:   5912 / 6776 loss=4.954, ppl=30.99, wps=22219.5, ups=0.08, wpb=262144, bsz=512, num_updates=12700, lr=0.00280607, gnorm=0.424, clip=0, loss_scale=4, train_wall=1180, gb_free=10.7, wall=152436
2024-02-24 04:12:17 | INFO | train_inner | epoch 002:   6012 / 6776 loss=4.946, ppl=30.82, wps=21900.2, ups=0.08, wpb=262144, bsz=512, num_updates=12800, lr=0.00279508, gnorm=0.456, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=153633
2024-02-24 04:32:22 | INFO | train_inner | epoch 002:   6112 / 6776 loss=4.947, ppl=30.84, wps=21744.1, ups=0.08, wpb=262144, bsz=512, num_updates=12900, lr=0.00278423, gnorm=0.43, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=154839
2024-02-24 04:52:25 | INFO | train_inner | epoch 002:   6212 / 6776 loss=4.947, ppl=30.85, wps=21793.9, ups=0.08, wpb=262021, bsz=511.8, num_updates=13000, lr=0.0027735, gnorm=0.443, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=156041
2024-02-24 05:12:22 | INFO | train_inner | epoch 002:   6312 / 6776 loss=4.95, ppl=30.9, wps=21847.5, ups=0.08, wpb=261524, bsz=510.8, num_updates=13100, lr=0.00276289, gnorm=0.412, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=157238
2024-02-24 05:32:15 | INFO | train_inner | epoch 002:   6412 / 6776 loss=4.944, ppl=30.78, wps=21976.4, ups=0.08, wpb=262144, bsz=512, num_updates=13200, lr=0.00275241, gnorm=0.478, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=158431
2024-02-24 05:52:10 | INFO | train_inner | epoch 002:   6512 / 6776 loss=4.94, ppl=30.69, wps=21920.5, ups=0.08, wpb=262144, bsz=512, num_updates=13300, lr=0.00274204, gnorm=0.444, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=159627
2024-02-24 06:11:58 | INFO | train_inner | epoch 002:   6612 / 6776 loss=4.942, ppl=30.74, wps=22067, ups=0.08, wpb=262144, bsz=512, num_updates=13400, lr=0.00273179, gnorm=0.437, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=160815
2024-02-24 06:32:09 | INFO | train_inner | epoch 002:   6712 / 6776 loss=4.942, ppl=30.73, wps=21647.6, ups=0.08, wpb=262144, bsz=512, num_updates=13500, lr=0.00272166, gnorm=0.432, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=162026
2024-02-24 06:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13564 updates
2024-02-24 06:45:01 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint2.pt
2024-02-24 06:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint2.pt
2024-02-24 06:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint2.pt (epoch 2 @ 13564 updates, score None) (writing took 87.31398041103967 seconds)
2024-02-24 06:46:28 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-02-24 06:46:28 | INFO | train | epoch 002 | loss 4.998 | ppl 31.97 | wps 21831 | ups 0.08 | wpb 262104 | bsz 511.9 | num_updates 13564 | lr 0.00271523 | gnorm 0.435 | clip 0 | loss_scale 4 | train_wall 81180 | gb_free 10.7 | wall 162885
2024-02-24 06:46:28 | INFO | fairseq.trainer | loading train data for epoch 3
2024-02-24 06:46:29 | INFO | fairseq.data.data_utils | loaded 52,350,000 examples from: ./data/data-bin/2/train
2024-02-24 06:46:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6724
2024-02-24 06:46:30 | INFO | fairseq.trainer | begin training epoch 3
2024-02-24 06:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-24 06:53:42 | INFO | train_inner | epoch 003:     36 / 6724 loss=4.936, ppl=30.61, wps=20122.7, ups=0.08, wpb=260178, bsz=508.2, num_updates=13600, lr=0.00271163, gnorm=0.459, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=163319
2024-02-24 07:13:35 | INFO | train_inner | epoch 003:    136 / 6724 loss=4.941, ppl=30.73, wps=21972.7, ups=0.08, wpb=262144, bsz=512, num_updates=13700, lr=0.00270172, gnorm=0.45, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=164512
2024-02-24 07:33:23 | INFO | train_inner | epoch 003:    236 / 6724 loss=4.941, ppl=30.73, wps=22077.5, ups=0.08, wpb=262144, bsz=512, num_updates=13800, lr=0.00269191, gnorm=0.446, clip=0, loss_scale=4, train_wall=1187, gb_free=10.7, wall=165699
2024-02-24 07:53:12 | INFO | train_inner | epoch 003:    336 / 6724 loss=4.935, ppl=30.59, wps=22040.8, ups=0.08, wpb=262144, bsz=512, num_updates=13900, lr=0.00268221, gnorm=0.467, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=166889
2024-02-24 08:12:57 | INFO | train_inner | epoch 003:    436 / 6724 loss=4.934, ppl=30.57, wps=22117.1, ups=0.08, wpb=262144, bsz=512, num_updates=14000, lr=0.00267261, gnorm=0.431, clip=0, loss_scale=4, train_wall=1185, gb_free=10.7, wall=168074
2024-02-24 08:32:45 | INFO | train_inner | epoch 003:    536 / 6724 loss=4.931, ppl=30.52, wps=22069.3, ups=0.08, wpb=262140, bsz=512, num_updates=14100, lr=0.00266312, gnorm=0.426, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=169262
2024-02-24 08:52:37 | INFO | train_inner | epoch 003:    636 / 6724 loss=4.93, ppl=30.48, wps=21997.2, ups=0.08, wpb=262144, bsz=512, num_updates=14200, lr=0.00265372, gnorm=0.449, clip=0, loss_scale=4, train_wall=1191, gb_free=10.7, wall=170453
2024-02-24 09:12:27 | INFO | train_inner | epoch 003:    736 / 6724 loss=4.931, ppl=30.51, wps=22030.2, ups=0.08, wpb=262144, bsz=512, num_updates=14300, lr=0.00264443, gnorm=0.47, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=171643
2024-02-24 09:32:17 | INFO | train_inner | epoch 003:    836 / 6724 loss=4.934, ppl=30.56, wps=22030.4, ups=0.08, wpb=262144, bsz=512, num_updates=14400, lr=0.00263523, gnorm=0.416, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=172833
2024-02-24 09:52:11 | INFO | train_inner | epoch 003:    936 / 6724 loss=4.93, ppl=30.49, wps=21945.8, ups=0.08, wpb=262144, bsz=512, num_updates=14500, lr=0.00262613, gnorm=0.444, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=174028
2024-02-24 10:12:06 | INFO | train_inner | epoch 003:   1036 / 6724 loss=4.928, ppl=30.45, wps=21934.7, ups=0.08, wpb=262144, bsz=512, num_updates=14600, lr=0.00261712, gnorm=0.448, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=175223
2024-02-24 10:31:53 | INFO | train_inner | epoch 003:   1136 / 6724 loss=4.929, ppl=30.47, wps=22098.2, ups=0.08, wpb=262144, bsz=512, num_updates=14700, lr=0.0026082, gnorm=0.469, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=176409
2024-02-24 10:51:43 | INFO | train_inner | epoch 003:   1236 / 6724 loss=4.928, ppl=30.45, wps=22027.5, ups=0.08, wpb=262144, bsz=512, num_updates=14800, lr=0.00259938, gnorm=0.416, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=177599
2024-02-24 11:11:33 | INFO | train_inner | epoch 003:   1336 / 6724 loss=4.928, ppl=30.45, wps=22017.6, ups=0.08, wpb=262144, bsz=512, num_updates=14900, lr=0.00259064, gnorm=0.451, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=178790
2024-02-24 11:31:37 | INFO | train_inner | epoch 003:   1436 / 6724 loss=4.927, ppl=30.42, wps=21778, ups=0.08, wpb=262144, bsz=512, num_updates=15000, lr=0.00258199, gnorm=0.456, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=179993
2024-02-24 11:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 15000 updates
2024-02-24 11:31:37 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_15000.pt
2024-02-24 11:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_15000.pt
2024-02-24 11:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_15000.pt (epoch 3 @ 15000 updates, score None) (writing took 43.6500478660455 seconds)
2024-02-24 11:52:28 | INFO | train_inner | epoch 003:   1536 / 6724 loss=4.923, ppl=30.35, wps=20958.9, ups=0.08, wpb=262144, bsz=512, num_updates=15100, lr=0.00257343, gnorm=0.429, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=181244
2024-02-24 12:12:42 | INFO | train_inner | epoch 003:   1636 / 6724 loss=4.924, ppl=30.36, wps=21580.8, ups=0.08, wpb=262144, bsz=512, num_updates=15200, lr=0.00256495, gnorm=0.446, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=182459
2024-02-24 12:33:02 | INFO | train_inner | epoch 003:   1736 / 6724 loss=4.922, ppl=30.31, wps=21497.6, ups=0.08, wpb=262144, bsz=512, num_updates=15300, lr=0.00255655, gnorm=0.414, clip=0, loss_scale=4, train_wall=1219, gb_free=10.7, wall=183678
2024-02-24 12:53:14 | INFO | train_inner | epoch 003:   1836 / 6724 loss=4.922, ppl=30.31, wps=21632.2, ups=0.08, wpb=262144, bsz=512, num_updates=15400, lr=0.00254824, gnorm=0.458, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=184890
2024-02-24 13:13:07 | INFO | train_inner | epoch 003:   1936 / 6724 loss=4.921, ppl=30.3, wps=21969.8, ups=0.08, wpb=262144, bsz=512, num_updates=15500, lr=0.00254, gnorm=0.444, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=186083
2024-02-24 13:33:00 | INFO | train_inner | epoch 003:   2036 / 6724 loss=4.922, ppl=30.32, wps=21965.4, ups=0.08, wpb=262144, bsz=512, num_updates=15600, lr=0.00253185, gnorm=0.447, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=187277
2024-02-24 13:52:53 | INFO | train_inner | epoch 003:   2136 / 6724 loss=4.923, ppl=30.33, wps=21970.6, ups=0.08, wpb=262144, bsz=512, num_updates=15700, lr=0.00252377, gnorm=0.428, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=188470
2024-02-24 14:12:42 | INFO | train_inner | epoch 003:   2236 / 6724 loss=4.916, ppl=30.19, wps=22047.7, ups=0.08, wpb=262144, bsz=512, num_updates=15800, lr=0.00251577, gnorm=0.465, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=189659
2024-02-24 14:32:30 | INFO | train_inner | epoch 003:   2336 / 6724 loss=4.916, ppl=30.19, wps=22066.5, ups=0.08, wpb=262144, bsz=512, num_updates=15900, lr=0.00250785, gnorm=0.458, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=190847
2024-02-24 14:52:17 | INFO | train_inner | epoch 003:   2436 / 6724 loss=4.913, ppl=30.12, wps=22097.1, ups=0.08, wpb=262144, bsz=512, num_updates=16000, lr=0.0025, gnorm=0.445, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=192033
2024-02-24 15:12:03 | INFO | train_inner | epoch 003:   2536 / 6724 loss=4.913, ppl=30.12, wps=22108.1, ups=0.08, wpb=262144, bsz=512, num_updates=16100, lr=0.00249222, gnorm=0.434, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=193219
2024-02-24 15:31:52 | INFO | train_inner | epoch 003:   2636 / 6724 loss=4.911, ppl=30.09, wps=22029.8, ups=0.08, wpb=262144, bsz=512, num_updates=16200, lr=0.00248452, gnorm=0.458, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=194409
2024-02-24 15:51:49 | INFO | train_inner | epoch 003:   2736 / 6724 loss=4.91, ppl=30.07, wps=21916.6, ups=0.08, wpb=262144, bsz=512, num_updates=16300, lr=0.00247689, gnorm=0.424, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=195605
2024-02-24 16:11:45 | INFO | train_inner | epoch 003:   2836 / 6724 loss=4.909, ppl=30.04, wps=21908.6, ups=0.08, wpb=262144, bsz=512, num_updates=16400, lr=0.00246932, gnorm=0.418, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=196802
2024-02-24 16:31:35 | INFO | train_inner | epoch 003:   2936 / 6724 loss=4.91, ppl=30.06, wps=22039.4, ups=0.08, wpb=262144, bsz=512, num_updates=16500, lr=0.00246183, gnorm=0.416, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=197991
2024-02-24 16:50:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-24 16:51:45 | INFO | train_inner | epoch 003:   3037 / 6724 loss=4.911, ppl=30.08, wps=21648, ups=0.08, wpb=262144, bsz=512, num_updates=16600, lr=0.0024544, gnorm=0.441, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=199202
2024-02-24 17:11:53 | INFO | train_inner | epoch 003:   3137 / 6724 loss=4.907, ppl=30, wps=21709.4, ups=0.08, wpb=262144, bsz=512, num_updates=16700, lr=0.00244704, gnorm=0.462, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=200409
2024-02-24 17:31:52 | INFO | train_inner | epoch 003:   3237 / 6724 loss=4.909, ppl=30.05, wps=21863.8, ups=0.08, wpb=262144, bsz=512, num_updates=16800, lr=0.00243975, gnorm=0.423, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=201608
2024-02-24 17:52:08 | INFO | train_inner | epoch 003:   3337 / 6724 loss=4.909, ppl=30.03, wps=21563.8, ups=0.08, wpb=262144, bsz=512, num_updates=16900, lr=0.00243252, gnorm=0.459, clip=0, loss_scale=4, train_wall=1215, gb_free=10.7, wall=202824
2024-02-24 18:12:13 | INFO | train_inner | epoch 003:   3437 / 6724 loss=4.906, ppl=29.99, wps=21696.4, ups=0.08, wpb=261519, bsz=510.8, num_updates=17000, lr=0.00242536, gnorm=0.459, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=204029
2024-02-24 18:32:00 | INFO | train_inner | epoch 003:   3537 / 6724 loss=4.905, ppl=29.95, wps=22091.6, ups=0.08, wpb=262144, bsz=512, num_updates=17100, lr=0.00241825, gnorm=0.453, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=205216
2024-02-24 18:52:17 | INFO | train_inner | epoch 003:   3637 / 6724 loss=4.906, ppl=29.98, wps=21526.9, ups=0.08, wpb=262144, bsz=512, num_updates=17200, lr=0.00241121, gnorm=0.426, clip=0, loss_scale=4, train_wall=1218, gb_free=10.7, wall=206434
2024-02-24 19:12:39 | INFO | train_inner | epoch 003:   3737 / 6724 loss=4.903, ppl=29.92, wps=21458.2, ups=0.08, wpb=262144, bsz=512, num_updates=17300, lr=0.00240424, gnorm=0.439, clip=0, loss_scale=4, train_wall=1221, gb_free=10.7, wall=207656
2024-02-24 19:32:34 | INFO | train_inner | epoch 003:   3837 / 6724 loss=4.904, ppl=29.95, wps=21937.2, ups=0.08, wpb=262144, bsz=512, num_updates=17400, lr=0.00239732, gnorm=0.449, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=208850
2024-02-24 19:52:52 | INFO | train_inner | epoch 003:   3937 / 6724 loss=4.899, ppl=29.84, wps=21522.9, ups=0.08, wpb=262144, bsz=512, num_updates=17500, lr=0.00239046, gnorm=0.449, clip=0, loss_scale=4, train_wall=1218, gb_free=10.7, wall=210068
2024-02-24 20:12:55 | INFO | train_inner | epoch 003:   4037 / 6724 loss=4.897, ppl=29.8, wps=21788.9, ups=0.08, wpb=262144, bsz=512, num_updates=17600, lr=0.00238366, gnorm=0.448, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=211272
2024-02-24 20:32:50 | INFO | train_inner | epoch 003:   4137 / 6724 loss=4.905, ppl=29.96, wps=21945.2, ups=0.08, wpb=262144, bsz=512, num_updates=17700, lr=0.00237691, gnorm=0.418, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=212466
2024-02-24 20:52:34 | INFO | train_inner | epoch 003:   4237 / 6724 loss=4.901, ppl=29.87, wps=22131.6, ups=0.08, wpb=262144, bsz=512, num_updates=17800, lr=0.00237023, gnorm=0.435, clip=0, loss_scale=4, train_wall=1184, gb_free=10.7, wall=213651
2024-02-24 21:12:29 | INFO | train_inner | epoch 003:   4337 / 6724 loss=4.898, ppl=29.81, wps=21947, ups=0.08, wpb=262144, bsz=512, num_updates=17900, lr=0.0023636, gnorm=0.467, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=214845
2024-02-24 21:32:27 | INFO | train_inner | epoch 003:   4437 / 6724 loss=4.902, ppl=29.89, wps=21882.5, ups=0.08, wpb=262144, bsz=512, num_updates=18000, lr=0.00235702, gnorm=0.444, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=216043
2024-02-24 21:52:24 | INFO | train_inner | epoch 003:   4537 / 6724 loss=4.894, ppl=29.73, wps=21900.2, ups=0.08, wpb=262144, bsz=512, num_updates=18100, lr=0.0023505, gnorm=0.426, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=217240
2024-02-24 22:12:36 | INFO | train_inner | epoch 003:   4637 / 6724 loss=4.896, ppl=29.78, wps=21626.1, ups=0.08, wpb=262144, bsz=512, num_updates=18200, lr=0.00234404, gnorm=0.433, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=218452
2024-02-24 22:32:51 | INFO | train_inner | epoch 003:   4737 / 6724 loss=4.892, ppl=29.68, wps=21565.7, ups=0.08, wpb=262144, bsz=512, num_updates=18300, lr=0.00233762, gnorm=0.442, clip=0, loss_scale=4, train_wall=1215, gb_free=10.7, wall=219668
2024-02-24 22:52:48 | INFO | train_inner | epoch 003:   4837 / 6724 loss=4.895, ppl=29.75, wps=21908.3, ups=0.08, wpb=262144, bsz=512, num_updates=18400, lr=0.00233126, gnorm=0.434, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=220864
2024-02-24 23:12:47 | INFO | train_inner | epoch 003:   4937 / 6724 loss=4.898, ppl=29.81, wps=21851.9, ups=0.08, wpb=262144, bsz=512, num_updates=18500, lr=0.00232495, gnorm=0.415, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=222064
2024-02-24 23:32:34 | INFO | train_inner | epoch 003:   5037 / 6724 loss=4.894, ppl=29.74, wps=22100.1, ups=0.08, wpb=262144, bsz=512, num_updates=18600, lr=0.00231869, gnorm=0.419, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=223250
2024-02-24 23:52:23 | INFO | train_inner | epoch 003:   5137 / 6724 loss=4.892, ppl=29.7, wps=22038.1, ups=0.08, wpb=262144, bsz=512, num_updates=18700, lr=0.00231249, gnorm=0.426, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=224440
2024-02-25 00:12:16 | INFO | train_inner | epoch 003:   5237 / 6724 loss=4.898, ppl=29.81, wps=21972, ups=0.08, wpb=262144, bsz=512, num_updates=18800, lr=0.00230633, gnorm=0.435, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=225633
2024-02-25 00:32:17 | INFO | train_inner | epoch 003:   5337 / 6724 loss=4.892, ppl=29.7, wps=21832.6, ups=0.08, wpb=262144, bsz=512, num_updates=18900, lr=0.00230022, gnorm=0.443, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=226833
2024-02-25 00:52:08 | INFO | train_inner | epoch 003:   5437 / 6724 loss=4.891, ppl=29.68, wps=22000.8, ups=0.08, wpb=262144, bsz=512, num_updates=19000, lr=0.00229416, gnorm=0.487, clip=0, loss_scale=4, train_wall=1191, gb_free=10.7, wall=228025
2024-02-25 01:12:15 | INFO | train_inner | epoch 003:   5537 / 6724 loss=4.889, ppl=29.63, wps=21719.7, ups=0.08, wpb=262144, bsz=512, num_updates=19100, lr=0.00228814, gnorm=0.442, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=229232
2024-02-25 01:32:24 | INFO | train_inner | epoch 003:   5637 / 6724 loss=4.89, ppl=29.65, wps=21681, ups=0.08, wpb=262144, bsz=512, num_updates=19200, lr=0.00228218, gnorm=0.432, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=230441
2024-02-25 01:52:29 | INFO | train_inner | epoch 003:   5737 / 6724 loss=4.888, ppl=29.61, wps=21762.1, ups=0.08, wpb=262144, bsz=512, num_updates=19300, lr=0.00227626, gnorm=0.453, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=231646
2024-02-25 02:12:38 | INFO | train_inner | epoch 003:   5837 / 6724 loss=4.886, ppl=29.57, wps=21677.8, ups=0.08, wpb=262144, bsz=512, num_updates=19400, lr=0.00227038, gnorm=0.425, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=232855
2024-02-25 02:32:52 | INFO | train_inner | epoch 003:   5937 / 6724 loss=4.886, ppl=29.56, wps=21593.1, ups=0.08, wpb=262144, bsz=512, num_updates=19500, lr=0.00226455, gnorm=0.438, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=234069
2024-02-25 02:52:56 | INFO | train_inner | epoch 003:   6037 / 6724 loss=4.886, ppl=29.57, wps=21773.6, ups=0.08, wpb=262144, bsz=512, num_updates=19600, lr=0.00225877, gnorm=0.462, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=235273
2024-02-25 03:13:09 | INFO | train_inner | epoch 003:   6137 / 6724 loss=4.885, ppl=29.55, wps=21623.5, ups=0.08, wpb=262144, bsz=512, num_updates=19700, lr=0.00225303, gnorm=0.446, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=236485
2024-02-25 03:33:26 | INFO | train_inner | epoch 003:   6237 / 6724 loss=4.884, ppl=29.53, wps=21532.3, ups=0.08, wpb=262144, bsz=512, num_updates=19800, lr=0.00224733, gnorm=0.43, clip=0, loss_scale=4, train_wall=1217, gb_free=10.7, wall=237703
2024-02-25 03:53:51 | INFO | train_inner | epoch 003:   6337 / 6724 loss=4.882, ppl=29.48, wps=21407.5, ups=0.08, wpb=262144, bsz=512, num_updates=19900, lr=0.00224168, gnorm=0.402, clip=0, loss_scale=4, train_wall=1224, gb_free=10.7, wall=238927
2024-02-25 04:13:56 | INFO | train_inner | epoch 003:   6437 / 6724 loss=4.885, ppl=29.54, wps=21752.8, ups=0.08, wpb=262144, bsz=512, num_updates=20000, lr=0.00223607, gnorm=0.434, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=240132
2024-02-25 04:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20000 updates
2024-02-25 04:13:56 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_20000.pt
2024-02-25 04:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_20000.pt
2024-02-25 04:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_3_20000.pt (epoch 3 @ 20000 updates, score None) (writing took 44.36814213800244 seconds)
2024-02-25 04:34:43 | INFO | train_inner | epoch 003:   6537 / 6724 loss=4.883, ppl=29.5, wps=21019.6, ups=0.08, wpb=262144, bsz=512, num_updates=20100, lr=0.0022305, gnorm=0.426, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=241379
2024-02-25 04:54:46 | INFO | train_inner | epoch 003:   6637 / 6724 loss=4.884, ppl=29.52, wps=21780.7, ups=0.08, wpb=262144, bsz=512, num_updates=20200, lr=0.00222497, gnorm=0.434, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=242583
2024-02-25 05:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20287 updates
2024-02-25 05:12:20 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint3.pt
2024-02-25 05:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint3.pt
2024-02-25 05:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint3.pt (epoch 3 @ 20287 updates, score None) (writing took 75.39697181095835 seconds)
2024-02-25 05:13:36 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-02-25 05:13:36 | INFO | train | epoch 003 | loss 4.908 | ppl 30.02 | wps 21802 | ups 0.08 | wpb 262115 | bsz 511.9 | num_updates 20287 | lr 0.00222019 | gnorm 0.44 | clip 0 | loss_scale 4 | train_wall 80647 | gb_free 10.7 | wall 243712
2024-02-25 05:13:36 | INFO | fairseq.trainer | loading train data for epoch 4
2024-02-25 05:13:37 | INFO | fairseq.data.data_utils | loaded 52,445,000 examples from: ./data/data-bin/3/train
2024-02-25 05:13:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6739
2024-02-25 05:13:37 | INFO | fairseq.trainer | begin training epoch 4
2024-02-25 05:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-25 05:16:11 | INFO | train_inner | epoch 004:     13 / 6739 loss=4.886, ppl=29.57, wps=20303.3, ups=0.08, wpb=260833, bsz=509.4, num_updates=20300, lr=0.00221948, gnorm=0.404, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=243868
2024-02-25 05:36:06 | INFO | train_inner | epoch 004:    113 / 6739 loss=4.88, ppl=29.46, wps=21944.2, ups=0.08, wpb=262144, bsz=512, num_updates=20400, lr=0.00221404, gnorm=0.44, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=245062
2024-02-25 05:56:05 | INFO | train_inner | epoch 004:    213 / 6739 loss=4.874, ppl=29.32, wps=21863.8, ups=0.08, wpb=262144, bsz=512, num_updates=20500, lr=0.00220863, gnorm=0.417, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=246261
2024-02-25 06:16:34 | INFO | train_inner | epoch 004:    313 / 6739 loss=4.879, ppl=29.42, wps=21320.5, ups=0.08, wpb=262144, bsz=512, num_updates=20600, lr=0.00220326, gnorm=0.423, clip=0, loss_scale=4, train_wall=1229, gb_free=10.7, wall=247491
2024-02-25 06:35:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-25 06:36:52 | INFO | train_inner | epoch 004:    414 / 6739 loss=4.877, ppl=29.38, wps=21522.3, ups=0.08, wpb=262144, bsz=512, num_updates=20700, lr=0.00219793, gnorm=0.455, clip=0, loss_scale=4, train_wall=1218, gb_free=10.7, wall=248709
2024-02-25 06:56:54 | INFO | train_inner | epoch 004:    514 / 6739 loss=4.875, ppl=29.34, wps=21822.1, ups=0.08, wpb=262144, bsz=512, num_updates=20800, lr=0.00219265, gnorm=0.437, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=249910
2024-02-25 07:16:41 | INFO | train_inner | epoch 004:    614 / 6739 loss=4.873, ppl=29.31, wps=22074.5, ups=0.08, wpb=262144, bsz=512, num_updates=20900, lr=0.00218739, gnorm=0.428, clip=0, loss_scale=4, train_wall=1187, gb_free=10.7, wall=251098
2024-02-25 07:36:31 | INFO | train_inner | epoch 004:    714 / 6739 loss=4.873, ppl=29.31, wps=22033.5, ups=0.08, wpb=262144, bsz=512, num_updates=21000, lr=0.00218218, gnorm=0.4, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=252287
2024-02-25 07:56:15 | INFO | train_inner | epoch 004:    814 / 6739 loss=4.878, ppl=29.41, wps=22128, ups=0.08, wpb=262144, bsz=512, num_updates=21100, lr=0.002177, gnorm=0.489, clip=0, loss_scale=4, train_wall=1184, gb_free=10.7, wall=253472
2024-02-25 08:16:08 | INFO | train_inner | epoch 004:    914 / 6739 loss=4.872, ppl=29.29, wps=21991.1, ups=0.08, wpb=262144, bsz=512, num_updates=21200, lr=0.00217186, gnorm=0.453, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=254664
2024-02-25 08:35:57 | INFO | train_inner | epoch 004:   1014 / 6739 loss=4.87, ppl=29.24, wps=22041, ups=0.08, wpb=262144, bsz=512, num_updates=21300, lr=0.00216676, gnorm=0.424, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=255853
2024-02-25 08:55:52 | INFO | train_inner | epoch 004:   1114 / 6739 loss=4.872, ppl=29.29, wps=21929.3, ups=0.08, wpb=262144, bsz=512, num_updates=21400, lr=0.00216169, gnorm=0.434, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=257049
2024-02-25 09:15:42 | INFO | train_inner | epoch 004:   1214 / 6739 loss=4.872, ppl=29.28, wps=22040.9, ups=0.08, wpb=262144, bsz=512, num_updates=21500, lr=0.00215666, gnorm=0.435, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=258238
2024-02-25 09:35:26 | INFO | train_inner | epoch 004:   1314 / 6739 loss=4.866, ppl=29.16, wps=22127.7, ups=0.08, wpb=262144, bsz=512, num_updates=21600, lr=0.00215166, gnorm=0.426, clip=0, loss_scale=4, train_wall=1184, gb_free=10.7, wall=259423
2024-02-25 09:55:43 | INFO | train_inner | epoch 004:   1414 / 6739 loss=4.877, ppl=29.38, wps=21537.7, ups=0.08, wpb=262144, bsz=512, num_updates=21700, lr=0.00214669, gnorm=0.433, clip=0, loss_scale=4, train_wall=1217, gb_free=10.7, wall=260640
2024-02-25 10:16:04 | INFO | train_inner | epoch 004:   1514 / 6739 loss=4.878, ppl=29.4, wps=21471.5, ups=0.08, wpb=262144, bsz=512, num_updates=21800, lr=0.00214176, gnorm=0.424, clip=0, loss_scale=4, train_wall=1221, gb_free=10.7, wall=261861
2024-02-25 10:36:08 | INFO | train_inner | epoch 004:   1614 / 6739 loss=4.873, ppl=29.31, wps=21784.6, ups=0.08, wpb=262144, bsz=512, num_updates=21900, lr=0.00213687, gnorm=0.417, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=263064
2024-02-25 10:56:10 | INFO | train_inner | epoch 004:   1714 / 6739 loss=4.872, ppl=29.28, wps=21809.5, ups=0.08, wpb=262144, bsz=512, num_updates=22000, lr=0.00213201, gnorm=0.443, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=264266
2024-02-25 11:16:06 | INFO | train_inner | epoch 004:   1814 / 6739 loss=4.868, ppl=29.2, wps=21906.7, ups=0.08, wpb=262144, bsz=512, num_updates=22100, lr=0.00212718, gnorm=0.446, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=265463
2024-02-25 11:36:09 | INFO | train_inner | epoch 004:   1914 / 6739 loss=4.868, ppl=29.21, wps=21790.6, ups=0.08, wpb=262144, bsz=512, num_updates=22200, lr=0.00212238, gnorm=0.47, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=266666
2024-02-25 11:56:03 | INFO | train_inner | epoch 004:   2014 / 6739 loss=4.866, ppl=29.17, wps=21958.7, ups=0.08, wpb=262144, bsz=512, num_updates=22300, lr=0.00211762, gnorm=0.436, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=267860
2024-02-25 12:16:00 | INFO | train_inner | epoch 004:   2114 / 6739 loss=4.87, ppl=29.24, wps=21906.5, ups=0.08, wpb=262144, bsz=512, num_updates=22400, lr=0.00211289, gnorm=0.424, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=269056
2024-02-25 12:36:02 | INFO | train_inner | epoch 004:   2214 / 6739 loss=4.867, ppl=29.19, wps=21807.1, ups=0.08, wpb=262144, bsz=512, num_updates=22500, lr=0.00210819, gnorm=0.434, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=270258
2024-02-25 12:56:01 | INFO | train_inner | epoch 004:   2314 / 6739 loss=4.87, ppl=29.24, wps=21864, ups=0.08, wpb=262144, bsz=512, num_updates=22600, lr=0.00210352, gnorm=0.441, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=271457
2024-02-25 13:15:56 | INFO | train_inner | epoch 004:   2414 / 6739 loss=4.869, ppl=29.23, wps=21937.9, ups=0.08, wpb=262144, bsz=512, num_updates=22700, lr=0.00209888, gnorm=0.419, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=272652
2024-02-25 13:36:02 | INFO | train_inner | epoch 004:   2514 / 6739 loss=4.866, ppl=29.17, wps=21726.6, ups=0.08, wpb=262144, bsz=512, num_updates=22800, lr=0.00209427, gnorm=0.437, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=273859
2024-02-25 13:56:25 | INFO | train_inner | epoch 004:   2614 / 6739 loss=4.864, ppl=29.13, wps=21446.7, ups=0.08, wpb=262144, bsz=512, num_updates=22900, lr=0.00208969, gnorm=0.446, clip=0, loss_scale=4, train_wall=1222, gb_free=10.7, wall=275081
2024-02-25 14:16:43 | INFO | train_inner | epoch 004:   2714 / 6739 loss=4.864, ppl=29.11, wps=21516.4, ups=0.08, wpb=262144, bsz=512, num_updates=23000, lr=0.00208514, gnorm=0.482, clip=0, loss_scale=4, train_wall=1218, gb_free=10.7, wall=276299
2024-02-25 14:36:57 | INFO | train_inner | epoch 004:   2814 / 6739 loss=4.861, ppl=29.07, wps=21600.9, ups=0.08, wpb=262144, bsz=512, num_updates=23100, lr=0.00208063, gnorm=0.499, clip=0, loss_scale=4, train_wall=1213, gb_free=10.7, wall=277513
2024-02-25 14:57:16 | INFO | train_inner | epoch 004:   2914 / 6739 loss=4.864, ppl=29.11, wps=21496.4, ups=0.08, wpb=262142, bsz=512, num_updates=23200, lr=0.00207614, gnorm=0.408, clip=0, loss_scale=4, train_wall=1219, gb_free=10.7, wall=278733
2024-02-25 15:16:40 | INFO | train_inner | epoch 004:   3014 / 6739 loss=4.865, ppl=29.14, wps=22520.5, ups=0.09, wpb=262144, bsz=512, num_updates=23300, lr=0.00207168, gnorm=0.431, clip=0, loss_scale=4, train_wall=1164, gb_free=10.7, wall=279897
2024-02-25 15:36:03 | INFO | train_inner | epoch 004:   3114 / 6739 loss=4.864, ppl=29.12, wps=22538.4, ups=0.09, wpb=262144, bsz=512, num_updates=23400, lr=0.00206725, gnorm=0.428, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=281060
2024-02-25 15:55:27 | INFO | train_inner | epoch 004:   3214 / 6739 loss=4.864, ppl=29.11, wps=22532.7, ups=0.09, wpb=262144, bsz=512, num_updates=23500, lr=0.00206284, gnorm=0.443, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=282223
2024-02-25 16:14:59 | INFO | train_inner | epoch 004:   3314 / 6739 loss=4.86, ppl=29.05, wps=22364.8, ups=0.09, wpb=262144, bsz=512, num_updates=23600, lr=0.00205847, gnorm=0.428, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=283395
2024-02-25 16:34:23 | INFO | train_inner | epoch 004:   3414 / 6739 loss=4.863, ppl=29.11, wps=22525.4, ups=0.09, wpb=262144, bsz=512, num_updates=23700, lr=0.00205412, gnorm=0.462, clip=0, loss_scale=4, train_wall=1164, gb_free=10.7, wall=284559
2024-02-25 16:53:47 | INFO | train_inner | epoch 004:   3514 / 6739 loss=4.861, ppl=29.05, wps=22511.9, ups=0.09, wpb=262144, bsz=512, num_updates=23800, lr=0.0020498, gnorm=0.441, clip=0, loss_scale=4, train_wall=1164, gb_free=10.7, wall=285723
2024-02-25 17:13:19 | INFO | train_inner | epoch 004:   3614 / 6739 loss=4.859, ppl=29.03, wps=22366.5, ups=0.09, wpb=262144, bsz=512, num_updates=23900, lr=0.00204551, gnorm=0.433, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=286895
2024-02-25 17:32:40 | INFO | train_inner | epoch 004:   3714 / 6739 loss=4.859, ppl=29.01, wps=22574.9, ups=0.09, wpb=262144, bsz=512, num_updates=24000, lr=0.00204124, gnorm=0.426, clip=0, loss_scale=4, train_wall=1161, gb_free=10.7, wall=288057
2024-02-25 17:52:03 | INFO | train_inner | epoch 004:   3814 / 6739 loss=4.861, ppl=29.07, wps=22535.6, ups=0.09, wpb=262144, bsz=512, num_updates=24100, lr=0.002037, gnorm=0.447, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=289220
2024-02-25 18:11:21 | INFO | train_inner | epoch 004:   3914 / 6739 loss=4.859, ppl=29.02, wps=22656.4, ups=0.09, wpb=262144, bsz=512, num_updates=24200, lr=0.00203279, gnorm=0.427, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=290377
2024-02-25 18:30:41 | INFO | train_inner | epoch 004:   4014 / 6739 loss=4.853, ppl=28.91, wps=22596, ups=0.09, wpb=262144, bsz=512, num_updates=24300, lr=0.0020286, gnorm=0.424, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=291537
2024-02-25 18:49:58 | INFO | train_inner | epoch 004:   4114 / 6739 loss=4.857, ppl=28.99, wps=22645, ups=0.09, wpb=262144, bsz=512, num_updates=24400, lr=0.00202444, gnorm=0.426, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=292695
2024-02-25 19:09:15 | INFO | train_inner | epoch 004:   4214 / 6739 loss=4.86, ppl=29.04, wps=22662.6, ups=0.09, wpb=262144, bsz=512, num_updates=24500, lr=0.00202031, gnorm=0.435, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=293851
2024-02-25 19:28:31 | INFO | train_inner | epoch 004:   4314 / 6739 loss=4.858, ppl=29, wps=22686.6, ups=0.09, wpb=262144, bsz=512, num_updates=24600, lr=0.00201619, gnorm=0.434, clip=0, loss_scale=4, train_wall=1155, gb_free=10.7, wall=295007
2024-02-25 19:47:55 | INFO | train_inner | epoch 004:   4414 / 6739 loss=4.854, ppl=28.91, wps=22517.4, ups=0.09, wpb=262144, bsz=512, num_updates=24700, lr=0.00201211, gnorm=0.439, clip=0, loss_scale=4, train_wall=1164, gb_free=10.7, wall=296171
2024-02-25 20:07:10 | INFO | train_inner | epoch 004:   4514 / 6739 loss=4.859, ppl=29.01, wps=22687.1, ups=0.09, wpb=262144, bsz=512, num_updates=24800, lr=0.00200805, gnorm=0.419, clip=0, loss_scale=8, train_wall=1155, gb_free=10.7, wall=297327
2024-02-25 20:11:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-25 20:26:42 | INFO | train_inner | epoch 004:   4615 / 6739 loss=4.856, ppl=28.95, wps=22370.2, ups=0.09, wpb=262144, bsz=512, num_updates=24900, lr=0.00200401, gnorm=0.439, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=298498
2024-02-25 20:46:07 | INFO | train_inner | epoch 004:   4715 / 6739 loss=4.855, ppl=28.95, wps=22499.6, ups=0.09, wpb=262144, bsz=512, num_updates=25000, lr=0.002, gnorm=0.437, clip=0, loss_scale=4, train_wall=1165, gb_free=10.7, wall=299664
2024-02-25 20:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 25000 updates
2024-02-25 20:46:07 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_4_25000.pt
2024-02-25 20:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_4_25000.pt
2024-02-25 20:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_4_25000.pt (epoch 4 @ 25000 updates, score None) (writing took 44.1369137680158 seconds)
2024-02-25 21:06:15 | INFO | train_inner | epoch 004:   4815 / 6739 loss=4.853, ppl=28.89, wps=21711.7, ups=0.08, wpb=262144, bsz=512, num_updates=25100, lr=0.00199601, gnorm=0.486, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=300871
2024-02-25 21:25:32 | INFO | train_inner | epoch 004:   4915 / 6739 loss=4.852, ppl=28.88, wps=22646.3, ups=0.09, wpb=262103, bsz=511.9, num_updates=25200, lr=0.00199205, gnorm=0.425, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=302028
2024-02-25 21:44:43 | INFO | train_inner | epoch 004:   5015 / 6739 loss=4.849, ppl=28.83, wps=22773.6, ups=0.09, wpb=262144, bsz=512, num_updates=25300, lr=0.00198811, gnorm=0.483, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=303179
2024-02-25 22:04:02 | INFO | train_inner | epoch 004:   5115 / 6739 loss=4.851, ppl=28.85, wps=22614.1, ups=0.09, wpb=262144, bsz=512, num_updates=25400, lr=0.00198419, gnorm=0.403, clip=0, loss_scale=4, train_wall=1159, gb_free=10.7, wall=304339
2024-02-25 22:23:16 | INFO | train_inner | epoch 004:   5215 / 6739 loss=4.857, ppl=28.98, wps=22721.7, ups=0.09, wpb=262144, bsz=512, num_updates=25500, lr=0.0019803, gnorm=0.427, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=305492
2024-02-25 22:42:29 | INFO | train_inner | epoch 004:   5315 / 6739 loss=4.855, ppl=28.93, wps=22729.4, ups=0.09, wpb=262144, bsz=512, num_updates=25600, lr=0.00197642, gnorm=0.47, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=306646
2024-02-25 23:01:40 | INFO | train_inner | epoch 004:   5415 / 6739 loss=4.85, ppl=28.83, wps=22770.8, ups=0.09, wpb=262144, bsz=512, num_updates=25700, lr=0.00197257, gnorm=0.443, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=307797
2024-02-25 23:21:00 | INFO | train_inner | epoch 004:   5515 / 6739 loss=4.852, ppl=28.88, wps=22609, ups=0.09, wpb=262144, bsz=512, num_updates=25800, lr=0.00196875, gnorm=0.477, clip=0, loss_scale=4, train_wall=1159, gb_free=10.7, wall=308956
2024-02-25 23:40:21 | INFO | train_inner | epoch 004:   5615 / 6739 loss=4.853, ppl=28.89, wps=22578.2, ups=0.09, wpb=262144, bsz=512, num_updates=25900, lr=0.00196494, gnorm=0.462, clip=0, loss_scale=4, train_wall=1161, gb_free=10.7, wall=310117
2024-02-25 23:59:38 | INFO | train_inner | epoch 004:   5715 / 6739 loss=4.853, ppl=28.89, wps=22653.6, ups=0.09, wpb=262144, bsz=512, num_updates=26000, lr=0.00196116, gnorm=0.447, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=311275
2024-02-26 00:18:51 | INFO | train_inner | epoch 004:   5815 / 6739 loss=4.85, ppl=28.84, wps=22741.3, ups=0.09, wpb=262144, bsz=512, num_updates=26100, lr=0.0019574, gnorm=0.448, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=312427
2024-02-26 00:38:03 | INFO | train_inner | epoch 004:   5915 / 6739 loss=4.848, ppl=28.81, wps=22761.2, ups=0.09, wpb=262144, bsz=512, num_updates=26200, lr=0.00195366, gnorm=0.43, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=313579
2024-02-26 00:57:16 | INFO | train_inner | epoch 004:   6015 / 6739 loss=4.849, ppl=28.82, wps=22733.3, ups=0.09, wpb=262144, bsz=512, num_updates=26300, lr=0.00194994, gnorm=0.434, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=314732
2024-02-26 01:16:28 | INFO | train_inner | epoch 004:   6115 / 6739 loss=4.847, ppl=28.79, wps=22743, ups=0.09, wpb=262144, bsz=512, num_updates=26400, lr=0.00194625, gnorm=0.45, clip=0, loss_scale=4, train_wall=1152, gb_free=10.7, wall=315885
2024-02-26 01:35:40 | INFO | train_inner | epoch 004:   6215 / 6739 loss=4.847, ppl=28.78, wps=22763.1, ups=0.09, wpb=262144, bsz=512, num_updates=26500, lr=0.00194257, gnorm=0.477, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=317036
2024-02-26 01:54:52 | INFO | train_inner | epoch 004:   6315 / 6739 loss=4.845, ppl=28.74, wps=22751.4, ups=0.09, wpb=262144, bsz=512, num_updates=26600, lr=0.00193892, gnorm=0.438, clip=0, loss_scale=4, train_wall=1152, gb_free=10.7, wall=318189
2024-02-26 02:14:11 | INFO | train_inner | epoch 004:   6415 / 6739 loss=4.845, ppl=28.74, wps=22624.7, ups=0.09, wpb=262144, bsz=512, num_updates=26700, lr=0.00193528, gnorm=0.501, clip=0, loss_scale=4, train_wall=1158, gb_free=10.7, wall=319347
2024-02-26 02:33:29 | INFO | train_inner | epoch 004:   6515 / 6739 loss=4.85, ppl=28.84, wps=22632.8, ups=0.09, wpb=262144, bsz=512, num_updates=26800, lr=0.00193167, gnorm=0.436, clip=0, loss_scale=4, train_wall=1158, gb_free=10.7, wall=320506
2024-02-26 02:52:48 | INFO | train_inner | epoch 004:   6615 / 6739 loss=4.849, ppl=28.82, wps=22624.4, ups=0.09, wpb=262144, bsz=512, num_updates=26900, lr=0.00192807, gnorm=0.458, clip=0, loss_scale=4, train_wall=1158, gb_free=10.7, wall=321664
2024-02-26 03:12:04 | INFO | train_inner | epoch 004:   6715 / 6739 loss=4.846, ppl=28.76, wps=22678.8, ups=0.09, wpb=262144, bsz=512, num_updates=27000, lr=0.0019245, gnorm=0.44, clip=0, loss_scale=4, train_wall=1156, gb_free=10.7, wall=322820
2024-02-26 03:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 27024 updates
2024-02-26 03:16:43 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint4.pt
2024-02-26 03:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint4.pt
2024-02-26 03:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint4.pt (epoch 4 @ 27024 updates, score None) (writing took 73.04204340092838 seconds)
2024-02-26 03:17:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-02-26 03:17:56 | INFO | train | epoch 004 | loss 4.862 | ppl 29.07 | wps 22224.8 | ups 0.08 | wpb 262134 | bsz 512 | num_updates 27024 | lr 0.00192365 | gnorm 0.441 | clip 0 | loss_scale 4 | train_wall 79327 | gb_free 10.7 | wall 323173
2024-02-26 03:17:56 | INFO | fairseq.trainer | loading train data for epoch 5
2024-02-26 03:17:57 | INFO | fairseq.data.data_utils | loaded 52,822,000 examples from: ./data/data-bin/4/train
2024-02-26 03:17:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6784
2024-02-26 03:17:58 | INFO | fairseq.trainer | begin training epoch 5
2024-02-26 03:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-26 03:32:48 | INFO | train_inner | epoch 005:     76 / 6784 loss=4.851, ppl=28.86, wps=21009.7, ups=0.08, wpb=261489, bsz=510.7, num_updates=27100, lr=0.00192095, gnorm=0.456, clip=0, loss_scale=4, train_wall=1169, gb_free=10.7, wall=324065
2024-02-26 03:52:22 | INFO | train_inner | epoch 005:    176 / 6784 loss=4.851, ppl=28.87, wps=22343.2, ups=0.09, wpb=262144, bsz=512, num_updates=27200, lr=0.00191741, gnorm=0.42, clip=0, loss_scale=4, train_wall=1173, gb_free=10.7, wall=325238
2024-02-26 04:11:47 | INFO | train_inner | epoch 005:    276 / 6784 loss=4.848, ppl=28.79, wps=22500.6, ups=0.09, wpb=262144, bsz=512, num_updates=27300, lr=0.0019139, gnorm=0.442, clip=0, loss_scale=4, train_wall=1165, gb_free=10.7, wall=326403
2024-02-26 04:31:10 | INFO | train_inner | epoch 005:    376 / 6784 loss=4.854, ppl=28.91, wps=22531.6, ups=0.09, wpb=262144, bsz=512, num_updates=27400, lr=0.0019104, gnorm=0.449, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=327567
2024-02-26 04:50:34 | INFO | train_inner | epoch 005:    476 / 6784 loss=4.845, ppl=28.73, wps=22527.7, ups=0.09, wpb=262144, bsz=512, num_updates=27500, lr=0.00190693, gnorm=0.437, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=328730
2024-02-26 05:09:55 | INFO | train_inner | epoch 005:    576 / 6784 loss=4.843, ppl=28.69, wps=22570.1, ups=0.09, wpb=262144, bsz=512, num_updates=27600, lr=0.00190347, gnorm=0.486, clip=0, loss_scale=4, train_wall=1161, gb_free=10.7, wall=329892
2024-02-26 05:29:17 | INFO | train_inner | epoch 005:    676 / 6784 loss=4.85, ppl=28.84, wps=22557.5, ups=0.09, wpb=262144, bsz=512, num_updates=27700, lr=0.00190003, gnorm=0.402, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=331054
2024-02-26 05:48:41 | INFO | train_inner | epoch 005:    776 / 6784 loss=4.842, ppl=28.68, wps=22532.5, ups=0.09, wpb=262144, bsz=512, num_updates=27800, lr=0.00189661, gnorm=0.497, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=332217
2024-02-26 06:08:06 | INFO | train_inner | epoch 005:    876 / 6784 loss=4.849, ppl=28.82, wps=22495.7, ups=0.09, wpb=262144, bsz=512, num_updates=27900, lr=0.00189321, gnorm=0.447, clip=0, loss_scale=4, train_wall=1165, gb_free=10.7, wall=333382
2024-02-26 06:27:29 | INFO | train_inner | epoch 005:    976 / 6784 loss=4.843, ppl=28.7, wps=22490.9, ups=0.09, wpb=261519, bsz=510.8, num_updates=28000, lr=0.00188982, gnorm=0.467, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=334545
2024-02-26 06:46:49 | INFO | train_inner | epoch 005:   1076 / 6784 loss=4.843, ppl=28.71, wps=22586.3, ups=0.09, wpb=262144, bsz=512, num_updates=28100, lr=0.00188646, gnorm=0.449, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=335706
2024-02-26 07:06:12 | INFO | train_inner | epoch 005:   1176 / 6784 loss=4.841, ppl=28.66, wps=22545.9, ups=0.09, wpb=262144, bsz=512, num_updates=28200, lr=0.00188311, gnorm=0.449, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=336869
2024-02-26 07:25:34 | INFO | train_inner | epoch 005:   1276 / 6784 loss=4.843, ppl=28.71, wps=22564.6, ups=0.09, wpb=262144, bsz=512, num_updates=28300, lr=0.00187978, gnorm=0.417, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=338030
2024-02-26 07:45:01 | INFO | train_inner | epoch 005:   1376 / 6784 loss=4.841, ppl=28.66, wps=22455.5, ups=0.09, wpb=262144, bsz=512, num_updates=28400, lr=0.00187647, gnorm=0.428, clip=0, loss_scale=4, train_wall=1167, gb_free=10.7, wall=339198
2024-02-26 08:04:24 | INFO | train_inner | epoch 005:   1476 / 6784 loss=4.844, ppl=28.71, wps=22547, ups=0.09, wpb=262144, bsz=512, num_updates=28500, lr=0.00187317, gnorm=0.462, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=340360
2024-02-26 08:23:42 | INFO | train_inner | epoch 005:   1576 / 6784 loss=4.832, ppl=28.49, wps=22646, ups=0.09, wpb=262144, bsz=512, num_updates=28600, lr=0.00186989, gnorm=0.46, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=341518
2024-02-26 08:42:58 | INFO | train_inner | epoch 005:   1676 / 6784 loss=4.844, ppl=28.72, wps=22658.3, ups=0.09, wpb=262144, bsz=512, num_updates=28700, lr=0.00186663, gnorm=0.477, clip=0, loss_scale=4, train_wall=1157, gb_free=10.7, wall=342675
2024-02-26 09:02:20 | INFO | train_inner | epoch 005:   1776 / 6784 loss=4.841, ppl=28.66, wps=22571.3, ups=0.09, wpb=262144, bsz=512, num_updates=28800, lr=0.00186339, gnorm=0.47, clip=0, loss_scale=4, train_wall=1161, gb_free=10.7, wall=343836
2024-02-26 09:22:19 | INFO | train_inner | epoch 005:   1876 / 6784 loss=4.841, ppl=28.67, wps=21863.6, ups=0.08, wpb=262144, bsz=512, num_updates=28900, lr=0.00186016, gnorm=0.452, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=345035
2024-02-26 09:34:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-26 09:42:23 | INFO | train_inner | epoch 005:   1977 / 6784 loss=4.845, ppl=28.74, wps=21768.1, ups=0.08, wpb=262144, bsz=512, num_updates=29000, lr=0.00185695, gnorm=0.434, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=346240
2024-02-26 10:02:32 | INFO | train_inner | epoch 005:   2077 / 6784 loss=4.843, ppl=28.7, wps=21690.7, ups=0.08, wpb=262144, bsz=512, num_updates=29100, lr=0.00185376, gnorm=0.457, clip=0, loss_scale=4, train_wall=1208, gb_free=10.7, wall=347448
2024-02-26 10:22:27 | INFO | train_inner | epoch 005:   2177 / 6784 loss=4.842, ppl=28.69, wps=21932.6, ups=0.08, wpb=262144, bsz=512, num_updates=29200, lr=0.00185058, gnorm=0.452, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=348643
2024-02-26 10:42:24 | INFO | train_inner | epoch 005:   2277 / 6784 loss=4.838, ppl=28.6, wps=21904.6, ups=0.08, wpb=262144, bsz=512, num_updates=29300, lr=0.00184742, gnorm=0.453, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=349840
2024-02-26 11:02:17 | INFO | train_inner | epoch 005:   2377 / 6784 loss=4.842, ppl=28.68, wps=21963.6, ups=0.08, wpb=262144, bsz=512, num_updates=29400, lr=0.00184428, gnorm=0.453, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=351034
2024-02-26 11:22:29 | INFO | train_inner | epoch 005:   2477 / 6784 loss=4.842, ppl=28.68, wps=21631.9, ups=0.08, wpb=262144, bsz=512, num_updates=29500, lr=0.00184115, gnorm=0.452, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=352246
2024-02-26 11:42:29 | INFO | train_inner | epoch 005:   2577 / 6784 loss=4.838, ppl=28.6, wps=21855.9, ups=0.08, wpb=262144, bsz=512, num_updates=29600, lr=0.00183804, gnorm=0.457, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=353445
2024-02-26 12:01:47 | INFO | train_inner | epoch 005:   2677 / 6784 loss=4.839, ppl=28.63, wps=22622.1, ups=0.09, wpb=262144, bsz=512, num_updates=29700, lr=0.00183494, gnorm=0.421, clip=0, loss_scale=4, train_wall=1159, gb_free=10.7, wall=354604
2024-02-26 12:21:06 | INFO | train_inner | epoch 005:   2777 / 6784 loss=4.835, ppl=28.55, wps=22620.3, ups=0.09, wpb=262144, bsz=512, num_updates=29800, lr=0.00183186, gnorm=0.468, clip=0, loss_scale=4, train_wall=1159, gb_free=10.7, wall=355763
2024-02-26 12:40:17 | INFO | train_inner | epoch 005:   2877 / 6784 loss=4.836, ppl=28.56, wps=22770.7, ups=0.09, wpb=262144, bsz=512, num_updates=29900, lr=0.00182879, gnorm=0.444, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=356914
2024-02-26 12:59:32 | INFO | train_inner | epoch 005:   2977 / 6784 loss=4.837, ppl=28.59, wps=22713.3, ups=0.09, wpb=262144, bsz=512, num_updates=30000, lr=0.00182574, gnorm=0.45, clip=0, loss_scale=4, train_wall=1154, gb_free=10.7, wall=358068
2024-02-26 12:59:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 30000 updates
2024-02-26 12:59:32 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_5_30000.pt
2024-02-26 12:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_5_30000.pt
2024-02-26 13:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_5_30000.pt (epoch 5 @ 30000 updates, score None) (writing took 44.27925328002311 seconds)
2024-02-26 13:19:27 | INFO | train_inner | epoch 005:   3077 / 6784 loss=4.835, ppl=28.55, wps=21926.7, ups=0.08, wpb=262144, bsz=512, num_updates=30100, lr=0.00182271, gnorm=0.444, clip=0, loss_scale=4, train_wall=1151, gb_free=10.7, wall=359264
2024-02-26 13:38:41 | INFO | train_inner | epoch 005:   3177 / 6784 loss=4.839, ppl=28.61, wps=22722.6, ups=0.09, wpb=262144, bsz=512, num_updates=30200, lr=0.00181969, gnorm=0.419, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=360417
2024-02-26 13:57:53 | INFO | train_inner | epoch 005:   3277 / 6784 loss=4.832, ppl=28.48, wps=22748.1, ups=0.09, wpb=262144, bsz=512, num_updates=30300, lr=0.00181668, gnorm=0.478, clip=0, loss_scale=4, train_wall=1152, gb_free=10.7, wall=361570
2024-02-26 14:17:19 | INFO | train_inner | epoch 005:   3377 / 6784 loss=4.832, ppl=28.49, wps=22484.9, ups=0.09, wpb=262144, bsz=512, num_updates=30400, lr=0.00181369, gnorm=0.472, clip=0, loss_scale=4, train_wall=1166, gb_free=10.7, wall=362736
2024-02-26 14:36:47 | INFO | train_inner | epoch 005:   3477 / 6784 loss=4.833, ppl=28.5, wps=22447, ups=0.09, wpb=262144, bsz=512, num_updates=30500, lr=0.00181071, gnorm=0.479, clip=0, loss_scale=4, train_wall=1168, gb_free=10.7, wall=363903
2024-02-26 14:56:14 | INFO | train_inner | epoch 005:   3577 / 6784 loss=4.829, ppl=28.41, wps=22469.6, ups=0.09, wpb=262144, bsz=512, num_updates=30600, lr=0.00180775, gnorm=0.439, clip=0, loss_scale=4, train_wall=1166, gb_free=10.7, wall=365070
2024-02-26 15:15:40 | INFO | train_inner | epoch 005:   3677 / 6784 loss=4.834, ppl=28.53, wps=22475.6, ups=0.09, wpb=262144, bsz=512, num_updates=30700, lr=0.00180481, gnorm=0.515, clip=0, loss_scale=4, train_wall=1166, gb_free=10.7, wall=366236
2024-02-26 15:35:02 | INFO | train_inner | epoch 005:   3777 / 6784 loss=4.833, ppl=28.5, wps=22551.2, ups=0.09, wpb=262144, bsz=512, num_updates=30800, lr=0.00180187, gnorm=0.39, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=367399
2024-02-26 15:54:42 | INFO | train_inner | epoch 005:   3877 / 6784 loss=4.832, ppl=28.48, wps=22212.8, ups=0.08, wpb=262144, bsz=512, num_updates=30900, lr=0.00179896, gnorm=0.45, clip=0, loss_scale=4, train_wall=1180, gb_free=10.7, wall=368579
2024-02-26 16:14:34 | INFO | train_inner | epoch 005:   3977 / 6784 loss=4.83, ppl=28.43, wps=21993.9, ups=0.08, wpb=262144, bsz=512, num_updates=31000, lr=0.00179605, gnorm=0.442, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=369771
2024-02-26 16:34:23 | INFO | train_inner | epoch 005:   4077 / 6784 loss=4.833, ppl=28.51, wps=22058.5, ups=0.08, wpb=262144, bsz=512, num_updates=31100, lr=0.00179316, gnorm=0.427, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=370959
2024-02-26 16:53:48 | INFO | train_inner | epoch 005:   4177 / 6784 loss=4.832, ppl=28.49, wps=22488.1, ups=0.09, wpb=262144, bsz=512, num_updates=31200, lr=0.00179029, gnorm=0.418, clip=0, loss_scale=4, train_wall=1165, gb_free=10.7, wall=372125
2024-02-26 17:13:17 | INFO | train_inner | epoch 005:   4277 / 6784 loss=4.832, ppl=28.49, wps=22432.2, ups=0.09, wpb=262144, bsz=512, num_updates=31300, lr=0.00178743, gnorm=0.486, clip=0, loss_scale=4, train_wall=1168, gb_free=10.7, wall=373294
2024-02-26 17:32:37 | INFO | train_inner | epoch 005:   4377 / 6784 loss=4.833, ppl=28.5, wps=22596.4, ups=0.09, wpb=262144, bsz=512, num_updates=31400, lr=0.00178458, gnorm=0.428, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=374454
2024-02-26 17:52:03 | INFO | train_inner | epoch 005:   4477 / 6784 loss=4.831, ppl=28.47, wps=22479.1, ups=0.09, wpb=262144, bsz=512, num_updates=31500, lr=0.00178174, gnorm=0.438, clip=0, loss_scale=4, train_wall=1166, gb_free=10.7, wall=375620
2024-02-26 18:11:25 | INFO | train_inner | epoch 005:   4577 / 6784 loss=4.829, ppl=28.42, wps=22576.7, ups=0.09, wpb=262144, bsz=512, num_updates=31600, lr=0.00177892, gnorm=0.448, clip=0, loss_scale=4, train_wall=1161, gb_free=10.7, wall=376781
2024-02-26 18:30:35 | INFO | train_inner | epoch 005:   4677 / 6784 loss=4.826, ppl=28.37, wps=22782.8, ups=0.09, wpb=262144, bsz=512, num_updates=31700, lr=0.00177611, gnorm=0.436, clip=0, loss_scale=4, train_wall=1150, gb_free=10.7, wall=377932
2024-02-26 18:49:49 | INFO | train_inner | epoch 005:   4777 / 6784 loss=4.832, ppl=28.48, wps=22720.3, ups=0.09, wpb=262144, bsz=512, num_updates=31800, lr=0.00177332, gnorm=0.458, clip=0, loss_scale=4, train_wall=1154, gb_free=10.7, wall=379085
2024-02-26 19:08:58 | INFO | train_inner | epoch 005:   4877 / 6784 loss=4.83, ppl=28.45, wps=22805, ups=0.09, wpb=262144, bsz=512, num_updates=31900, lr=0.00177054, gnorm=0.415, clip=0, loss_scale=4, train_wall=1149, gb_free=10.7, wall=380235
2024-02-26 19:28:12 | INFO | train_inner | epoch 005:   4977 / 6784 loss=4.829, ppl=28.43, wps=22724.3, ups=0.09, wpb=262144, bsz=512, num_updates=32000, lr=0.00176777, gnorm=0.445, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=381388
2024-02-26 19:47:32 | INFO | train_inner | epoch 005:   5077 / 6784 loss=4.829, ppl=28.42, wps=22602.1, ups=0.09, wpb=262144, bsz=512, num_updates=32100, lr=0.00176501, gnorm=0.451, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=382548
2024-02-26 20:06:52 | INFO | train_inner | epoch 005:   5177 / 6784 loss=4.829, ppl=28.43, wps=22598.5, ups=0.09, wpb=262144, bsz=512, num_updates=32200, lr=0.00176227, gnorm=0.43, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=383708
2024-02-26 20:26:20 | INFO | train_inner | epoch 005:   5277 / 6784 loss=4.834, ppl=28.52, wps=22444.4, ups=0.09, wpb=262144, bsz=512, num_updates=32300, lr=0.00175954, gnorm=0.469, clip=0, loss_scale=4, train_wall=1168, gb_free=10.7, wall=384876
2024-02-26 20:45:44 | INFO | train_inner | epoch 005:   5377 / 6784 loss=4.829, ppl=28.43, wps=22519.4, ups=0.09, wpb=262144, bsz=512, num_updates=32400, lr=0.00175682, gnorm=0.478, clip=0, loss_scale=4, train_wall=1164, gb_free=10.7, wall=386040
2024-02-26 21:04:57 | INFO | train_inner | epoch 005:   5477 / 6784 loss=4.827, ppl=28.38, wps=22735.3, ups=0.09, wpb=262144, bsz=512, num_updates=32500, lr=0.00175412, gnorm=0.438, clip=0, loss_scale=4, train_wall=1153, gb_free=10.7, wall=387193
2024-02-26 21:24:24 | INFO | train_inner | epoch 005:   5577 / 6784 loss=4.829, ppl=28.41, wps=22469.7, ups=0.09, wpb=262142, bsz=512, num_updates=32600, lr=0.00175142, gnorm=0.438, clip=0, loss_scale=4, train_wall=1166, gb_free=10.7, wall=388360
2024-02-26 21:44:12 | INFO | train_inner | epoch 005:   5677 / 6784 loss=4.825, ppl=28.35, wps=22061.6, ups=0.08, wpb=262144, bsz=512, num_updates=32700, lr=0.00174874, gnorm=0.431, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=389548
2024-02-26 22:03:49 | INFO | train_inner | epoch 005:   5777 / 6784 loss=4.831, ppl=28.46, wps=22262.3, ups=0.08, wpb=262144, bsz=512, num_updates=32800, lr=0.00174608, gnorm=0.483, clip=0, loss_scale=4, train_wall=1177, gb_free=10.7, wall=390726
2024-02-26 22:23:38 | INFO | train_inner | epoch 005:   5877 / 6784 loss=4.825, ppl=28.34, wps=22053, ups=0.08, wpb=262144, bsz=512, num_updates=32900, lr=0.00174342, gnorm=0.459, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=391915
2024-02-26 22:42:59 | INFO | train_inner | epoch 005:   5977 / 6784 loss=4.827, ppl=28.38, wps=22589.2, ups=0.09, wpb=262144, bsz=512, num_updates=33000, lr=0.00174078, gnorm=0.448, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=393075
2024-02-26 22:55:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-02-26 23:02:37 | INFO | train_inner | epoch 005:   6078 / 6784 loss=4.825, ppl=28.34, wps=22250.7, ups=0.08, wpb=262144, bsz=512, num_updates=33100, lr=0.00173814, gnorm=0.475, clip=0, loss_scale=4, train_wall=1178, gb_free=10.7, wall=394253
2024-02-26 23:22:08 | INFO | train_inner | epoch 005:   6178 / 6784 loss=4.822, ppl=28.29, wps=22373.2, ups=0.09, wpb=262144, bsz=512, num_updates=33200, lr=0.00173553, gnorm=0.422, clip=0, loss_scale=4, train_wall=1171, gb_free=10.7, wall=395425
2024-02-26 23:41:48 | INFO | train_inner | epoch 005:   6278 / 6784 loss=4.824, ppl=28.32, wps=22213.9, ups=0.08, wpb=262144, bsz=512, num_updates=33300, lr=0.00173292, gnorm=0.431, clip=0, loss_scale=4, train_wall=1180, gb_free=10.7, wall=396605
2024-02-27 00:01:19 | INFO | train_inner | epoch 005:   6378 / 6784 loss=4.826, ppl=28.36, wps=22344.5, ups=0.09, wpb=261571, bsz=510.9, num_updates=33400, lr=0.00173032, gnorm=0.452, clip=0, loss_scale=4, train_wall=1170, gb_free=10.7, wall=397776
2024-02-27 00:20:51 | INFO | train_inner | epoch 005:   6478 / 6784 loss=4.822, ppl=28.28, wps=22368.5, ups=0.09, wpb=262144, bsz=512, num_updates=33500, lr=0.00172774, gnorm=0.462, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=398947
2024-02-27 00:40:23 | INFO | train_inner | epoch 005:   6578 / 6784 loss=4.824, ppl=28.33, wps=22366.7, ups=0.09, wpb=262144, bsz=512, num_updates=33600, lr=0.00172516, gnorm=0.458, clip=0, loss_scale=4, train_wall=1172, gb_free=10.7, wall=400119
2024-02-27 01:00:18 | INFO | train_inner | epoch 005:   6678 / 6784 loss=4.818, ppl=28.2, wps=21937.4, ups=0.08, wpb=262144, bsz=512, num_updates=33700, lr=0.0017226, gnorm=0.419, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=401314
2024-02-27 01:20:04 | INFO | train_inner | epoch 005:   6778 / 6784 loss=4.822, ppl=28.3, wps=22107, ups=0.08, wpb=262144, bsz=512, num_updates=33800, lr=0.00172005, gnorm=0.438, clip=0, loss_scale=4, train_wall=1186, gb_free=10.7, wall=402500
2024-02-27 01:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33806 updates
2024-02-27 01:21:14 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint5.pt
2024-02-27 01:21:30 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint5.pt
2024-02-27 01:22:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint5.pt (epoch 5 @ 33806 updates, score None) (writing took 74.06608664896339 seconds)
2024-02-27 01:22:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-02-27 01:22:28 | INFO | train | epoch 005 | loss 4.835 | ppl 28.54 | wps 22369.4 | ups 0.09 | wpb 262126 | bsz 512 | num_updates 33806 | lr 0.0017199 | gnorm 0.449 | clip 0 | loss_scale 4 | train_wall 79337 | gb_free 10.7 | wall 402645
2024-02-27 01:22:28 | INFO | fairseq.trainer | loading train data for epoch 6
2024-02-27 01:22:29 | INFO | fairseq.data.data_utils | loaded 52,348,000 examples from: ./data/data-bin/5/train
2024-02-27 01:22:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6735
2024-02-27 01:22:30 | INFO | fairseq.trainer | begin training epoch 6
2024-02-27 01:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-27 01:41:20 | INFO | train_inner | epoch 006:     94 / 6735 loss=4.826, ppl=28.36, wps=20533.6, ups=0.08, wpb=262144, bsz=512, num_updates=33900, lr=0.00171751, gnorm=0.426, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=403777
2024-02-27 02:01:50 | INFO | train_inner | epoch 006:    194 / 6735 loss=4.822, ppl=28.29, wps=21327.2, ups=0.08, wpb=262144, bsz=512, num_updates=34000, lr=0.00171499, gnorm=0.43, clip=0, loss_scale=4, train_wall=1229, gb_free=10.7, wall=405006
2024-02-27 02:21:57 | INFO | train_inner | epoch 006:    294 / 6735 loss=4.826, ppl=28.37, wps=21719.9, ups=0.08, wpb=262144, bsz=512, num_updates=34100, lr=0.00171247, gnorm=0.448, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=406213
2024-02-27 02:41:56 | INFO | train_inner | epoch 006:    394 / 6735 loss=4.819, ppl=28.22, wps=21850.7, ups=0.08, wpb=262144, bsz=512, num_updates=34200, lr=0.00170996, gnorm=0.465, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=407413
2024-02-27 03:02:01 | INFO | train_inner | epoch 006:    494 / 6735 loss=4.823, ppl=28.31, wps=21760.3, ups=0.08, wpb=262144, bsz=512, num_updates=34300, lr=0.00170747, gnorm=0.454, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=408617
2024-02-27 03:22:03 | INFO | train_inner | epoch 006:    594 / 6735 loss=4.821, ppl=28.27, wps=21803.6, ups=0.08, wpb=262144, bsz=512, num_updates=34400, lr=0.00170499, gnorm=0.448, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=409820
2024-02-27 03:41:50 | INFO | train_inner | epoch 006:    694 / 6735 loss=4.822, ppl=28.28, wps=22088.1, ups=0.08, wpb=262144, bsz=512, num_updates=34500, lr=0.00170251, gnorm=0.469, clip=0, loss_scale=4, train_wall=1187, gb_free=10.7, wall=411007
2024-02-27 04:01:32 | INFO | train_inner | epoch 006:    794 / 6735 loss=4.825, ppl=28.35, wps=22184.2, ups=0.08, wpb=262144, bsz=512, num_updates=34600, lr=0.00170005, gnorm=0.46, clip=0, loss_scale=4, train_wall=1181, gb_free=10.7, wall=412188
2024-02-27 04:21:12 | INFO | train_inner | epoch 006:    894 / 6735 loss=4.821, ppl=28.27, wps=22216.6, ups=0.08, wpb=262144, bsz=512, num_updates=34700, lr=0.0016976, gnorm=0.437, clip=0, loss_scale=4, train_wall=1180, gb_free=10.7, wall=413368
2024-02-27 04:41:02 | INFO | train_inner | epoch 006:    994 / 6735 loss=4.825, ppl=28.35, wps=22017.2, ups=0.08, wpb=262144, bsz=512, num_updates=34800, lr=0.00169516, gnorm=0.416, clip=0, loss_scale=4, train_wall=1190, gb_free=10.7, wall=414559
2024-02-27 05:01:19 | INFO | train_inner | epoch 006:   1094 / 6735 loss=4.818, ppl=28.2, wps=21498.3, ups=0.08, wpb=261519, bsz=510.8, num_updates=34900, lr=0.00169273, gnorm=0.469, clip=0, loss_scale=4, train_wall=1216, gb_free=10.7, wall=415775
2024-02-27 05:21:30 | INFO | train_inner | epoch 006:   1194 / 6735 loss=4.824, ppl=28.33, wps=21648.5, ups=0.08, wpb=262144, bsz=512, num_updates=35000, lr=0.00169031, gnorm=0.471, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=416986
2024-02-27 05:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 35000 updates
2024-02-27 05:21:30 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_35000.pt
2024-02-27 05:21:45 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_35000.pt
2024-02-27 05:22:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_35000.pt (epoch 6 @ 35000 updates, score None) (writing took 44.49102477100678 seconds)
2024-02-27 05:42:03 | INFO | train_inner | epoch 006:   1294 / 6735 loss=4.82, ppl=28.24, wps=21258, ups=0.08, wpb=262144, bsz=512, num_updates=35100, lr=0.0016879, gnorm=0.439, clip=0, loss_scale=4, train_wall=1188, gb_free=10.7, wall=418219
2024-02-27 06:01:59 | INFO | train_inner | epoch 006:   1394 / 6735 loss=4.819, ppl=28.22, wps=21921.6, ups=0.08, wpb=262144, bsz=512, num_updates=35200, lr=0.0016855, gnorm=0.425, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=419415
2024-02-27 06:21:51 | INFO | train_inner | epoch 006:   1494 / 6735 loss=4.819, ppl=28.23, wps=21988.8, ups=0.08, wpb=262144, bsz=512, num_updates=35300, lr=0.00168311, gnorm=0.452, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=420607
2024-02-27 06:37:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2024-02-27 06:41:55 | INFO | train_inner | epoch 006:   1595 / 6735 loss=4.82, ppl=28.24, wps=21769.8, ups=0.08, wpb=262144, bsz=512, num_updates=35400, lr=0.00168073, gnorm=0.451, clip=0, loss_scale=2, train_wall=1204, gb_free=10.7, wall=421811
2024-02-27 07:01:47 | INFO | train_inner | epoch 006:   1695 / 6735 loss=4.823, ppl=28.3, wps=21994.8, ups=0.08, wpb=262144, bsz=512, num_updates=35500, lr=0.00167836, gnorm=0.451, clip=0, loss_scale=2, train_wall=1192, gb_free=10.7, wall=423003
2024-02-27 07:21:40 | INFO | train_inner | epoch 006:   1795 / 6735 loss=4.815, ppl=28.15, wps=21976.2, ups=0.08, wpb=262144, bsz=512, num_updates=35600, lr=0.001676, gnorm=0.434, clip=0, loss_scale=2, train_wall=1193, gb_free=10.7, wall=424196
2024-02-27 07:41:32 | INFO | train_inner | epoch 006:   1895 / 6735 loss=4.823, ppl=28.31, wps=21993, ups=0.08, wpb=262144, bsz=512, num_updates=35700, lr=0.00167365, gnorm=0.48, clip=0, loss_scale=2, train_wall=1192, gb_free=10.7, wall=425388
2024-02-27 08:01:57 | INFO | train_inner | epoch 006:   1995 / 6735 loss=4.814, ppl=28.13, wps=21390.3, ups=0.08, wpb=262144, bsz=512, num_updates=35800, lr=0.00167132, gnorm=0.424, clip=0, loss_scale=2, train_wall=1225, gb_free=10.7, wall=426614
2024-02-27 08:22:03 | INFO | train_inner | epoch 006:   2095 / 6735 loss=4.82, ppl=28.25, wps=21737.6, ups=0.08, wpb=262144, bsz=512, num_updates=35900, lr=0.00166899, gnorm=0.476, clip=0, loss_scale=2, train_wall=1206, gb_free=10.7, wall=427820
2024-02-27 08:41:50 | INFO | train_inner | epoch 006:   2195 / 6735 loss=4.824, ppl=28.33, wps=22095.6, ups=0.08, wpb=262144, bsz=512, num_updates=36000, lr=0.00166667, gnorm=0.486, clip=0, loss_scale=2, train_wall=1186, gb_free=10.7, wall=429006
2024-02-27 09:01:35 | INFO | train_inner | epoch 006:   2295 / 6735 loss=4.818, ppl=28.2, wps=22112.3, ups=0.08, wpb=262144, bsz=512, num_updates=36100, lr=0.00166436, gnorm=0.456, clip=0, loss_scale=2, train_wall=1185, gb_free=10.7, wall=430192
2024-02-27 09:21:31 | INFO | train_inner | epoch 006:   2395 / 6735 loss=4.818, ppl=28.22, wps=21915.9, ups=0.08, wpb=262144, bsz=512, num_updates=36200, lr=0.00166206, gnorm=0.458, clip=0, loss_scale=2, train_wall=1196, gb_free=10.7, wall=431388
2024-02-27 09:41:13 | INFO | train_inner | epoch 006:   2495 / 6735 loss=4.814, ppl=28.13, wps=22188.7, ups=0.08, wpb=262144, bsz=512, num_updates=36300, lr=0.00165977, gnorm=0.443, clip=0, loss_scale=2, train_wall=1181, gb_free=10.7, wall=432569
2024-02-27 10:00:32 | INFO | train_inner | epoch 006:   2595 / 6735 loss=4.819, ppl=28.23, wps=22615.2, ups=0.09, wpb=262144, bsz=512, num_updates=36400, lr=0.00165748, gnorm=0.439, clip=0, loss_scale=2, train_wall=1159, gb_free=10.7, wall=433728
2024-02-27 10:20:20 | INFO | train_inner | epoch 006:   2695 / 6735 loss=4.815, ppl=28.15, wps=22067.1, ups=0.08, wpb=262144, bsz=512, num_updates=36500, lr=0.00165521, gnorm=0.424, clip=0, loss_scale=2, train_wall=1188, gb_free=10.7, wall=434916
2024-02-27 10:39:49 | INFO | train_inner | epoch 006:   2795 / 6735 loss=4.815, ppl=28.15, wps=22410.1, ups=0.09, wpb=262144, bsz=512, num_updates=36600, lr=0.00165295, gnorm=0.457, clip=0, loss_scale=2, train_wall=1170, gb_free=10.7, wall=436086
2024-02-27 10:59:36 | INFO | train_inner | epoch 006:   2895 / 6735 loss=4.819, ppl=28.23, wps=22091.9, ups=0.08, wpb=262144, bsz=512, num_updates=36700, lr=0.0016507, gnorm=0.475, clip=0, loss_scale=2, train_wall=1186, gb_free=10.7, wall=437273
2024-02-27 11:19:25 | INFO | train_inner | epoch 006:   2995 / 6735 loss=4.817, ppl=28.19, wps=22044.5, ups=0.08, wpb=262144, bsz=512, num_updates=36800, lr=0.00164845, gnorm=0.47, clip=0, loss_scale=2, train_wall=1189, gb_free=10.7, wall=438462
2024-02-27 11:39:20 | INFO | train_inner | epoch 006:   3095 / 6735 loss=4.815, ppl=28.15, wps=21949.1, ups=0.08, wpb=262144, bsz=512, num_updates=36900, lr=0.00164622, gnorm=0.456, clip=0, loss_scale=2, train_wall=1194, gb_free=10.7, wall=439656
2024-02-27 11:59:13 | INFO | train_inner | epoch 006:   3195 / 6735 loss=4.814, ppl=28.12, wps=21974, ups=0.08, wpb=262144, bsz=512, num_updates=37000, lr=0.00164399, gnorm=0.457, clip=0, loss_scale=2, train_wall=1193, gb_free=10.7, wall=440849
2024-02-27 12:18:59 | INFO | train_inner | epoch 006:   3295 / 6735 loss=4.818, ppl=28.2, wps=22093.3, ups=0.08, wpb=262144, bsz=512, num_updates=37100, lr=0.00164177, gnorm=0.421, clip=0, loss_scale=2, train_wall=1186, gb_free=10.7, wall=442036
2024-02-27 12:38:53 | INFO | train_inner | epoch 006:   3395 / 6735 loss=4.812, ppl=28.1, wps=21964.5, ups=0.08, wpb=262144, bsz=512, num_updates=37200, lr=0.00163956, gnorm=0.471, clip=0, loss_scale=2, train_wall=1193, gb_free=10.7, wall=443229
2024-02-27 12:58:37 | INFO | train_inner | epoch 006:   3495 / 6735 loss=4.812, ppl=28.1, wps=22138.6, ups=0.08, wpb=262144, bsz=512, num_updates=37300, lr=0.00163737, gnorm=0.445, clip=0, loss_scale=2, train_wall=1184, gb_free=10.7, wall=444413
2024-02-27 13:18:16 | INFO | train_inner | epoch 006:   3595 / 6735 loss=4.813, ppl=28.1, wps=22224.1, ups=0.08, wpb=262144, bsz=512, num_updates=37400, lr=0.00163517, gnorm=0.452, clip=0, loss_scale=2, train_wall=1179, gb_free=10.7, wall=445593
2024-02-27 13:37:44 | INFO | train_inner | epoch 006:   3695 / 6735 loss=4.812, ppl=28.08, wps=22449.3, ups=0.09, wpb=262144, bsz=512, num_updates=37500, lr=0.00163299, gnorm=0.479, clip=0, loss_scale=2, train_wall=1167, gb_free=10.7, wall=446760
2024-02-27 13:57:18 | INFO | train_inner | epoch 006:   3795 / 6735 loss=4.819, ppl=28.23, wps=22326.7, ups=0.09, wpb=262144, bsz=512, num_updates=37600, lr=0.00163082, gnorm=0.463, clip=0, loss_scale=2, train_wall=1174, gb_free=10.7, wall=447935
2024-02-27 14:16:44 | INFO | train_inner | epoch 006:   3895 / 6735 loss=4.81, ppl=28.06, wps=22476.5, ups=0.09, wpb=262144, bsz=512, num_updates=37700, lr=0.00162866, gnorm=0.421, clip=0, loss_scale=2, train_wall=1166, gb_free=10.7, wall=449101
2024-02-27 14:36:13 | INFO | train_inner | epoch 006:   3995 / 6735 loss=4.813, ppl=28.11, wps=22440, ups=0.09, wpb=262144, bsz=512, num_updates=37800, lr=0.0016265, gnorm=0.441, clip=0, loss_scale=2, train_wall=1168, gb_free=10.7, wall=450269
2024-02-27 14:55:40 | INFO | train_inner | epoch 006:   4095 / 6735 loss=4.81, ppl=28.04, wps=22458.6, ups=0.09, wpb=262144, bsz=512, num_updates=37900, lr=0.00162435, gnorm=0.448, clip=0, loss_scale=2, train_wall=1167, gb_free=10.7, wall=451436
2024-02-27 15:15:15 | INFO | train_inner | epoch 006:   4195 / 6735 loss=4.813, ppl=28.11, wps=22306.6, ups=0.09, wpb=262144, bsz=512, num_updates=38000, lr=0.00162221, gnorm=0.462, clip=0, loss_scale=2, train_wall=1175, gb_free=10.7, wall=452611
2024-02-27 15:34:46 | INFO | train_inner | epoch 006:   4295 / 6735 loss=4.817, ppl=28.18, wps=22394.5, ups=0.09, wpb=262144, bsz=512, num_updates=38100, lr=0.00162008, gnorm=0.425, clip=0, loss_scale=2, train_wall=1170, gb_free=10.7, wall=453782
2024-02-27 15:54:19 | INFO | train_inner | epoch 006:   4395 / 6735 loss=4.815, ppl=28.15, wps=22335.4, ups=0.09, wpb=262140, bsz=512, num_updates=38200, lr=0.00161796, gnorm=0.414, clip=0, loss_scale=2, train_wall=1173, gb_free=10.7, wall=454956
2024-02-27 16:13:51 | INFO | train_inner | epoch 006:   4495 / 6735 loss=4.815, ppl=28.15, wps=22380, ups=0.09, wpb=262144, bsz=512, num_updates=38300, lr=0.00161585, gnorm=0.478, clip=0, loss_scale=2, train_wall=1171, gb_free=10.7, wall=456127
2024-02-27 16:34:58 | INFO | train_inner | epoch 006:   4595 / 6735 loss=4.813, ppl=28.1, wps=20682.3, ups=0.08, wpb=262144, bsz=512, num_updates=38400, lr=0.00161374, gnorm=0.408, clip=0, loss_scale=2, train_wall=1267, gb_free=10.7, wall=457394
2024-02-27 16:55:39 | INFO | train_inner | epoch 006:   4695 / 6735 loss=4.814, ppl=28.13, wps=21125.3, ups=0.08, wpb=262144, bsz=512, num_updates=38500, lr=0.00161165, gnorm=0.451, clip=0, loss_scale=2, train_wall=1241, gb_free=10.7, wall=458635
2024-02-27 17:15:50 | INFO | train_inner | epoch 006:   4795 / 6735 loss=4.813, ppl=28.11, wps=21648.2, ups=0.08, wpb=262144, bsz=512, num_updates=38600, lr=0.00160956, gnorm=0.47, clip=0, loss_scale=2, train_wall=1211, gb_free=10.7, wall=459846
2024-02-27 17:36:46 | INFO | train_inner | epoch 006:   4895 / 6735 loss=4.807, ppl=27.99, wps=20867.2, ups=0.08, wpb=262144, bsz=512, num_updates=38700, lr=0.00160748, gnorm=0.426, clip=0, loss_scale=2, train_wall=1256, gb_free=10.7, wall=461103
2024-02-27 17:57:30 | INFO | train_inner | epoch 006:   4995 / 6735 loss=4.814, ppl=28.12, wps=21067.4, ups=0.08, wpb=262144, bsz=512, num_updates=38800, lr=0.0016054, gnorm=0.444, clip=0, loss_scale=2, train_wall=1244, gb_free=10.7, wall=462347
2024-02-27 18:18:22 | INFO | train_inner | epoch 006:   5095 / 6735 loss=4.811, ppl=28.08, wps=20943.9, ups=0.08, wpb=262144, bsz=512, num_updates=38900, lr=0.00160334, gnorm=0.47, clip=0, loss_scale=2, train_wall=1251, gb_free=10.7, wall=463599
2024-02-27 18:40:01 | INFO | train_inner | epoch 006:   5195 / 6735 loss=4.811, ppl=28.06, wps=20185.4, ups=0.08, wpb=262144, bsz=512, num_updates=39000, lr=0.00160128, gnorm=0.419, clip=0, loss_scale=2, train_wall=1298, gb_free=10.7, wall=464897
2024-02-27 19:01:53 | INFO | train_inner | epoch 006:   5295 / 6735 loss=4.805, ppl=27.95, wps=19975.6, ups=0.08, wpb=262144, bsz=512, num_updates=39100, lr=0.00159923, gnorm=0.459, clip=0, loss_scale=2, train_wall=1312, gb_free=10.7, wall=466210
2024-02-27 19:23:27 | INFO | train_inner | epoch 006:   5395 / 6735 loss=4.813, ppl=28.1, wps=20256.4, ups=0.08, wpb=262144, bsz=512, num_updates=39200, lr=0.00159719, gnorm=0.471, clip=0, loss_scale=2, train_wall=1294, gb_free=10.7, wall=467504
2024-02-27 19:44:49 | INFO | train_inner | epoch 006:   5495 / 6735 loss=4.816, ppl=28.17, wps=20448.4, ups=0.08, wpb=262144, bsz=512, num_updates=39300, lr=0.00159516, gnorm=0.508, clip=0, loss_scale=2, train_wall=1282, gb_free=10.7, wall=468786
2024-02-27 20:06:05 | INFO | train_inner | epoch 006:   5595 / 6735 loss=4.808, ppl=28, wps=20547.6, ups=0.08, wpb=262144, bsz=512, num_updates=39400, lr=0.00159313, gnorm=0.445, clip=0, loss_scale=2, train_wall=1276, gb_free=10.7, wall=470061
2024-02-27 20:27:22 | INFO | train_inner | epoch 006:   5695 / 6735 loss=4.808, ppl=28.01, wps=20530.4, ups=0.08, wpb=262144, bsz=512, num_updates=39500, lr=0.00159111, gnorm=0.437, clip=0, loss_scale=4, train_wall=1277, gb_free=10.7, wall=471338
2024-02-27 20:47:41 | INFO | train_inner | epoch 006:   5795 / 6735 loss=4.81, ppl=28.06, wps=21494.9, ups=0.08, wpb=262144, bsz=512, num_updates=39600, lr=0.0015891, gnorm=0.467, clip=0, loss_scale=4, train_wall=1219, gb_free=10.7, wall=472558
2024-02-27 21:07:23 | INFO | train_inner | epoch 006:   5895 / 6735 loss=4.81, ppl=28.06, wps=22177, ups=0.08, wpb=262144, bsz=512, num_updates=39700, lr=0.0015871, gnorm=0.432, clip=0, loss_scale=4, train_wall=1182, gb_free=10.7, wall=473740
2024-02-27 21:26:55 | INFO | train_inner | epoch 006:   5995 / 6735 loss=4.812, ppl=28.09, wps=22326.4, ups=0.09, wpb=261571, bsz=510.9, num_updates=39800, lr=0.00158511, gnorm=0.461, clip=0, loss_scale=4, train_wall=1171, gb_free=10.7, wall=474912
2024-02-27 21:46:15 | INFO | train_inner | epoch 006:   6095 / 6735 loss=4.806, ppl=27.96, wps=22590.1, ups=0.09, wpb=262144, bsz=512, num_updates=39900, lr=0.00158312, gnorm=0.473, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=476072
2024-02-27 22:05:38 | INFO | train_inner | epoch 006:   6195 / 6735 loss=4.801, ppl=27.88, wps=22547.5, ups=0.09, wpb=262144, bsz=512, num_updates=40000, lr=0.00158114, gnorm=0.454, clip=0, loss_scale=4, train_wall=1162, gb_free=10.7, wall=477235
2024-02-27 22:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40000 updates
2024-02-27 22:05:38 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_40000.pt
2024-02-27 22:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_40000.pt
2024-02-27 22:06:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_6_40000.pt (epoch 6 @ 40000 updates, score None) (writing took 44.08410663390532 seconds)
2024-02-27 22:25:43 | INFO | train_inner | epoch 006:   6295 / 6735 loss=4.806, ppl=27.97, wps=21763.6, ups=0.08, wpb=262144, bsz=512, num_updates=40100, lr=0.00157917, gnorm=0.464, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=478439
2024-02-27 22:45:03 | INFO | train_inner | epoch 006:   6395 / 6735 loss=4.807, ppl=28, wps=22586.3, ups=0.09, wpb=262144, bsz=512, num_updates=40200, lr=0.0015772, gnorm=0.521, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=479600
2024-02-27 23:04:26 | INFO | train_inner | epoch 006:   6495 / 6735 loss=4.809, ppl=28.04, wps=22538.3, ups=0.09, wpb=262144, bsz=512, num_updates=40300, lr=0.00157524, gnorm=0.454, clip=0, loss_scale=4, train_wall=1163, gb_free=10.7, wall=480763
2024-02-27 23:23:44 | INFO | train_inner | epoch 006:   6595 / 6735 loss=4.804, ppl=27.93, wps=22642.1, ups=0.09, wpb=262144, bsz=512, num_updates=40400, lr=0.00157329, gnorm=0.452, clip=0, loss_scale=4, train_wall=1158, gb_free=10.7, wall=481921
2024-02-27 23:43:04 | INFO | train_inner | epoch 006:   6695 / 6735 loss=4.802, ppl=27.9, wps=22600.4, ups=0.09, wpb=262144, bsz=512, num_updates=40500, lr=0.00157135, gnorm=0.447, clip=0, loss_scale=4, train_wall=1160, gb_free=10.7, wall=483081
2024-02-27 23:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40540 updates
2024-02-27 23:50:47 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint6.pt
2024-02-27 23:51:03 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint6.pt
2024-02-27 23:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint6.pt (epoch 6 @ 40540 updates, score None) (writing took 73.21595538198017 seconds)
2024-02-27 23:52:00 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-02-27 23:52:00 | INFO | train | epoch 006 | loss 4.815 | ppl 28.15 | wps 21798.7 | ups 0.08 | wpb 262116 | bsz 511.9 | num_updates 40540 | lr 0.00157057 | gnorm 0.452 | clip 0 | loss_scale 4 | train_wall 80792 | gb_free 10.7 | wall 483617
2024-02-27 23:52:00 | INFO | fairseq.trainer | loading train data for epoch 7
2024-02-27 23:52:01 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-02-27 23:52:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-02-27 23:52:02 | INFO | fairseq.trainer | begin training epoch 7
2024-02-27 23:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-28 00:03:44 | INFO | train_inner | epoch 007:     60 / 6796 loss=4.807, ppl=28, wps=21087.5, ups=0.08, wpb=261489, bsz=510.7, num_updates=40600, lr=0.00156941, gnorm=0.467, clip=0, loss_scale=4, train_wall=1165, gb_free=10.7, wall=484321
2024-02-28 00:03:44 | INFO | fairseq_cli.train | Stopping training due to num_updates: 40600 >= max_update: 40600
2024-02-28 00:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 40600 updates
2024-02-28 00:03:44 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_last.pt
2024-02-28 00:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_last.pt
2024-02-28 00:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd/checkpoint_last.pt (epoch 7 @ 40600 updates, score None) (writing took 15.480709430994466 seconds)
2024-02-28 00:04:00 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-02-28 00:04:00 | INFO | train | epoch 007 | loss 4.808 | ppl 28 | wps 21873 | ups 0.08 | wpb 262144 | bsz 512 | num_updates 40600 | lr 0.00156941 | gnorm 0.467 | clip 0 | loss_scale 4 | train_wall 702 | gb_free 10.7 | wall 484336
2024-02-28 00:04:00 | INFO | fairseq_cli.train | done training in 484333.8 seconds
Amaitu da
