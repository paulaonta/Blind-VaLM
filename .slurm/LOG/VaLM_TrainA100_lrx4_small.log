Hasi da
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=1 on rank 1
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=5 on rank 5
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=6 on rank 6
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=3 on rank 3
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=4 on rank 4
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=7 on rank 7
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | setting CUDA device=2 on rank 2
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-08-04 15:53:39 | INFO | fairseq.distributed.utils | initialized host durunda as rank 0
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 7): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 7
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 2
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 6): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 6
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 4): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 4
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 1
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 5): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 5
2024-08-04 15:53:40 | INFO | fairseq.distributed.utils | initialized host durunda as rank 3
NCCL version 2.18.1+cuda12.1
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-08-04 15:53:51 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'VaLM-baseline', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40600, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './CHECKPOINTS/checkpoint_valmA100_40600upd_small', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt2_small', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False, 'use_knn_datastore': True, 'load_knn_datastore': False, 'dstore_fp16': False, 'use_gpu_to_search': False, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 8, 'probe': 32, 'dstore_filename': 'data/datastore', 'use_joint_attention': True, 'joint_layer_index': 2}, 'task': {'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-08-04 15:53:51 | INFO | fairseq.tasks.language_modeling | dictionary: 49412 types
2024-08-04 15:54:00 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(49412, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-21): 22 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (22): TransformerDecoderLayerwithJointAttention(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (img_k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (img_v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (img_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (23): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=49412, bias=False)
  )
)
2024-08-04 15:54:00 | INFO | fairseq_cli.train | task: LanguageModelingTask
2024-08-04 15:54:00 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2024-08-04 15:54:00 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2024-08-04 15:54:00 | INFO | fairseq_cli.train | num. shared model params: 355,010,560 (num. trained: 355,010,560)
2024-08-04 15:54:00 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-08-04 15:54:00 | INFO | fairseq.data.data_utils | loaded 5,000 examples from: ./data/data-bin/0/valid
2024-08-04 15:54:00 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-08-04 15:54:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   4: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   5: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   6: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | rank   7: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-08-04 15:54:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2024-08-04 15:54:15 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2024-08-04 15:54:15 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2024-08-04 15:54:15 | INFO | fairseq.trainer | Preparing to load checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_last.pt
2024-08-04 15:54:15 | INFO | fairseq.trainer | No existing checkpoint found ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_last.pt
2024-08-04 15:54:15 | INFO | fairseq.trainer | loading train data for epoch 1
2024-08-04 15:54:15 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-08-04 15:54:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-08-04 15:54:19 | INFO | fairseq.trainer | begin training epoch 1
2024-08-04 15:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-04 15:54:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2024-08-04 15:54:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2024-08-04 15:54:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-08-04 16:05:34 | INFO | train_inner | epoch 001:    103 / 6796 loss=12.407, ppl=5429.66, wps=40233.3, ups=0.15, wpb=262144, bsz=512, num_updates=100, lr=5.00975e-05, gnorm=16.93, clip=100, loss_scale=16, train_wall=675, gb_free=10.3, wall=680
2024-08-04 16:16:29 | INFO | train_inner | epoch 001:    203 / 6796 loss=9.143, ppl=565.26, wps=40047.5, ups=0.15, wpb=262144, bsz=512, num_updates=200, lr=0.000100095, gnorm=4.587, clip=100, loss_scale=16, train_wall=654, gb_free=10.3, wall=1334
2024-08-04 16:27:22 | INFO | train_inner | epoch 001:    303 / 6796 loss=8.425, ppl=343.81, wps=40150.1, ups=0.15, wpb=262144, bsz=512, num_updates=300, lr=0.000150093, gnorm=4.854, clip=100, loss_scale=16, train_wall=653, gb_free=10.3, wall=1987
2024-08-04 16:38:10 | INFO | train_inner | epoch 001:    403 / 6796 loss=8.042, ppl=263.62, wps=40447.8, ups=0.15, wpb=262144, bsz=512, num_updates=400, lr=0.00020009, gnorm=5.198, clip=100, loss_scale=16, train_wall=648, gb_free=10.3, wall=2635
2024-08-04 16:49:07 | INFO | train_inner | epoch 001:    503 / 6796 loss=7.682, ppl=205.41, wps=39922.5, ups=0.15, wpb=262144, bsz=512, num_updates=500, lr=0.000250088, gnorm=4.562, clip=100, loss_scale=16, train_wall=656, gb_free=10.3, wall=3292
2024-08-04 17:00:01 | INFO | train_inner | epoch 001:    603 / 6796 loss=7.327, ppl=160.59, wps=40069.7, ups=0.15, wpb=262144, bsz=512, num_updates=600, lr=0.000300085, gnorm=3.945, clip=99, loss_scale=16, train_wall=654, gb_free=10.3, wall=3946
2024-08-04 17:10:54 | INFO | train_inner | epoch 001:    703 / 6796 loss=7.016, ppl=129.4, wps=40104.7, ups=0.15, wpb=262144, bsz=512, num_updates=700, lr=0.000350083, gnorm=3.425, clip=100, loss_scale=16, train_wall=653, gb_free=10.3, wall=4600
2024-08-04 17:21:45 | INFO | train_inner | epoch 001:    803 / 6796 loss=6.763, ppl=108.59, wps=40319.5, ups=0.15, wpb=262144, bsz=512, num_updates=800, lr=0.00040008, gnorm=3.03, clip=100, loss_scale=16, train_wall=650, gb_free=10.3, wall=5250
2024-08-04 17:32:42 | INFO | train_inner | epoch 001:    903 / 6796 loss=6.563, ppl=94.57, wps=39848.2, ups=0.15, wpb=262144, bsz=512, num_updates=900, lr=0.000450078, gnorm=2.776, clip=97, loss_scale=16, train_wall=658, gb_free=10.3, wall=5908
2024-08-04 17:43:34 | INFO | train_inner | epoch 001:   1003 / 6796 loss=6.375, ppl=82.98, wps=40219.9, ups=0.15, wpb=262141, bsz=512, num_updates=1000, lr=0.000500075, gnorm=2.518, clip=89, loss_scale=16, train_wall=651, gb_free=10.3, wall=6560
2024-08-04 17:54:27 | INFO | train_inner | epoch 001:   1103 / 6796 loss=6.217, ppl=74.39, wps=40176.2, ups=0.15, wpb=262144, bsz=512, num_updates=1100, lr=0.000550072, gnorm=2.378, clip=82, loss_scale=16, train_wall=652, gb_free=10.3, wall=7212
2024-08-04 18:05:22 | INFO | train_inner | epoch 001:   1203 / 6796 loss=6.076, ppl=67.46, wps=40023.1, ups=0.15, wpb=262144, bsz=512, num_updates=1200, lr=0.00060007, gnorm=2.11, clip=61, loss_scale=16, train_wall=655, gb_free=10.3, wall=7867
2024-08-04 18:16:17 | INFO | train_inner | epoch 001:   1303 / 6796 loss=5.953, ppl=61.95, wps=40033.1, ups=0.15, wpb=262144, bsz=512, num_updates=1300, lr=0.000650068, gnorm=2.018, clip=51, loss_scale=16, train_wall=655, gb_free=10.3, wall=8522
2024-08-04 18:27:11 | INFO | train_inner | epoch 001:   1403 / 6796 loss=5.861, ppl=58.13, wps=40081.6, ups=0.15, wpb=262144, bsz=512, num_updates=1400, lr=0.000700065, gnorm=1.867, clip=24, loss_scale=16, train_wall=654, gb_free=10.3, wall=9176
2024-08-04 18:38:04 | INFO | train_inner | epoch 001:   1503 / 6796 loss=5.773, ppl=54.68, wps=40145.1, ups=0.15, wpb=262144, bsz=512, num_updates=1500, lr=0.000750062, gnorm=1.768, clip=17, loss_scale=16, train_wall=653, gb_free=10.3, wall=9829
2024-08-04 18:48:54 | INFO | train_inner | epoch 001:   1603 / 6796 loss=5.709, ppl=52.31, wps=40303.2, ups=0.15, wpb=262144, bsz=512, num_updates=1600, lr=0.00080006, gnorm=1.702, clip=9, loss_scale=16, train_wall=650, gb_free=10.3, wall=10479
2024-08-04 18:59:43 | INFO | train_inner | epoch 001:   1703 / 6796 loss=5.67, ppl=50.92, wps=40367.9, ups=0.15, wpb=262144, bsz=512, num_updates=1700, lr=0.000850058, gnorm=1.877, clip=21, loss_scale=16, train_wall=649, gb_free=10.3, wall=11129
2024-08-04 19:10:38 | INFO | train_inner | epoch 001:   1803 / 6796 loss=5.595, ppl=48.33, wps=40018.6, ups=0.15, wpb=262144, bsz=512, num_updates=1800, lr=0.000900055, gnorm=1.428, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=11784
2024-08-04 19:21:34 | INFO | train_inner | epoch 001:   1903 / 6796 loss=5.549, ppl=46.82, wps=39984.3, ups=0.15, wpb=262144, bsz=512, num_updates=1900, lr=0.000950053, gnorm=1.513, clip=5, loss_scale=16, train_wall=655, gb_free=10.3, wall=12439
2024-08-04 19:32:29 | INFO | train_inner | epoch 001:   2003 / 6796 loss=5.508, ppl=45.52, wps=39962, ups=0.15, wpb=261857, bsz=511.4, num_updates=2000, lr=0.00100005, gnorm=1.422, clip=2, loss_scale=16, train_wall=655, gb_free=10.3, wall=13095
2024-08-04 19:37:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-08-04 19:43:33 | INFO | train_inner | epoch 001:   2104 / 6796 loss=5.474, ppl=44.44, wps=39527.1, ups=0.15, wpb=262144, bsz=512, num_updates=2100, lr=0.00105005, gnorm=1.414, clip=3, loss_scale=16, train_wall=663, gb_free=10.3, wall=13758
2024-08-04 19:54:27 | INFO | train_inner | epoch 001:   2204 / 6796 loss=5.438, ppl=43.36, wps=40031.8, ups=0.15, wpb=262144, bsz=512, num_updates=2200, lr=0.00110005, gnorm=1.384, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=14413
2024-08-04 20:05:18 | INFO | train_inner | epoch 001:   2304 / 6796 loss=5.408, ppl=42.46, wps=40272.1, ups=0.15, wpb=262144, bsz=512, num_updates=2300, lr=0.00115004, gnorm=1.372, clip=2, loss_scale=16, train_wall=651, gb_free=10.3, wall=15064
2024-08-04 20:16:07 | INFO | train_inner | epoch 001:   2404 / 6796 loss=5.384, ppl=41.76, wps=40397.4, ups=0.15, wpb=262144, bsz=512, num_updates=2400, lr=0.00120004, gnorm=1.345, clip=0, loss_scale=16, train_wall=649, gb_free=10.3, wall=15713
2024-08-04 20:27:00 | INFO | train_inner | epoch 001:   2504 / 6796 loss=5.359, ppl=41.05, wps=40170.7, ups=0.15, wpb=262144, bsz=512, num_updates=2500, lr=0.00125004, gnorm=1.295, clip=1, loss_scale=16, train_wall=652, gb_free=10.3, wall=16365
2024-08-04 20:37:57 | INFO | train_inner | epoch 001:   2604 / 6796 loss=5.33, ppl=40.22, wps=39861.5, ups=0.15, wpb=262144, bsz=512, num_updates=2600, lr=0.00130004, gnorm=1.291, clip=0, loss_scale=16, train_wall=657, gb_free=10.3, wall=17023
2024-08-04 20:48:51 | INFO | train_inner | epoch 001:   2704 / 6796 loss=5.312, ppl=39.72, wps=40120.5, ups=0.15, wpb=262144, bsz=512, num_updates=2700, lr=0.00135003, gnorm=1.25, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=17676
2024-08-04 20:59:47 | INFO | train_inner | epoch 001:   2804 / 6796 loss=5.285, ppl=39, wps=39971.4, ups=0.15, wpb=262144, bsz=512, num_updates=2800, lr=0.00140003, gnorm=1.187, clip=0, loss_scale=16, train_wall=656, gb_free=10.3, wall=18332
2024-08-04 21:10:39 | INFO | train_inner | epoch 001:   2904 / 6796 loss=5.274, ppl=38.69, wps=40162.2, ups=0.15, wpb=262144, bsz=512, num_updates=2900, lr=0.00145003, gnorm=1.187, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=18985
2024-08-04 21:21:29 | INFO | train_inner | epoch 001:   3004 / 6796 loss=5.254, ppl=38.15, wps=40355.9, ups=0.15, wpb=262144, bsz=512, num_updates=3000, lr=0.00150003, gnorm=1.146, clip=0, loss_scale=16, train_wall=649, gb_free=10.3, wall=19634
2024-08-04 21:32:23 | INFO | train_inner | epoch 001:   3104 / 6796 loss=5.237, ppl=37.72, wps=40060.5, ups=0.15, wpb=262144, bsz=512, num_updates=3100, lr=0.00155002, gnorm=1.115, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=20289
2024-08-04 21:43:26 | INFO | train_inner | epoch 001:   3204 / 6796 loss=5.223, ppl=37.35, wps=39539.5, ups=0.15, wpb=262144, bsz=512, num_updates=3200, lr=0.00160002, gnorm=1.07, clip=0, loss_scale=16, train_wall=663, gb_free=10.3, wall=20952
2024-08-04 21:54:29 | INFO | train_inner | epoch 001:   3304 / 6796 loss=5.203, ppl=36.83, wps=39557.5, ups=0.15, wpb=262144, bsz=512, num_updates=3300, lr=0.00165002, gnorm=1.041, clip=0, loss_scale=16, train_wall=662, gb_free=10.3, wall=21614
2024-08-04 22:05:29 | INFO | train_inner | epoch 001:   3404 / 6796 loss=5.194, ppl=36.6, wps=39710.1, ups=0.15, wpb=262144, bsz=512, num_updates=3400, lr=0.00170002, gnorm=1.013, clip=0, loss_scale=16, train_wall=660, gb_free=10.3, wall=22274
2024-08-04 22:16:20 | INFO | train_inner | epoch 001:   3504 / 6796 loss=5.181, ppl=36.27, wps=40289, ups=0.15, wpb=262144, bsz=512, num_updates=3500, lr=0.00175001, gnorm=0.998, clip=0, loss_scale=16, train_wall=650, gb_free=10.3, wall=22925
2024-08-04 22:27:15 | INFO | train_inner | epoch 001:   3604 / 6796 loss=5.167, ppl=35.93, wps=40023.1, ups=0.15, wpb=262144, bsz=512, num_updates=3600, lr=0.00180001, gnorm=0.947, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=23580
2024-08-04 22:38:08 | INFO | train_inner | epoch 001:   3704 / 6796 loss=5.155, ppl=35.64, wps=40112.3, ups=0.15, wpb=262144, bsz=512, num_updates=3700, lr=0.00185001, gnorm=0.941, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=24234
2024-08-04 22:48:58 | INFO | train_inner | epoch 001:   3804 / 6796 loss=5.14, ppl=35.26, wps=40349.9, ups=0.15, wpb=262144, bsz=512, num_updates=3800, lr=0.00190001, gnorm=0.89, clip=0, loss_scale=16, train_wall=649, gb_free=10.3, wall=24883
2024-08-04 22:59:51 | INFO | train_inner | epoch 001:   3904 / 6796 loss=5.134, ppl=35.12, wps=40127.9, ups=0.15, wpb=261852, bsz=511.4, num_updates=3900, lr=0.00195, gnorm=0.873, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=25536
2024-08-04 23:10:45 | INFO | train_inner | epoch 001:   4004 / 6796 loss=5.121, ppl=34.81, wps=40084.6, ups=0.15, wpb=262144, bsz=512, num_updates=4000, lr=0.002, gnorm=0.836, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=26190
2024-08-04 23:21:37 | INFO | train_inner | epoch 001:   4104 / 6796 loss=5.11, ppl=34.54, wps=40192.1, ups=0.15, wpb=262144, bsz=512, num_updates=4100, lr=0.00197546, gnorm=0.814, clip=0, loss_scale=32, train_wall=652, gb_free=10.3, wall=26842
2024-08-04 23:32:28 | INFO | train_inner | epoch 001:   4204 / 6796 loss=5.093, ppl=34.14, wps=40238.1, ups=0.15, wpb=262144, bsz=512, num_updates=4200, lr=0.0019518, gnorm=0.769, clip=0, loss_scale=32, train_wall=651, gb_free=10.3, wall=27494
2024-08-04 23:43:24 | INFO | train_inner | epoch 001:   4304 / 6796 loss=5.082, ppl=33.88, wps=39957, ups=0.15, wpb=262144, bsz=512, num_updates=4300, lr=0.00192897, gnorm=0.74, clip=0, loss_scale=32, train_wall=656, gb_free=10.3, wall=28150
2024-08-04 23:54:24 | INFO | train_inner | epoch 001:   4404 / 6796 loss=5.065, ppl=33.48, wps=39749, ups=0.15, wpb=262144, bsz=512, num_updates=4400, lr=0.00190693, gnorm=0.719, clip=0, loss_scale=32, train_wall=659, gb_free=10.3, wall=28809
2024-08-05 00:05:18 | INFO | train_inner | epoch 001:   4504 / 6796 loss=5.048, ppl=33.07, wps=40079.7, ups=0.15, wpb=262144, bsz=512, num_updates=4500, lr=0.00188562, gnorm=0.693, clip=0, loss_scale=32, train_wall=654, gb_free=10.3, wall=29463
2024-08-05 00:16:11 | INFO | train_inner | epoch 001:   4604 / 6796 loss=5.035, ppl=32.79, wps=40161.2, ups=0.15, wpb=262144, bsz=512, num_updates=4600, lr=0.00186501, gnorm=0.692, clip=0, loss_scale=32, train_wall=652, gb_free=10.3, wall=30116
2024-08-05 00:27:03 | INFO | train_inner | epoch 001:   4704 / 6796 loss=5.026, ppl=32.59, wps=40201.2, ups=0.15, wpb=262144, bsz=512, num_updates=4700, lr=0.00184506, gnorm=0.661, clip=0, loss_scale=32, train_wall=652, gb_free=10.3, wall=30768
2024-08-05 00:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-08-05 00:38:05 | INFO | train_inner | epoch 001:   4805 / 6796 loss=5.009, ppl=32.2, wps=39552.4, ups=0.15, wpb=262144, bsz=512, num_updates=4800, lr=0.00182574, gnorm=0.659, clip=0, loss_scale=16, train_wall=662, gb_free=10.3, wall=31431
2024-08-05 00:49:01 | INFO | train_inner | epoch 001:   4905 / 6796 loss=5.002, ppl=32.04, wps=39988.3, ups=0.15, wpb=262144, bsz=512, num_updates=4900, lr=0.00180702, gnorm=0.631, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=32086
2024-08-05 00:59:55 | INFO | train_inner | epoch 001:   5005 / 6796 loss=4.991, ppl=31.81, wps=40113.6, ups=0.15, wpb=262144, bsz=512, num_updates=5000, lr=0.00178885, gnorm=0.623, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=32740
2024-08-05 01:10:44 | INFO | train_inner | epoch 001:   5105 / 6796 loss=4.974, ppl=31.42, wps=40340.5, ups=0.15, wpb=262144, bsz=512, num_updates=5100, lr=0.00177123, gnorm=0.616, clip=0, loss_scale=16, train_wall=650, gb_free=10.3, wall=33390
2024-08-05 01:21:37 | INFO | train_inner | epoch 001:   5205 / 6796 loss=4.965, ppl=31.22, wps=40164.5, ups=0.15, wpb=262144, bsz=512, num_updates=5200, lr=0.00175412, gnorm=0.607, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=34042
2024-08-05 01:32:27 | INFO | train_inner | epoch 001:   5305 / 6796 loss=4.963, ppl=31.19, wps=40311.3, ups=0.15, wpb=262144, bsz=512, num_updates=5300, lr=0.00173749, gnorm=0.601, clip=0, loss_scale=16, train_wall=650, gb_free=10.3, wall=34693
2024-08-05 01:43:21 | INFO | train_inner | epoch 001:   5405 / 6796 loss=4.943, ppl=30.76, wps=40097.9, ups=0.15, wpb=262144, bsz=512, num_updates=5400, lr=0.00172133, gnorm=0.589, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=35346
2024-08-05 01:54:14 | INFO | train_inner | epoch 001:   5505 / 6796 loss=4.935, ppl=30.6, wps=40141, ups=0.15, wpb=262144, bsz=512, num_updates=5500, lr=0.00170561, gnorm=0.577, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=35999
2024-08-05 02:05:10 | INFO | train_inner | epoch 001:   5605 / 6796 loss=4.933, ppl=30.56, wps=39997.4, ups=0.15, wpb=262144, bsz=512, num_updates=5600, lr=0.00169031, gnorm=0.578, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=36655
2024-08-05 02:16:09 | INFO | train_inner | epoch 001:   5705 / 6796 loss=4.923, ppl=30.34, wps=39750, ups=0.15, wpb=262144, bsz=512, num_updates=5700, lr=0.00167542, gnorm=0.571, clip=0, loss_scale=16, train_wall=659, gb_free=10.3, wall=37314
2024-08-05 02:26:59 | INFO | train_inner | epoch 001:   5805 / 6796 loss=4.917, ppl=30.21, wps=40333.7, ups=0.15, wpb=262144, bsz=512, num_updates=5800, lr=0.00166091, gnorm=0.576, clip=0, loss_scale=16, train_wall=650, gb_free=10.3, wall=37964
2024-08-05 02:37:50 | INFO | train_inner | epoch 001:   5905 / 6796 loss=4.906, ppl=29.99, wps=40284.6, ups=0.15, wpb=262144, bsz=512, num_updates=5900, lr=0.00164677, gnorm=0.565, clip=0, loss_scale=16, train_wall=650, gb_free=10.3, wall=38615
2024-08-05 02:48:42 | INFO | train_inner | epoch 001:   6005 / 6796 loss=4.901, ppl=29.88, wps=40216.3, ups=0.15, wpb=262144, bsz=512, num_updates=6000, lr=0.00163299, gnorm=0.557, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=39267
2024-08-05 02:59:36 | INFO | train_inner | epoch 001:   6105 / 6796 loss=4.894, ppl=29.74, wps=40067.7, ups=0.15, wpb=262144, bsz=512, num_updates=6100, lr=0.00161955, gnorm=0.537, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=39921
2024-08-05 03:10:28 | INFO | train_inner | epoch 001:   6205 / 6796 loss=4.887, ppl=29.59, wps=40198.1, ups=0.15, wpb=262144, bsz=512, num_updates=6200, lr=0.00160644, gnorm=0.544, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=40573
2024-08-05 03:21:16 | INFO | train_inner | epoch 001:   6305 / 6796 loss=4.881, ppl=29.46, wps=40427.4, ups=0.15, wpb=262144, bsz=512, num_updates=6300, lr=0.00159364, gnorm=0.535, clip=0, loss_scale=16, train_wall=648, gb_free=10.3, wall=41222
2024-08-05 03:32:07 | INFO | train_inner | epoch 001:   6405 / 6796 loss=4.874, ppl=29.32, wps=40269.3, ups=0.15, wpb=262144, bsz=512, num_updates=6400, lr=0.00158114, gnorm=0.535, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=41873
2024-08-05 03:43:02 | INFO | train_inner | epoch 001:   6505 / 6796 loss=4.872, ppl=29.28, wps=40064.6, ups=0.15, wpb=262144, bsz=512, num_updates=6500, lr=0.00156893, gnorm=0.532, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=42527
2024-08-05 03:53:53 | INFO | train_inner | epoch 001:   6605 / 6796 loss=4.863, ppl=29.1, wps=40226.2, ups=0.15, wpb=262144, bsz=512, num_updates=6600, lr=0.001557, gnorm=0.536, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=43179
2024-08-05 04:04:46 | INFO | train_inner | epoch 001:   6705 / 6796 loss=4.857, ppl=28.99, wps=40177.9, ups=0.15, wpb=262144, bsz=512, num_updates=6700, lr=0.00154533, gnorm=0.525, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=43831
2024-08-05 04:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6791 updates
2024-08-05 04:14:40 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint1.pt
2024-08-05 04:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint1.pt
2024-08-05 04:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint1.pt (epoch 1 @ 6791 updates, score None) (writing took 149.25837557017803 seconds)
2024-08-05 04:17:09 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-08-05 04:17:09 | INFO | train | epoch 001 | loss 5.615 | ppl 49 | wps 39958.7 | ups 0.15 | wpb 262116 | bsz 511.9 | num_updates 6791 | lr 0.00153495 | gnorm 1.614 | clip 18.6 | loss_scale 16 | train_wall 44402 | gb_free 10.3 | wall 44575
2024-08-05 04:17:09 | INFO | fairseq.trainer | loading train data for epoch 2
2024-08-05 04:17:10 | INFO | fairseq.data.data_utils | loaded 52,734,000 examples from: ./data/data-bin/1/train
2024-08-05 04:17:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6776
2024-08-05 04:17:11 | INFO | fairseq.trainer | begin training epoch 2
2024-08-05 04:17:11 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-05 04:18:09 | INFO | train_inner | epoch 002:      9 / 6776 loss=4.849, ppl=28.81, wps=32463, ups=0.12, wpb=260833, bsz=509.4, num_updates=6800, lr=0.00153393, gnorm=0.538, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=44635
2024-08-05 04:23:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-08-05 04:29:10 | INFO | train_inner | epoch 002:    110 / 6776 loss=4.845, ppl=28.74, wps=39669.1, ups=0.15, wpb=262144, bsz=512, num_updates=6900, lr=0.00152277, gnorm=0.531, clip=0, loss_scale=16, train_wall=661, gb_free=10.3, wall=45295
2024-08-05 04:40:10 | INFO | train_inner | epoch 002:    210 / 6776 loss=4.843, ppl=28.69, wps=39719.9, ups=0.15, wpb=262144, bsz=512, num_updates=7000, lr=0.00151186, gnorm=0.527, clip=0, loss_scale=16, train_wall=660, gb_free=10.3, wall=45955
2024-08-05 04:51:16 | INFO | train_inner | epoch 002:    310 / 6776 loss=4.839, ppl=28.63, wps=39359.8, ups=0.15, wpb=262144, bsz=512, num_updates=7100, lr=0.00150117, gnorm=0.527, clip=0, loss_scale=16, train_wall=666, gb_free=10.3, wall=46621
2024-08-05 05:02:23 | INFO | train_inner | epoch 002:    410 / 6776 loss=4.833, ppl=28.51, wps=39294.2, ups=0.15, wpb=262144, bsz=512, num_updates=7200, lr=0.00149071, gnorm=0.539, clip=0, loss_scale=16, train_wall=667, gb_free=10.3, wall=47289
2024-08-05 05:13:29 | INFO | train_inner | epoch 002:    510 / 6776 loss=4.825, ppl=28.35, wps=39389.5, ups=0.15, wpb=262144, bsz=512, num_updates=7300, lr=0.00148047, gnorm=0.535, clip=0, loss_scale=16, train_wall=665, gb_free=10.3, wall=47954
2024-08-05 05:24:31 | INFO | train_inner | epoch 002:    610 / 6776 loss=4.823, ppl=28.3, wps=39607.2, ups=0.15, wpb=262144, bsz=512, num_updates=7400, lr=0.00147043, gnorm=0.525, clip=0, loss_scale=16, train_wall=662, gb_free=10.3, wall=48616
2024-08-05 05:35:32 | INFO | train_inner | epoch 002:    710 / 6776 loss=4.821, ppl=28.27, wps=39629.3, ups=0.15, wpb=262144, bsz=512, num_updates=7500, lr=0.00146059, gnorm=0.503, clip=0, loss_scale=16, train_wall=661, gb_free=10.3, wall=49277
2024-08-05 05:46:35 | INFO | train_inner | epoch 002:    810 / 6776 loss=4.816, ppl=28.17, wps=39538, ups=0.15, wpb=262144, bsz=512, num_updates=7600, lr=0.00145095, gnorm=0.519, clip=0, loss_scale=16, train_wall=663, gb_free=10.3, wall=49940
2024-08-05 05:57:29 | INFO | train_inner | epoch 002:    910 / 6776 loss=4.804, ppl=27.94, wps=40061.2, ups=0.15, wpb=262144, bsz=512, num_updates=7700, lr=0.0014415, gnorm=0.518, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=50595
2024-08-05 06:08:25 | INFO | train_inner | epoch 002:   1010 / 6776 loss=4.798, ppl=27.82, wps=40018.3, ups=0.15, wpb=262144, bsz=512, num_updates=7800, lr=0.00143223, gnorm=0.498, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=51250
2024-08-05 06:19:16 | INFO | train_inner | epoch 002:   1110 / 6776 loss=4.804, ppl=27.93, wps=40263, ups=0.15, wpb=262144, bsz=512, num_updates=7900, lr=0.00142314, gnorm=0.518, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=51901
2024-08-05 06:30:08 | INFO | train_inner | epoch 002:   1210 / 6776 loss=4.795, ppl=27.76, wps=40188.3, ups=0.15, wpb=262144, bsz=512, num_updates=8000, lr=0.00141421, gnorm=0.509, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=52553
2024-08-05 06:40:59 | INFO | train_inner | epoch 002:   1310 / 6776 loss=4.792, ppl=27.71, wps=40258.4, ups=0.15, wpb=262144, bsz=512, num_updates=8100, lr=0.00140546, gnorm=0.519, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=53204
2024-08-05 06:51:51 | INFO | train_inner | epoch 002:   1410 / 6776 loss=4.796, ppl=27.79, wps=40238.5, ups=0.15, wpb=262144, bsz=512, num_updates=8200, lr=0.00139686, gnorm=0.519, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=53856
2024-08-05 07:02:43 | INFO | train_inner | epoch 002:   1510 / 6776 loss=4.787, ppl=27.61, wps=40198, ups=0.15, wpb=262144, bsz=512, num_updates=8300, lr=0.00138842, gnorm=0.495, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=54508
2024-08-05 07:13:39 | INFO | train_inner | epoch 002:   1610 / 6776 loss=4.782, ppl=27.52, wps=39952.3, ups=0.15, wpb=262144, bsz=512, num_updates=8400, lr=0.00138013, gnorm=0.511, clip=0, loss_scale=16, train_wall=656, gb_free=10.3, wall=55164
2024-08-05 07:24:41 | INFO | train_inner | epoch 002:   1710 / 6776 loss=4.779, ppl=27.45, wps=39562.9, ups=0.15, wpb=262144, bsz=512, num_updates=8500, lr=0.00137199, gnorm=0.529, clip=0, loss_scale=16, train_wall=662, gb_free=10.3, wall=55827
2024-08-05 07:35:47 | INFO | train_inner | epoch 002:   1810 / 6776 loss=4.775, ppl=27.38, wps=39385.7, ups=0.15, wpb=262142, bsz=512, num_updates=8600, lr=0.00136399, gnorm=0.515, clip=0, loss_scale=16, train_wall=665, gb_free=10.3, wall=56492
2024-08-05 07:46:51 | INFO | train_inner | epoch 002:   1910 / 6776 loss=4.77, ppl=27.28, wps=39456.4, ups=0.15, wpb=262144, bsz=512, num_updates=8700, lr=0.00135613, gnorm=0.504, clip=0, loss_scale=16, train_wall=664, gb_free=10.3, wall=57157
2024-08-05 07:57:54 | INFO | train_inner | epoch 002:   2010 / 6776 loss=4.77, ppl=27.29, wps=39559.6, ups=0.15, wpb=262144, bsz=512, num_updates=8800, lr=0.0013484, gnorm=0.506, clip=0, loss_scale=16, train_wall=662, gb_free=10.3, wall=57819
2024-08-05 08:08:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-08-05 08:09:00 | INFO | train_inner | epoch 002:   2111 / 6776 loss=4.765, ppl=27.19, wps=39356.2, ups=0.15, wpb=262144, bsz=512, num_updates=8900, lr=0.0013408, gnorm=0.504, clip=0, loss_scale=16, train_wall=666, gb_free=10.3, wall=58485
2024-08-05 08:19:58 | INFO | train_inner | epoch 002:   2211 / 6776 loss=4.759, ppl=27.08, wps=39867.6, ups=0.15, wpb=262144, bsz=512, num_updates=9000, lr=0.00133333, gnorm=0.514, clip=0, loss_scale=16, train_wall=657, gb_free=10.3, wall=59143
2024-08-05 08:30:52 | INFO | train_inner | epoch 002:   2311 / 6776 loss=4.765, ppl=27.18, wps=40091.4, ups=0.15, wpb=262144, bsz=512, num_updates=9100, lr=0.00132599, gnorm=0.5, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=59797
2024-08-05 08:41:43 | INFO | train_inner | epoch 002:   2411 / 6776 loss=4.75, ppl=26.92, wps=40247.7, ups=0.15, wpb=262144, bsz=512, num_updates=9200, lr=0.00131876, gnorm=0.507, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=60448
2024-08-05 08:52:38 | INFO | train_inner | epoch 002:   2511 / 6776 loss=4.752, ppl=26.94, wps=40032.1, ups=0.15, wpb=262144, bsz=512, num_updates=9300, lr=0.00131165, gnorm=0.487, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=61103
2024-08-05 09:03:27 | INFO | train_inner | epoch 002:   2611 / 6776 loss=4.747, ppl=26.85, wps=40346.8, ups=0.15, wpb=262144, bsz=512, num_updates=9400, lr=0.00130466, gnorm=0.515, clip=0, loss_scale=16, train_wall=649, gb_free=10.3, wall=61753
2024-08-05 09:14:16 | INFO | train_inner | epoch 002:   2711 / 6776 loss=4.747, ppl=26.86, wps=40418, ups=0.15, wpb=262144, bsz=512, num_updates=9500, lr=0.00129777, gnorm=0.493, clip=0, loss_scale=16, train_wall=648, gb_free=10.3, wall=62401
2024-08-05 09:25:10 | INFO | train_inner | epoch 002:   2811 / 6776 loss=4.743, ppl=26.77, wps=40108.5, ups=0.15, wpb=262144, bsz=512, num_updates=9600, lr=0.00129099, gnorm=0.503, clip=0, loss_scale=16, train_wall=653, gb_free=10.3, wall=63055
2024-08-05 09:36:02 | INFO | train_inner | epoch 002:   2911 / 6776 loss=4.745, ppl=26.81, wps=40207.3, ups=0.15, wpb=262144, bsz=512, num_updates=9700, lr=0.00128432, gnorm=0.537, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=63707
2024-08-05 09:46:53 | INFO | train_inner | epoch 002:   3011 / 6776 loss=4.737, ppl=26.68, wps=40262.1, ups=0.15, wpb=262144, bsz=512, num_updates=9800, lr=0.00127775, gnorm=0.518, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=64358
2024-08-05 09:57:47 | INFO | train_inner | epoch 002:   3111 / 6776 loss=4.735, ppl=26.63, wps=40067, ups=0.15, wpb=262144, bsz=512, num_updates=9900, lr=0.00127128, gnorm=0.499, clip=0, loss_scale=16, train_wall=654, gb_free=10.3, wall=65012
2024-08-05 10:08:46 | INFO | train_inner | epoch 002:   3211 / 6776 loss=4.738, ppl=26.69, wps=39750.7, ups=0.15, wpb=262144, bsz=512, num_updates=10000, lr=0.00126491, gnorm=0.523, clip=0, loss_scale=16, train_wall=659, gb_free=10.3, wall=65672
2024-08-05 10:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 10000 updates
2024-08-05 10:08:46 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_2_10000.pt
2024-08-05 10:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_2_10000.pt
2024-08-05 10:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score None) (writing took 115.58516968414187 seconds)
2024-08-05 10:21:33 | INFO | train_inner | epoch 002:   3311 / 6776 loss=4.725, ppl=26.45, wps=34188.9, ups=0.13, wpb=262144, bsz=512, num_updates=10100, lr=0.00125863, gnorm=0.517, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=66438
2024-08-05 10:32:25 | INFO | train_inner | epoch 002:   3411 / 6776 loss=4.728, ppl=26.49, wps=40193.3, ups=0.15, wpb=262144, bsz=512, num_updates=10200, lr=0.00125245, gnorm=0.511, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=67091
2024-08-05 10:43:16 | INFO | train_inner | epoch 002:   3511 / 6776 loss=4.724, ppl=26.43, wps=40277.9, ups=0.15, wpb=262144, bsz=512, num_updates=10300, lr=0.00124635, gnorm=0.496, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=67742
2024-08-05 10:54:05 | INFO | train_inner | epoch 002:   3611 / 6776 loss=4.721, ppl=26.38, wps=40426.5, ups=0.15, wpb=262144, bsz=512, num_updates=10400, lr=0.00124035, gnorm=0.524, clip=0, loss_scale=16, train_wall=648, gb_free=10.3, wall=68390
2024-08-05 10:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-05 11:05:03 | INFO | train_inner | epoch 002:   3712 / 6776 loss=4.72, ppl=26.36, wps=39793.2, ups=0.15, wpb=262144, bsz=512, num_updates=10500, lr=0.00123443, gnorm=0.499, clip=0, loss_scale=8, train_wall=658, gb_free=10.3, wall=69049
2024-08-05 11:15:54 | INFO | train_inner | epoch 002:   3812 / 6776 loss=4.715, ppl=26.27, wps=40315.6, ups=0.15, wpb=262144, bsz=512, num_updates=10600, lr=0.00122859, gnorm=0.501, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=69699
2024-08-05 11:26:45 | INFO | train_inner | epoch 002:   3912 / 6776 loss=4.714, ppl=26.25, wps=40228.8, ups=0.15, wpb=262144, bsz=512, num_updates=10700, lr=0.00122284, gnorm=0.52, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=70351
2024-08-05 11:37:40 | INFO | train_inner | epoch 002:   4012 / 6776 loss=4.71, ppl=26.17, wps=40065.7, ups=0.15, wpb=262144, bsz=512, num_updates=10800, lr=0.00121716, gnorm=0.529, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=71005
2024-08-05 11:48:33 | INFO | train_inner | epoch 002:   4112 / 6776 loss=4.708, ppl=26.13, wps=40136.6, ups=0.15, wpb=262144, bsz=512, num_updates=10900, lr=0.00121157, gnorm=0.487, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=71658
2024-08-05 11:59:28 | INFO | train_inner | epoch 002:   4212 / 6776 loss=4.708, ppl=26.14, wps=40024.7, ups=0.15, wpb=262144, bsz=512, num_updates=11000, lr=0.00120605, gnorm=0.488, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=72313
2024-08-05 12:10:24 | INFO | train_inner | epoch 002:   4312 / 6776 loss=4.706, ppl=26.1, wps=39967.2, ups=0.15, wpb=262144, bsz=512, num_updates=11100, lr=0.0012006, gnorm=0.5, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=72969
2024-08-05 12:21:17 | INFO | train_inner | epoch 002:   4412 / 6776 loss=4.699, ppl=25.98, wps=40129, ups=0.15, wpb=262144, bsz=512, num_updates=11200, lr=0.00119523, gnorm=0.5, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=73622
2024-08-05 12:32:12 | INFO | train_inner | epoch 002:   4512 / 6776 loss=4.703, ppl=26.05, wps=40041.1, ups=0.15, wpb=262144, bsz=512, num_updates=11300, lr=0.00118993, gnorm=0.502, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=74277
2024-08-05 12:43:03 | INFO | train_inner | epoch 002:   4612 / 6776 loss=4.696, ppl=25.93, wps=40226.4, ups=0.15, wpb=262144, bsz=512, num_updates=11400, lr=0.0011847, gnorm=0.488, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=74928
2024-08-05 12:53:58 | INFO | train_inner | epoch 002:   4712 / 6776 loss=4.695, ppl=25.89, wps=40041.8, ups=0.15, wpb=262144, bsz=512, num_updates=11500, lr=0.00117954, gnorm=0.491, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=75583
2024-08-05 13:04:53 | INFO | train_inner | epoch 002:   4812 / 6776 loss=4.691, ppl=25.83, wps=40010.6, ups=0.15, wpb=262144, bsz=512, num_updates=11600, lr=0.00117444, gnorm=0.515, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=76238
2024-08-05 13:15:45 | INFO | train_inner | epoch 002:   4912 / 6776 loss=4.692, ppl=25.84, wps=40220.3, ups=0.15, wpb=262144, bsz=512, num_updates=11700, lr=0.00116941, gnorm=0.521, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=76890
2024-08-05 13:26:38 | INFO | train_inner | epoch 002:   5012 / 6776 loss=4.693, ppl=25.86, wps=40122.4, ups=0.15, wpb=262021, bsz=511.8, num_updates=11800, lr=0.00116445, gnorm=0.498, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=77543
2024-08-05 13:37:29 | INFO | train_inner | epoch 002:   5112 / 6776 loss=4.688, ppl=25.78, wps=40234, ups=0.15, wpb=262144, bsz=512, num_updates=11900, lr=0.00115954, gnorm=0.491, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=78195
2024-08-05 13:48:22 | INFO | train_inner | epoch 002:   5212 / 6776 loss=4.683, ppl=25.69, wps=40179, ups=0.15, wpb=262144, bsz=512, num_updates=12000, lr=0.0011547, gnorm=0.506, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=78847
2024-08-05 13:59:14 | INFO | train_inner | epoch 002:   5312 / 6776 loss=4.683, ppl=25.68, wps=40214.4, ups=0.15, wpb=262144, bsz=512, num_updates=12100, lr=0.00114992, gnorm=0.51, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=79499
2024-08-05 14:10:06 | INFO | train_inner | epoch 002:   5412 / 6776 loss=4.682, ppl=25.68, wps=40183.6, ups=0.15, wpb=262144, bsz=512, num_updates=12200, lr=0.0011452, gnorm=0.505, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=80151
2024-08-05 14:20:59 | INFO | train_inner | epoch 002:   5512 / 6776 loss=4.681, ppl=25.65, wps=40172.8, ups=0.15, wpb=262144, bsz=512, num_updates=12300, lr=0.00114053, gnorm=0.507, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=80804
2024-08-05 14:31:55 | INFO | train_inner | epoch 002:   5612 / 6776 loss=4.678, ppl=25.6, wps=39937.3, ups=0.15, wpb=262144, bsz=512, num_updates=12400, lr=0.00113592, gnorm=0.506, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=81460
2024-08-05 14:42:46 | INFO | train_inner | epoch 002:   5712 / 6776 loss=4.676, ppl=25.56, wps=40260.9, ups=0.15, wpb=262144, bsz=512, num_updates=12500, lr=0.00113137, gnorm=0.496, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=82111
2024-08-05 14:53:37 | INFO | train_inner | epoch 002:   5812 / 6776 loss=4.67, ppl=25.46, wps=40268.7, ups=0.15, wpb=262144, bsz=512, num_updates=12600, lr=0.00112687, gnorm=0.533, clip=0, loss_scale=16, train_wall=651, gb_free=10.3, wall=82762
2024-08-05 14:55:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-05 15:04:35 | INFO | train_inner | epoch 002:   5913 / 6776 loss=4.672, ppl=25.49, wps=39827.5, ups=0.15, wpb=262144, bsz=512, num_updates=12700, lr=0.00112243, gnorm=0.525, clip=0, loss_scale=8, train_wall=658, gb_free=10.3, wall=83421
2024-08-05 15:15:29 | INFO | train_inner | epoch 002:   6013 / 6776 loss=4.667, ppl=25.41, wps=40085.7, ups=0.15, wpb=262144, bsz=512, num_updates=12800, lr=0.00111803, gnorm=0.501, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=84075
2024-08-05 15:26:22 | INFO | train_inner | epoch 002:   6113 / 6776 loss=4.673, ppl=25.5, wps=40151.6, ups=0.15, wpb=262144, bsz=512, num_updates=12900, lr=0.00111369, gnorm=0.518, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=84727
2024-08-05 15:37:15 | INFO | train_inner | epoch 002:   6213 / 6776 loss=4.67, ppl=25.46, wps=40173.3, ups=0.15, wpb=262144, bsz=512, num_updates=13000, lr=0.0011094, gnorm=0.5, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=85380
2024-08-05 15:48:07 | INFO | train_inner | epoch 002:   6313 / 6776 loss=4.667, ppl=25.4, wps=40187.4, ups=0.15, wpb=262144, bsz=512, num_updates=13100, lr=0.00110516, gnorm=0.534, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=86032
2024-08-05 15:58:55 | INFO | train_inner | epoch 002:   6413 / 6776 loss=4.664, ppl=25.35, wps=40443.8, ups=0.15, wpb=262144, bsz=512, num_updates=13200, lr=0.00110096, gnorm=0.511, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=86680
2024-08-05 16:09:50 | INFO | train_inner | epoch 002:   6513 / 6776 loss=4.661, ppl=25.3, wps=40054, ups=0.15, wpb=262144, bsz=512, num_updates=13300, lr=0.00109682, gnorm=0.521, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=87335
2024-08-05 16:20:46 | INFO | train_inner | epoch 002:   6613 / 6776 loss=4.657, ppl=25.24, wps=39904.8, ups=0.15, wpb=261852, bsz=511.4, num_updates=13400, lr=0.00109272, gnorm=0.514, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=87991
2024-08-05 16:31:38 | INFO | train_inner | epoch 002:   6713 / 6776 loss=4.658, ppl=25.25, wps=40214, ups=0.15, wpb=262144, bsz=512, num_updates=13500, lr=0.00108866, gnorm=0.525, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=88643
2024-08-05 16:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13563 updates
2024-08-05 16:38:30 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint2.pt
2024-08-05 16:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint2.pt
2024-08-05 16:40:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint2.pt (epoch 2 @ 13563 updates, score None) (writing took 145.90070234425366 seconds)
2024-08-05 16:40:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-08-05 16:40:56 | INFO | train | epoch 002 | loss 4.735 | ppl 26.63 | wps 39773.5 | ups 0.15 | wpb 262104 | bsz 511.9 | num_updates 13563 | lr 0.00108613 | gnorm 0.511 | clip 0 | loss_scale 8 | train_wall 44345 | gb_free 10.3 | wall 89202
2024-08-05 16:40:56 | INFO | fairseq.trainer | loading train data for epoch 3
2024-08-05 16:40:57 | INFO | fairseq.data.data_utils | loaded 52,350,000 examples from: ./data/data-bin/2/train
2024-08-05 16:40:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6724
2024-08-05 16:40:58 | INFO | fairseq.trainer | begin training epoch 3
2024-08-05 16:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-05 16:45:03 | INFO | train_inner | epoch 003:     37 / 6724 loss=4.664, ppl=25.34, wps=32286.5, ups=0.12, wpb=259850, bsz=507.5, num_updates=13600, lr=0.00108465, gnorm=0.506, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=89448
2024-08-05 16:56:02 | INFO | train_inner | epoch 003:    137 / 6724 loss=4.661, ppl=25.29, wps=39737.1, ups=0.15, wpb=262144, bsz=512, num_updates=13700, lr=0.00108069, gnorm=0.494, clip=0, loss_scale=8, train_wall=659, gb_free=10.3, wall=90108
2024-08-05 17:07:00 | INFO | train_inner | epoch 003:    237 / 6724 loss=4.659, ppl=25.26, wps=39842.6, ups=0.15, wpb=262144, bsz=512, num_updates=13800, lr=0.00107676, gnorm=0.522, clip=0, loss_scale=8, train_wall=658, gb_free=10.3, wall=90766
2024-08-05 17:17:54 | INFO | train_inner | epoch 003:    337 / 6724 loss=4.655, ppl=25.2, wps=40077.1, ups=0.15, wpb=261847, bsz=511.4, num_updates=13900, lr=0.00107288, gnorm=0.505, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=91419
2024-08-05 17:28:55 | INFO | train_inner | epoch 003:    437 / 6724 loss=4.656, ppl=25.22, wps=39633.7, ups=0.15, wpb=262144, bsz=512, num_updates=14000, lr=0.00106904, gnorm=0.488, clip=0, loss_scale=8, train_wall=661, gb_free=10.3, wall=92080
2024-08-05 17:39:47 | INFO | train_inner | epoch 003:    537 / 6724 loss=4.648, ppl=25.08, wps=40208.3, ups=0.15, wpb=262144, bsz=512, num_updates=14100, lr=0.00106525, gnorm=0.52, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=92732
2024-08-05 17:50:43 | INFO | train_inner | epoch 003:    637 / 6724 loss=4.653, ppl=25.15, wps=39959.3, ups=0.15, wpb=262144, bsz=512, num_updates=14200, lr=0.00106149, gnorm=0.513, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=93388
2024-08-05 18:01:37 | INFO | train_inner | epoch 003:    737 / 6724 loss=4.647, ppl=25.05, wps=40099.8, ups=0.15, wpb=262144, bsz=512, num_updates=14300, lr=0.00105777, gnorm=0.56, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=94042
2024-08-05 18:12:33 | INFO | train_inner | epoch 003:    837 / 6724 loss=4.651, ppl=25.13, wps=39922.8, ups=0.15, wpb=262144, bsz=512, num_updates=14400, lr=0.00105409, gnorm=0.525, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=94699
2024-08-05 18:23:28 | INFO | train_inner | epoch 003:    937 / 6724 loss=4.65, ppl=25.11, wps=40065, ups=0.15, wpb=262140, bsz=512, num_updates=14500, lr=0.00105045, gnorm=0.532, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=95353
2024-08-05 18:34:22 | INFO | train_inner | epoch 003:   1037 / 6724 loss=4.648, ppl=25.08, wps=40087.3, ups=0.15, wpb=262144, bsz=512, num_updates=14600, lr=0.00104685, gnorm=0.521, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=96007
2024-08-05 18:44:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-05 18:45:29 | INFO | train_inner | epoch 003:   1138 / 6724 loss=4.646, ppl=25.03, wps=39259.3, ups=0.15, wpb=262144, bsz=512, num_updates=14700, lr=0.00104328, gnorm=0.541, clip=0, loss_scale=8, train_wall=667, gb_free=10.3, wall=96675
2024-08-05 18:56:28 | INFO | train_inner | epoch 003:   1238 / 6724 loss=4.642, ppl=24.96, wps=39778.7, ups=0.15, wpb=262144, bsz=512, num_updates=14800, lr=0.00103975, gnorm=0.495, clip=0, loss_scale=8, train_wall=659, gb_free=10.3, wall=97334
2024-08-05 19:07:24 | INFO | train_inner | epoch 003:   1338 / 6724 loss=4.631, ppl=24.78, wps=39998.5, ups=0.15, wpb=262144, bsz=512, num_updates=14900, lr=0.00103626, gnorm=0.503, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=97989
2024-08-05 19:18:17 | INFO | train_inner | epoch 003:   1438 / 6724 loss=4.637, ppl=24.88, wps=40152.8, ups=0.15, wpb=262144, bsz=512, num_updates=15000, lr=0.0010328, gnorm=0.52, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=98642
2024-08-05 19:29:13 | INFO | train_inner | epoch 003:   1538 / 6724 loss=4.638, ppl=24.9, wps=39961.4, ups=0.15, wpb=262144, bsz=512, num_updates=15100, lr=0.00102937, gnorm=0.511, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=99298
2024-08-05 19:40:08 | INFO | train_inner | epoch 003:   1638 / 6724 loss=4.637, ppl=24.88, wps=39973.1, ups=0.15, wpb=262144, bsz=512, num_updates=15200, lr=0.00102598, gnorm=0.538, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=99954
2024-08-05 19:51:03 | INFO | train_inner | epoch 003:   1738 / 6724 loss=4.631, ppl=24.77, wps=40044.5, ups=0.15, wpb=262144, bsz=512, num_updates=15300, lr=0.00102262, gnorm=0.525, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=100608
2024-08-05 20:01:59 | INFO | train_inner | epoch 003:   1838 / 6724 loss=4.633, ppl=24.81, wps=39945.4, ups=0.15, wpb=262144, bsz=512, num_updates=15400, lr=0.00101929, gnorm=0.536, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=101265
2024-08-05 20:12:53 | INFO | train_inner | epoch 003:   1938 / 6724 loss=4.632, ppl=24.79, wps=40110.9, ups=0.15, wpb=262144, bsz=512, num_updates=15500, lr=0.001016, gnorm=0.523, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=101918
2024-08-05 20:23:48 | INFO | train_inner | epoch 003:   2038 / 6724 loss=4.627, ppl=24.71, wps=40000.3, ups=0.15, wpb=262144, bsz=512, num_updates=15600, lr=0.00101274, gnorm=0.532, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=102573
2024-08-05 20:34:45 | INFO | train_inner | epoch 003:   2138 / 6724 loss=4.627, ppl=24.71, wps=39916.2, ups=0.15, wpb=262144, bsz=512, num_updates=15700, lr=0.00100951, gnorm=0.499, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=103230
2024-08-05 20:45:39 | INFO | train_inner | epoch 003:   2238 / 6724 loss=4.629, ppl=24.75, wps=40101.1, ups=0.15, wpb=262144, bsz=512, num_updates=15800, lr=0.00100631, gnorm=0.512, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=103884
2024-08-05 20:56:30 | INFO | train_inner | epoch 003:   2338 / 6724 loss=4.63, ppl=24.76, wps=40228.9, ups=0.15, wpb=262144, bsz=512, num_updates=15900, lr=0.00100314, gnorm=0.533, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=104536
2024-08-05 21:07:27 | INFO | train_inner | epoch 003:   2438 / 6724 loss=4.623, ppl=24.63, wps=39928.4, ups=0.15, wpb=262144, bsz=512, num_updates=16000, lr=0.001, gnorm=0.513, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=105192
2024-08-05 21:18:22 | INFO | train_inner | epoch 003:   2538 / 6724 loss=4.624, ppl=24.66, wps=40028.2, ups=0.15, wpb=262144, bsz=512, num_updates=16100, lr=0.00099689, gnorm=0.493, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=105847
2024-08-05 21:29:15 | INFO | train_inner | epoch 003:   2638 / 6724 loss=4.616, ppl=24.53, wps=40137.8, ups=0.15, wpb=262144, bsz=512, num_updates=16200, lr=0.000993808, gnorm=0.507, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=106500
2024-08-05 21:40:09 | INFO | train_inner | epoch 003:   2738 / 6724 loss=4.626, ppl=24.68, wps=40069.4, ups=0.15, wpb=262144, bsz=512, num_updates=16300, lr=0.000990755, gnorm=0.533, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=107154
2024-08-05 21:51:03 | INFO | train_inner | epoch 003:   2838 / 6724 loss=4.623, ppl=24.64, wps=40086.6, ups=0.15, wpb=262144, bsz=512, num_updates=16400, lr=0.00098773, gnorm=0.517, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=107808
2024-08-05 22:01:57 | INFO | train_inner | epoch 003:   2938 / 6724 loss=4.616, ppl=24.53, wps=40107.5, ups=0.15, wpb=262144, bsz=512, num_updates=16500, lr=0.000984732, gnorm=0.5, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=108462
2024-08-05 22:12:52 | INFO | train_inner | epoch 003:   3038 / 6724 loss=4.614, ppl=24.49, wps=40006.5, ups=0.15, wpb=262144, bsz=512, num_updates=16600, lr=0.000981761, gnorm=0.522, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=109117
2024-08-05 22:23:47 | INFO | train_inner | epoch 003:   3138 / 6724 loss=4.622, ppl=24.63, wps=40027.5, ups=0.15, wpb=262144, bsz=512, num_updates=16700, lr=0.000978818, gnorm=0.545, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=109772
2024-08-05 22:34:43 | INFO | train_inner | epoch 003:   3238 / 6724 loss=4.618, ppl=24.56, wps=39962.2, ups=0.15, wpb=262144, bsz=512, num_updates=16800, lr=0.0009759, gnorm=0.521, clip=0, loss_scale=16, train_wall=656, gb_free=10.3, wall=110428
2024-08-05 22:45:38 | INFO | train_inner | epoch 003:   3338 / 6724 loss=4.616, ppl=24.52, wps=39994.4, ups=0.15, wpb=262144, bsz=512, num_updates=16900, lr=0.000973009, gnorm=0.497, clip=0, loss_scale=16, train_wall=655, gb_free=10.3, wall=111083
2024-08-05 22:47:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-05 22:56:42 | INFO | train_inner | epoch 003:   3439 / 6724 loss=4.614, ppl=24.49, wps=39487.2, ups=0.15, wpb=262144, bsz=512, num_updates=17000, lr=0.000970143, gnorm=0.523, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=111747
2024-08-05 23:07:40 | INFO | train_inner | epoch 003:   3539 / 6724 loss=4.615, ppl=24.5, wps=39872.8, ups=0.15, wpb=262144, bsz=512, num_updates=17100, lr=0.000967302, gnorm=0.528, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=112405
2024-08-05 23:18:35 | INFO | train_inner | epoch 003:   3639 / 6724 loss=4.613, ppl=24.46, wps=40006.1, ups=0.15, wpb=262144, bsz=512, num_updates=17200, lr=0.000964486, gnorm=0.51, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=113060
2024-08-05 23:29:32 | INFO | train_inner | epoch 003:   3739 / 6724 loss=4.608, ppl=24.39, wps=39895.6, ups=0.15, wpb=262144, bsz=512, num_updates=17300, lr=0.000961694, gnorm=0.496, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=113717
2024-08-05 23:40:27 | INFO | train_inner | epoch 003:   3839 / 6724 loss=4.607, ppl=24.36, wps=40012.9, ups=0.15, wpb=262144, bsz=512, num_updates=17400, lr=0.000958927, gnorm=0.515, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=114372
2024-08-05 23:51:19 | INFO | train_inner | epoch 003:   3939 / 6724 loss=4.608, ppl=24.39, wps=40192.5, ups=0.15, wpb=262144, bsz=512, num_updates=17500, lr=0.000956183, gnorm=0.518, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=115025
2024-08-06 00:02:10 | INFO | train_inner | epoch 003:   4039 / 6724 loss=4.602, ppl=24.29, wps=40265.9, ups=0.15, wpb=262144, bsz=512, num_updates=17600, lr=0.000953463, gnorm=0.507, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=115676
2024-08-06 00:12:58 | INFO | train_inner | epoch 003:   4139 / 6724 loss=4.607, ppl=24.37, wps=40455.8, ups=0.15, wpb=262144, bsz=512, num_updates=17700, lr=0.000950765, gnorm=0.524, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=116324
2024-08-06 00:23:53 | INFO | train_inner | epoch 003:   4239 / 6724 loss=4.608, ppl=24.38, wps=40018.8, ups=0.15, wpb=262144, bsz=512, num_updates=17800, lr=0.000948091, gnorm=0.513, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=116979
2024-08-06 00:34:44 | INFO | train_inner | epoch 003:   4339 / 6724 loss=4.606, ppl=24.36, wps=40281.2, ups=0.15, wpb=262144, bsz=512, num_updates=17900, lr=0.000945439, gnorm=0.514, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=117629
2024-08-06 00:45:40 | INFO | train_inner | epoch 003:   4439 / 6724 loss=4.603, ppl=24.31, wps=39982.9, ups=0.15, wpb=262144, bsz=512, num_updates=18000, lr=0.000942809, gnorm=0.5, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=118285
2024-08-06 00:56:29 | INFO | train_inner | epoch 003:   4539 / 6724 loss=4.601, ppl=24.27, wps=40372.7, ups=0.15, wpb=262144, bsz=512, num_updates=18100, lr=0.000940201, gnorm=0.515, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=118934
2024-08-06 01:07:23 | INFO | train_inner | epoch 003:   4639 / 6724 loss=4.602, ppl=24.28, wps=40104.1, ups=0.15, wpb=262144, bsz=512, num_updates=18200, lr=0.000937614, gnorm=0.526, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=119588
2024-08-06 01:18:16 | INFO | train_inner | epoch 003:   4739 / 6724 loss=4.596, ppl=24.19, wps=40141.7, ups=0.15, wpb=262144, bsz=512, num_updates=18300, lr=0.000935049, gnorm=0.502, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=120241
2024-08-06 01:29:11 | INFO | train_inner | epoch 003:   4839 / 6724 loss=4.601, ppl=24.27, wps=39994.3, ups=0.15, wpb=262144, bsz=512, num_updates=18400, lr=0.000932505, gnorm=0.516, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=120896
2024-08-06 01:40:04 | INFO | train_inner | epoch 003:   4939 / 6724 loss=4.598, ppl=24.22, wps=40137.9, ups=0.15, wpb=262144, bsz=512, num_updates=18500, lr=0.000929981, gnorm=0.509, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=121550
2024-08-06 01:50:56 | INFO | train_inner | epoch 003:   5039 / 6724 loss=4.599, ppl=24.24, wps=40255.8, ups=0.15, wpb=262144, bsz=512, num_updates=18600, lr=0.000927478, gnorm=0.52, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=122201
2024-08-06 02:01:45 | INFO | train_inner | epoch 003:   5139 / 6724 loss=4.597, ppl=24.2, wps=40330.4, ups=0.15, wpb=262144, bsz=512, num_updates=18700, lr=0.000924995, gnorm=0.515, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=122851
2024-08-06 02:12:36 | INFO | train_inner | epoch 003:   5239 / 6724 loss=4.598, ppl=24.21, wps=40325.9, ups=0.15, wpb=262144, bsz=512, num_updates=18800, lr=0.000922531, gnorm=0.515, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=123501
2024-08-06 02:23:28 | INFO | train_inner | epoch 003:   5339 / 6724 loss=4.6, ppl=24.26, wps=40194.7, ups=0.15, wpb=262144, bsz=512, num_updates=18900, lr=0.000920087, gnorm=0.529, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=124153
2024-08-06 02:34:20 | INFO | train_inner | epoch 003:   5439 / 6724 loss=4.595, ppl=24.16, wps=40160.4, ups=0.15, wpb=262144, bsz=512, num_updates=19000, lr=0.000917663, gnorm=0.538, clip=0, loss_scale=16, train_wall=652, gb_free=10.3, wall=124806
2024-08-06 02:43:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 02:45:19 | INFO | train_inner | epoch 003:   5540 / 6724 loss=4.592, ppl=24.12, wps=39788.7, ups=0.15, wpb=262144, bsz=512, num_updates=19100, lr=0.000915258, gnorm=0.49, clip=0, loss_scale=8, train_wall=659, gb_free=10.3, wall=125465
2024-08-06 02:56:07 | INFO | train_inner | epoch 003:   5640 / 6724 loss=4.593, ppl=24.14, wps=40498.6, ups=0.15, wpb=262144, bsz=512, num_updates=19200, lr=0.000912871, gnorm=0.534, clip=0, loss_scale=8, train_wall=647, gb_free=10.3, wall=126112
2024-08-06 03:06:56 | INFO | train_inner | epoch 003:   5740 / 6724 loss=4.591, ppl=24.09, wps=40391.9, ups=0.15, wpb=262144, bsz=512, num_updates=19300, lr=0.000910503, gnorm=0.529, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=126761
2024-08-06 03:17:50 | INFO | train_inner | epoch 003:   5840 / 6724 loss=4.588, ppl=24.06, wps=40046.9, ups=0.15, wpb=262144, bsz=512, num_updates=19400, lr=0.000908153, gnorm=0.532, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=127416
2024-08-06 03:28:45 | INFO | train_inner | epoch 003:   5940 / 6724 loss=4.587, ppl=24.04, wps=40021.4, ups=0.15, wpb=262144, bsz=512, num_updates=19500, lr=0.000905822, gnorm=0.511, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=128071
2024-08-06 03:39:38 | INFO | train_inner | epoch 003:   6040 / 6724 loss=4.585, ppl=24, wps=40183.3, ups=0.15, wpb=262144, bsz=512, num_updates=19600, lr=0.000903508, gnorm=0.501, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=128723
2024-08-06 03:50:27 | INFO | train_inner | epoch 003:   6140 / 6724 loss=4.586, ppl=24.01, wps=40350.2, ups=0.15, wpb=262144, bsz=512, num_updates=19700, lr=0.000901212, gnorm=0.546, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=129373
2024-08-06 04:01:16 | INFO | train_inner | epoch 003:   6240 / 6724 loss=4.588, ppl=24.05, wps=40416.2, ups=0.15, wpb=262144, bsz=512, num_updates=19800, lr=0.000898933, gnorm=0.518, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=130021
2024-08-06 04:12:06 | INFO | train_inner | epoch 003:   6340 / 6724 loss=4.59, ppl=24.09, wps=40338.9, ups=0.15, wpb=262144, bsz=512, num_updates=19900, lr=0.000896672, gnorm=0.531, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=130671
2024-08-06 04:22:54 | INFO | train_inner | epoch 003:   6440 / 6724 loss=4.578, ppl=23.89, wps=40449.2, ups=0.15, wpb=262144, bsz=512, num_updates=20000, lr=0.000894427, gnorm=0.551, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=131319
2024-08-06 04:22:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20000 updates
2024-08-06 04:22:54 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_3_20000.pt
2024-08-06 04:23:35 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_3_20000.pt
2024-08-06 04:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_3_20000.pt (epoch 3 @ 20000 updates, score None) (writing took 120.443508150056 seconds)
2024-08-06 04:35:49 | INFO | train_inner | epoch 003:   6540 / 6724 loss=4.585, ppl=24, wps=33819, ups=0.13, wpb=262144, bsz=512, num_updates=20100, lr=0.000892199, gnorm=0.519, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=132094
2024-08-06 04:46:44 | INFO | train_inner | epoch 003:   6640 / 6724 loss=4.581, ppl=23.93, wps=40037.2, ups=0.15, wpb=262144, bsz=512, num_updates=20200, lr=0.000889988, gnorm=0.522, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=132749
2024-08-06 04:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20284 updates
2024-08-06 04:55:49 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint3.pt
2024-08-06 04:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint3.pt
2024-08-06 04:58:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint3.pt (epoch 3 @ 20284 updates, score None) (writing took 142.42071145027876 seconds)
2024-08-06 04:58:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-08-06 04:58:11 | INFO | train | epoch 003 | loss 4.616 | ppl 24.53 | wps 39825.5 | ups 0.15 | wpb 262115 | bsz 511.9 | num_updates 20284 | lr 0.000888144 | gnorm 0.519 | clip 0 | loss_scale 8 | train_wall 43952 | gb_free 10.3 | wall 133437
2024-08-06 04:58:11 | INFO | fairseq.trainer | loading train data for epoch 4
2024-08-06 04:58:12 | INFO | fairseq.data.data_utils | loaded 52,445,000 examples from: ./data/data-bin/3/train
2024-08-06 04:58:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6739
2024-08-06 04:58:13 | INFO | fairseq.trainer | begin training epoch 4
2024-08-06 04:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-06 04:59:56 | INFO | train_inner | epoch 004:     16 / 6739 loss=4.584, ppl=23.98, wps=32881.3, ups=0.13, wpb=260506, bsz=508.8, num_updates=20300, lr=0.000887794, gnorm=0.555, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=133541
2024-08-06 05:10:48 | INFO | train_inner | epoch 004:    116 / 6739 loss=4.58, ppl=23.92, wps=40214.6, ups=0.15, wpb=262144, bsz=512, num_updates=20400, lr=0.000885615, gnorm=0.503, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=134193
2024-08-06 05:21:42 | INFO | train_inner | epoch 004:    216 / 6739 loss=4.577, ppl=23.86, wps=40096.7, ups=0.15, wpb=262144, bsz=512, num_updates=20500, lr=0.000883452, gnorm=0.535, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=134847
2024-08-06 05:32:32 | INFO | train_inner | epoch 004:    316 / 6739 loss=4.579, ppl=23.9, wps=40301.4, ups=0.15, wpb=262144, bsz=512, num_updates=20600, lr=0.000881305, gnorm=0.526, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=135497
2024-08-06 05:43:25 | INFO | train_inner | epoch 004:    416 / 6739 loss=4.576, ppl=23.86, wps=40161.1, ups=0.15, wpb=262144, bsz=512, num_updates=20700, lr=0.000879174, gnorm=0.519, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=136150
2024-08-06 05:54:15 | INFO | train_inner | epoch 004:    516 / 6739 loss=4.575, ppl=23.83, wps=40347.6, ups=0.15, wpb=262144, bsz=512, num_updates=20800, lr=0.000877058, gnorm=0.543, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=136800
2024-08-06 06:05:10 | INFO | train_inner | epoch 004:    616 / 6739 loss=4.579, ppl=23.9, wps=39965.8, ups=0.15, wpb=262144, bsz=512, num_updates=20900, lr=0.000874957, gnorm=0.556, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=137456
2024-08-06 06:16:02 | INFO | train_inner | epoch 004:    716 / 6739 loss=4.577, ppl=23.87, wps=40213, ups=0.15, wpb=262144, bsz=512, num_updates=21000, lr=0.000872872, gnorm=0.517, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=138108
2024-08-06 06:26:55 | INFO | train_inner | epoch 004:    816 / 6739 loss=4.578, ppl=23.89, wps=40186.6, ups=0.15, wpb=262144, bsz=512, num_updates=21100, lr=0.000870801, gnorm=0.54, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=138760
2024-08-06 06:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 06:37:56 | INFO | train_inner | epoch 004:    917 / 6739 loss=4.574, ppl=23.82, wps=39665.4, ups=0.15, wpb=262144, bsz=512, num_updates=21200, lr=0.000868744, gnorm=0.532, clip=0, loss_scale=8, train_wall=661, gb_free=10.3, wall=139421
2024-08-06 06:48:49 | INFO | train_inner | epoch 004:   1017 / 6739 loss=4.575, ppl=23.83, wps=40113.8, ups=0.15, wpb=262144, bsz=512, num_updates=21300, lr=0.000866703, gnorm=0.536, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=140074
2024-08-06 06:59:40 | INFO | train_inner | epoch 004:   1117 / 6739 loss=4.573, ppl=23.8, wps=40259.3, ups=0.15, wpb=262144, bsz=512, num_updates=21400, lr=0.000864675, gnorm=0.499, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=140726
2024-08-06 07:10:31 | INFO | train_inner | epoch 004:   1217 / 6739 loss=4.567, ppl=23.71, wps=40293.7, ups=0.15, wpb=262144, bsz=512, num_updates=21500, lr=0.000862662, gnorm=0.555, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=141376
2024-08-06 07:21:16 | INFO | train_inner | epoch 004:   1317 / 6739 loss=4.572, ppl=23.78, wps=40604.7, ups=0.15, wpb=262144, bsz=512, num_updates=21600, lr=0.000860663, gnorm=0.543, clip=0, loss_scale=8, train_wall=645, gb_free=10.3, wall=142022
2024-08-06 07:32:08 | INFO | train_inner | epoch 004:   1417 / 6739 loss=4.57, ppl=23.74, wps=40200.8, ups=0.15, wpb=262144, bsz=512, num_updates=21700, lr=0.000858678, gnorm=0.535, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=142674
2024-08-06 07:42:58 | INFO | train_inner | epoch 004:   1517 / 6739 loss=4.567, ppl=23.71, wps=40327.1, ups=0.15, wpb=262103, bsz=511.9, num_updates=21800, lr=0.000856706, gnorm=0.542, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=143324
2024-08-06 07:53:49 | INFO | train_inner | epoch 004:   1617 / 6739 loss=4.567, ppl=23.7, wps=40314.8, ups=0.15, wpb=262144, bsz=512, num_updates=21900, lr=0.000854748, gnorm=0.52, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=143974
2024-08-06 08:04:39 | INFO | train_inner | epoch 004:   1717 / 6739 loss=4.567, ppl=23.71, wps=40316.8, ups=0.15, wpb=262144, bsz=512, num_updates=22000, lr=0.000852803, gnorm=0.524, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=144624
2024-08-06 08:15:29 | INFO | train_inner | epoch 004:   1817 / 6739 loss=4.566, ppl=23.69, wps=40345.6, ups=0.15, wpb=262144, bsz=512, num_updates=22100, lr=0.000850871, gnorm=0.549, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=145274
2024-08-06 08:26:20 | INFO | train_inner | epoch 004:   1917 / 6739 loss=4.562, ppl=23.62, wps=40219.6, ups=0.15, wpb=262144, bsz=512, num_updates=22200, lr=0.000848953, gnorm=0.52, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=145926
2024-08-06 08:37:10 | INFO | train_inner | epoch 004:   2017 / 6739 loss=4.566, ppl=23.69, wps=40344, ups=0.15, wpb=262144, bsz=512, num_updates=22300, lr=0.000847047, gnorm=0.526, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=146575
2024-08-06 08:48:04 | INFO | train_inner | epoch 004:   2117 / 6739 loss=4.562, ppl=23.61, wps=40098.1, ups=0.15, wpb=262144, bsz=512, num_updates=22400, lr=0.000845154, gnorm=0.521, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=147229
2024-08-06 08:58:53 | INFO | train_inner | epoch 004:   2217 / 6739 loss=4.563, ppl=23.63, wps=40379.2, ups=0.15, wpb=262144, bsz=512, num_updates=22500, lr=0.000843274, gnorm=0.523, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=147878
2024-08-06 09:09:43 | INFO | train_inner | epoch 004:   2317 / 6739 loss=4.562, ppl=23.62, wps=40354, ups=0.15, wpb=262144, bsz=512, num_updates=22600, lr=0.000841406, gnorm=0.506, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=148528
2024-08-06 09:20:33 | INFO | train_inner | epoch 004:   2417 / 6739 loss=4.56, ppl=23.6, wps=40330.5, ups=0.15, wpb=262144, bsz=512, num_updates=22700, lr=0.000839551, gnorm=0.551, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=149178
2024-08-06 09:31:26 | INFO | train_inner | epoch 004:   2517 / 6739 loss=4.559, ppl=23.57, wps=40122.4, ups=0.15, wpb=262144, bsz=512, num_updates=22800, lr=0.000837708, gnorm=0.547, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=149831
2024-08-06 09:42:14 | INFO | train_inner | epoch 004:   2617 / 6739 loss=4.558, ppl=23.56, wps=40492.2, ups=0.15, wpb=262144, bsz=512, num_updates=22900, lr=0.000835877, gnorm=0.533, clip=0, loss_scale=8, train_wall=647, gb_free=10.3, wall=150479
2024-08-06 09:53:05 | INFO | train_inner | epoch 004:   2717 / 6739 loss=4.562, ppl=23.62, wps=40257.5, ups=0.15, wpb=262144, bsz=512, num_updates=23000, lr=0.000834058, gnorm=0.539, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=151130
2024-08-06 10:03:58 | INFO | train_inner | epoch 004:   2817 / 6739 loss=4.562, ppl=23.63, wps=40136.4, ups=0.15, wpb=262144, bsz=512, num_updates=23100, lr=0.00083225, gnorm=0.533, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=151783
2024-08-06 10:14:50 | INFO | train_inner | epoch 004:   2917 / 6739 loss=4.559, ppl=23.58, wps=40189.4, ups=0.15, wpb=262144, bsz=512, num_updates=23200, lr=0.000830455, gnorm=0.526, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=152435
2024-08-06 10:22:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 10:25:47 | INFO | train_inner | epoch 004:   3018 / 6739 loss=4.562, ppl=23.62, wps=39912.3, ups=0.15, wpb=262144, bsz=512, num_updates=23300, lr=0.000828671, gnorm=0.532, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=153092
2024-08-06 10:36:42 | INFO | train_inner | epoch 004:   3118 / 6739 loss=4.557, ppl=23.54, wps=39993.9, ups=0.15, wpb=262144, bsz=512, num_updates=23400, lr=0.000826898, gnorm=0.529, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=153748
2024-08-06 10:47:36 | INFO | train_inner | epoch 004:   3218 / 6739 loss=4.558, ppl=23.56, wps=40130.5, ups=0.15, wpb=262144, bsz=512, num_updates=23500, lr=0.000825137, gnorm=0.525, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=154401
2024-08-06 10:58:27 | INFO | train_inner | epoch 004:   3318 / 6739 loss=4.555, ppl=23.51, wps=40252.7, ups=0.15, wpb=262144, bsz=512, num_updates=23600, lr=0.000823387, gnorm=0.524, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=155052
2024-08-06 11:09:18 | INFO | train_inner | epoch 004:   3418 / 6739 loss=4.553, ppl=23.48, wps=40277, ups=0.15, wpb=262144, bsz=512, num_updates=23700, lr=0.000821648, gnorm=0.514, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=155703
2024-08-06 11:20:10 | INFO | train_inner | epoch 004:   3518 / 6739 loss=4.553, ppl=23.48, wps=40180.2, ups=0.15, wpb=262144, bsz=512, num_updates=23800, lr=0.00081992, gnorm=0.546, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=156355
2024-08-06 11:31:00 | INFO | train_inner | epoch 004:   3618 / 6739 loss=4.552, ppl=23.45, wps=40349, ups=0.15, wpb=262144, bsz=512, num_updates=23900, lr=0.000818203, gnorm=0.543, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=157005
2024-08-06 11:41:52 | INFO | train_inner | epoch 004:   3718 / 6739 loss=4.551, ppl=23.43, wps=40170.9, ups=0.15, wpb=262144, bsz=512, num_updates=24000, lr=0.000816497, gnorm=0.569, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=157658
2024-08-06 11:52:47 | INFO | train_inner | epoch 004:   3818 / 6739 loss=4.554, ppl=23.49, wps=40020.9, ups=0.15, wpb=262144, bsz=512, num_updates=24100, lr=0.000814801, gnorm=0.542, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=158313
2024-08-06 12:03:43 | INFO | train_inner | epoch 004:   3918 / 6739 loss=4.552, ppl=23.45, wps=39997.1, ups=0.15, wpb=262144, bsz=512, num_updates=24200, lr=0.000813116, gnorm=0.547, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=158968
2024-08-06 12:14:33 | INFO | train_inner | epoch 004:   4018 / 6739 loss=4.547, ppl=23.37, wps=40343.4, ups=0.15, wpb=262144, bsz=512, num_updates=24300, lr=0.000811441, gnorm=0.536, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=159618
2024-08-06 12:25:26 | INFO | train_inner | epoch 004:   4118 / 6739 loss=4.551, ppl=23.44, wps=40105.3, ups=0.15, wpb=262144, bsz=512, num_updates=24400, lr=0.000809776, gnorm=0.542, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=160272
2024-08-06 12:36:17 | INFO | train_inner | epoch 004:   4218 / 6739 loss=4.547, ppl=23.38, wps=40274.7, ups=0.15, wpb=262144, bsz=512, num_updates=24500, lr=0.000808122, gnorm=0.546, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=160922
2024-08-06 12:47:08 | INFO | train_inner | epoch 004:   4318 / 6739 loss=4.548, ppl=23.4, wps=40280, ups=0.15, wpb=262144, bsz=512, num_updates=24600, lr=0.000806478, gnorm=0.546, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=161573
2024-08-06 12:57:57 | INFO | train_inner | epoch 004:   4418 / 6739 loss=4.549, ppl=23.41, wps=40384.1, ups=0.15, wpb=262144, bsz=512, num_updates=24700, lr=0.000804844, gnorm=0.54, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=162222
2024-08-06 13:08:48 | INFO | train_inner | epoch 004:   4518 / 6739 loss=4.547, ppl=23.37, wps=40240.8, ups=0.15, wpb=262144, bsz=512, num_updates=24800, lr=0.000803219, gnorm=0.563, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=162874
2024-08-06 13:19:50 | INFO | train_inner | epoch 004:   4618 / 6739 loss=4.546, ppl=23.36, wps=39639, ups=0.15, wpb=262144, bsz=512, num_updates=24900, lr=0.000801605, gnorm=0.563, clip=0, loss_scale=8, train_wall=661, gb_free=10.3, wall=163535
2024-08-06 13:31:02 | INFO | train_inner | epoch 004:   4718 / 6739 loss=4.548, ppl=23.39, wps=39009.2, ups=0.15, wpb=262144, bsz=512, num_updates=25000, lr=0.0008, gnorm=0.532, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=164207
2024-08-06 13:42:17 | INFO | train_inner | epoch 004:   4818 / 6739 loss=4.545, ppl=23.34, wps=38841.3, ups=0.15, wpb=262142, bsz=512, num_updates=25100, lr=0.000798405, gnorm=0.56, clip=0, loss_scale=8, train_wall=675, gb_free=10.3, wall=164882
2024-08-06 13:53:31 | INFO | train_inner | epoch 004:   4918 / 6739 loss=4.542, ppl=23.29, wps=38877.8, ups=0.15, wpb=262144, bsz=512, num_updates=25200, lr=0.000796819, gnorm=0.565, clip=0, loss_scale=8, train_wall=674, gb_free=10.3, wall=165556
2024-08-06 14:04:44 | INFO | train_inner | epoch 004:   5018 / 6739 loss=4.546, ppl=23.36, wps=38971.5, ups=0.15, wpb=262144, bsz=512, num_updates=25300, lr=0.000795243, gnorm=0.532, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=166229
2024-08-06 14:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 14:16:00 | INFO | train_inner | epoch 004:   5119 / 6739 loss=4.547, ppl=23.37, wps=38774.4, ups=0.15, wpb=262144, bsz=512, num_updates=25400, lr=0.000793676, gnorm=0.592, clip=0, loss_scale=8, train_wall=676, gb_free=10.3, wall=166905
2024-08-06 14:27:12 | INFO | train_inner | epoch 004:   5219 / 6739 loss=4.541, ppl=23.28, wps=38990.3, ups=0.15, wpb=262144, bsz=512, num_updates=25500, lr=0.000792118, gnorm=0.511, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=167577
2024-08-06 14:38:26 | INFO | train_inner | epoch 004:   5319 / 6739 loss=4.542, ppl=23.3, wps=38900.2, ups=0.15, wpb=262144, bsz=512, num_updates=25600, lr=0.000790569, gnorm=0.53, clip=0, loss_scale=8, train_wall=674, gb_free=10.3, wall=168251
2024-08-06 14:49:37 | INFO | train_inner | epoch 004:   5419 / 6739 loss=4.54, ppl=23.26, wps=39078.9, ups=0.15, wpb=262144, bsz=512, num_updates=25700, lr=0.00078903, gnorm=0.538, clip=0, loss_scale=8, train_wall=671, gb_free=10.3, wall=168922
2024-08-06 15:00:47 | INFO | train_inner | epoch 004:   5519 / 6739 loss=4.537, ppl=23.22, wps=39128.9, ups=0.15, wpb=262144, bsz=512, num_updates=25800, lr=0.000787499, gnorm=0.547, clip=0, loss_scale=8, train_wall=670, gb_free=10.3, wall=169592
2024-08-06 15:11:59 | INFO | train_inner | epoch 004:   5619 / 6739 loss=4.539, ppl=23.24, wps=38973.9, ups=0.15, wpb=262144, bsz=512, num_updates=25900, lr=0.000785977, gnorm=0.579, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=170265
2024-08-06 15:23:14 | INFO | train_inner | epoch 004:   5719 / 6739 loss=4.54, ppl=23.26, wps=38856.9, ups=0.15, wpb=262144, bsz=512, num_updates=26000, lr=0.000784465, gnorm=0.531, clip=0, loss_scale=8, train_wall=674, gb_free=10.3, wall=170939
2024-08-06 15:34:25 | INFO | train_inner | epoch 004:   5819 / 6739 loss=4.54, ppl=23.26, wps=39042.4, ups=0.15, wpb=262144, bsz=512, num_updates=26100, lr=0.00078296, gnorm=0.525, clip=0, loss_scale=8, train_wall=671, gb_free=10.3, wall=171611
2024-08-06 15:45:34 | INFO | train_inner | epoch 004:   5919 / 6739 loss=4.535, ppl=23.19, wps=39183.1, ups=0.15, wpb=262144, bsz=512, num_updates=26200, lr=0.000781465, gnorm=0.555, clip=0, loss_scale=8, train_wall=669, gb_free=10.3, wall=172280
2024-08-06 15:56:44 | INFO | train_inner | epoch 004:   6019 / 6739 loss=4.54, ppl=23.26, wps=39129, ups=0.15, wpb=262144, bsz=512, num_updates=26300, lr=0.000779978, gnorm=0.554, clip=0, loss_scale=8, train_wall=670, gb_free=10.3, wall=172950
2024-08-06 16:07:50 | INFO | train_inner | epoch 004:   6119 / 6739 loss=4.539, ppl=23.25, wps=39413.1, ups=0.15, wpb=262144, bsz=512, num_updates=26400, lr=0.000778499, gnorm=0.546, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=173615
2024-08-06 16:18:50 | INFO | train_inner | epoch 004:   6219 / 6739 loss=4.537, ppl=23.22, wps=39708.2, ups=0.15, wpb=262144, bsz=512, num_updates=26500, lr=0.000777029, gnorm=0.561, clip=0, loss_scale=8, train_wall=660, gb_free=10.3, wall=174275
2024-08-06 16:29:50 | INFO | train_inner | epoch 004:   6319 / 6739 loss=4.534, ppl=23.16, wps=39678.3, ups=0.15, wpb=262144, bsz=512, num_updates=26600, lr=0.000775567, gnorm=0.547, clip=0, loss_scale=8, train_wall=660, gb_free=10.3, wall=174936
2024-08-06 16:40:54 | INFO | train_inner | epoch 004:   6419 / 6739 loss=4.542, ppl=23.3, wps=39493.7, ups=0.15, wpb=262144, bsz=512, num_updates=26700, lr=0.000774113, gnorm=0.552, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=175599
2024-08-06 16:51:57 | INFO | train_inner | epoch 004:   6519 / 6739 loss=4.535, ppl=23.19, wps=39539.4, ups=0.15, wpb=262144, bsz=512, num_updates=26800, lr=0.000772667, gnorm=0.523, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=176262
2024-08-06 17:03:03 | INFO | train_inner | epoch 004:   6619 / 6739 loss=4.534, ppl=23.16, wps=39376.8, ups=0.15, wpb=262144, bsz=512, num_updates=26900, lr=0.00077123, gnorm=0.543, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=176928
2024-08-06 17:14:05 | INFO | train_inner | epoch 004:   6719 / 6739 loss=4.532, ppl=23.14, wps=39597.6, ups=0.15, wpb=262144, bsz=512, num_updates=27000, lr=0.0007698, gnorm=0.559, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=177590
2024-08-06 17:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 27020 updates
2024-08-06 17:16:19 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint4.pt
2024-08-06 17:17:01 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint4.pt
2024-08-06 17:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint4.pt (epoch 4 @ 27020 updates, score None) (writing took 143.92173035629094 seconds)
2024-08-06 17:18:43 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-08-06 17:18:43 | INFO | train | epoch 004 | loss 4.555 | ppl 23.51 | wps 39740.3 | ups 0.15 | wpb 262134 | bsz 512 | num_updates 27020 | lr 0.000769515 | gnorm 0.539 | clip 0 | loss_scale 8 | train_wall 44267 | gb_free 10.3 | wall 177868
2024-08-06 17:18:43 | INFO | fairseq.trainer | loading train data for epoch 5
2024-08-06 17:18:44 | INFO | fairseq.data.data_utils | loaded 52,822,000 examples from: ./data/data-bin/4/train
2024-08-06 17:18:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6784
2024-08-06 17:18:45 | INFO | fairseq.trainer | begin training epoch 5
2024-08-06 17:18:45 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-06 17:27:36 | INFO | train_inner | epoch 005:     80 / 6784 loss=4.536, ppl=23.19, wps=32239.5, ups=0.12, wpb=261489, bsz=510.7, num_updates=27100, lr=0.000768379, gnorm=0.549, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=178401
2024-08-06 17:38:46 | INFO | train_inner | epoch 005:    180 / 6784 loss=4.537, ppl=23.21, wps=39109.2, ups=0.15, wpb=262144, bsz=512, num_updates=27200, lr=0.000766965, gnorm=0.539, clip=0, loss_scale=8, train_wall=670, gb_free=10.3, wall=179072
2024-08-06 17:49:49 | INFO | train_inner | epoch 005:    280 / 6784 loss=4.536, ppl=23.2, wps=39560.6, ups=0.15, wpb=262144, bsz=512, num_updates=27300, lr=0.000765559, gnorm=0.54, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=179734
2024-08-06 18:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 18:01:02 | INFO | train_inner | epoch 005:    381 / 6784 loss=4.537, ppl=23.21, wps=38945.1, ups=0.15, wpb=262144, bsz=512, num_updates=27400, lr=0.000764161, gnorm=0.526, clip=0, loss_scale=8, train_wall=673, gb_free=10.3, wall=180407
2024-08-06 18:12:09 | INFO | train_inner | epoch 005:    481 / 6784 loss=4.538, ppl=23.24, wps=39307.8, ups=0.15, wpb=262144, bsz=512, num_updates=27500, lr=0.00076277, gnorm=0.564, clip=0, loss_scale=8, train_wall=667, gb_free=10.3, wall=181074
2024-08-06 18:23:14 | INFO | train_inner | epoch 005:    581 / 6784 loss=4.532, ppl=23.14, wps=39414.8, ups=0.15, wpb=262144, bsz=512, num_updates=27600, lr=0.000761387, gnorm=0.542, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=181739
2024-08-06 18:34:20 | INFO | train_inner | epoch 005:    681 / 6784 loss=4.533, ppl=23.15, wps=39342.1, ups=0.15, wpb=262144, bsz=512, num_updates=27700, lr=0.000760011, gnorm=0.52, clip=0, loss_scale=8, train_wall=666, gb_free=10.3, wall=182406
2024-08-06 18:45:28 | INFO | train_inner | epoch 005:    781 / 6784 loss=4.532, ppl=23.14, wps=39242.4, ups=0.15, wpb=262144, bsz=512, num_updates=27800, lr=0.000758643, gnorm=0.559, clip=0, loss_scale=8, train_wall=668, gb_free=10.3, wall=183074
2024-08-06 18:56:36 | INFO | train_inner | epoch 005:    881 / 6784 loss=4.53, ppl=23.11, wps=39268.9, ups=0.15, wpb=262144, bsz=512, num_updates=27900, lr=0.000757282, gnorm=0.528, clip=0, loss_scale=8, train_wall=667, gb_free=10.3, wall=183741
2024-08-06 19:07:40 | INFO | train_inner | epoch 005:    981 / 6784 loss=4.533, ppl=23.15, wps=39489.8, ups=0.15, wpb=262144, bsz=512, num_updates=28000, lr=0.000755929, gnorm=0.561, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=184405
2024-08-06 19:18:36 | INFO | train_inner | epoch 005:   1081 / 6784 loss=4.533, ppl=23.16, wps=39942, ups=0.15, wpb=262144, bsz=512, num_updates=28100, lr=0.000754583, gnorm=0.523, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=185061
2024-08-06 19:29:36 | INFO | train_inner | epoch 005:   1181 / 6784 loss=4.528, ppl=23.07, wps=39734.4, ups=0.15, wpb=262144, bsz=512, num_updates=28200, lr=0.000753244, gnorm=0.552, clip=0, loss_scale=8, train_wall=659, gb_free=10.3, wall=185721
2024-08-06 19:40:30 | INFO | train_inner | epoch 005:   1281 / 6784 loss=4.531, ppl=23.12, wps=40042.4, ups=0.15, wpb=262144, bsz=512, num_updates=28300, lr=0.000751912, gnorm=0.53, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=186376
2024-08-06 19:51:21 | INFO | train_inner | epoch 005:   1381 / 6784 loss=4.53, ppl=23.1, wps=40284, ups=0.15, wpb=262144, bsz=512, num_updates=28400, lr=0.000750587, gnorm=0.556, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=187027
2024-08-06 20:02:14 | INFO | train_inner | epoch 005:   1481 / 6784 loss=4.524, ppl=23.01, wps=40153.8, ups=0.15, wpb=262144, bsz=512, num_updates=28500, lr=0.000749269, gnorm=0.533, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=187679
2024-08-06 20:13:08 | INFO | train_inner | epoch 005:   1581 / 6784 loss=4.529, ppl=23.08, wps=40083.7, ups=0.15, wpb=262144, bsz=512, num_updates=28600, lr=0.000747958, gnorm=0.536, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=188333
2024-08-06 20:24:04 | INFO | train_inner | epoch 005:   1681 / 6784 loss=4.527, ppl=23.05, wps=39945.9, ups=0.15, wpb=262144, bsz=512, num_updates=28700, lr=0.000746653, gnorm=0.549, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=188990
2024-08-06 20:34:57 | INFO | train_inner | epoch 005:   1781 / 6784 loss=4.529, ppl=23.08, wps=40187.9, ups=0.15, wpb=262144, bsz=512, num_updates=28800, lr=0.000745356, gnorm=0.544, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=189642
2024-08-06 20:45:53 | INFO | train_inner | epoch 005:   1881 / 6784 loss=4.526, ppl=23.04, wps=39923.9, ups=0.15, wpb=262144, bsz=512, num_updates=28900, lr=0.000744065, gnorm=0.57, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=190299
2024-08-06 20:56:50 | INFO | train_inner | epoch 005:   1981 / 6784 loss=4.528, ppl=23.07, wps=39898.2, ups=0.15, wpb=262144, bsz=512, num_updates=29000, lr=0.000742781, gnorm=0.548, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=190956
2024-08-06 21:07:42 | INFO | train_inner | epoch 005:   2081 / 6784 loss=4.524, ppl=23, wps=40168.1, ups=0.15, wpb=261898, bsz=511.5, num_updates=29100, lr=0.000741504, gnorm=0.544, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=191608
2024-08-06 21:18:34 | INFO | train_inner | epoch 005:   2181 / 6784 loss=4.519, ppl=22.93, wps=40207.4, ups=0.15, wpb=262144, bsz=512, num_updates=29200, lr=0.000740233, gnorm=0.521, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=192260
2024-08-06 21:29:31 | INFO | train_inner | epoch 005:   2281 / 6784 loss=4.525, ppl=23.02, wps=39890.3, ups=0.15, wpb=262144, bsz=512, num_updates=29300, lr=0.000738969, gnorm=0.559, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=192917
2024-08-06 21:40:24 | INFO | train_inner | epoch 005:   2381 / 6784 loss=4.526, ppl=23.04, wps=40163.5, ups=0.15, wpb=262144, bsz=512, num_updates=29400, lr=0.000737711, gnorm=0.527, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=193569
2024-08-06 21:48:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-06 21:51:19 | INFO | train_inner | epoch 005:   2482 / 6784 loss=4.526, ppl=23.04, wps=40043.9, ups=0.15, wpb=262144, bsz=512, num_updates=29500, lr=0.00073646, gnorm=0.549, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=194224
2024-08-06 22:02:12 | INFO | train_inner | epoch 005:   2582 / 6784 loss=4.522, ppl=22.97, wps=40110.2, ups=0.15, wpb=262144, bsz=512, num_updates=29600, lr=0.000735215, gnorm=0.528, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=194878
2024-08-06 22:13:06 | INFO | train_inner | epoch 005:   2682 / 6784 loss=4.523, ppl=22.99, wps=40116.2, ups=0.15, wpb=262144, bsz=512, num_updates=29700, lr=0.000733976, gnorm=0.534, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=195531
2024-08-06 22:24:01 | INFO | train_inner | epoch 005:   2782 / 6784 loss=4.52, ppl=22.94, wps=40032.6, ups=0.15, wpb=262144, bsz=512, num_updates=29800, lr=0.000732743, gnorm=0.538, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=196186
2024-08-06 22:34:59 | INFO | train_inner | epoch 005:   2882 / 6784 loss=4.52, ppl=22.94, wps=39796.1, ups=0.15, wpb=262144, bsz=512, num_updates=29900, lr=0.000731517, gnorm=0.544, clip=0, loss_scale=8, train_wall=658, gb_free=10.3, wall=196845
2024-08-06 22:45:53 | INFO | train_inner | epoch 005:   2982 / 6784 loss=4.519, ppl=22.93, wps=40127, ups=0.15, wpb=262144, bsz=512, num_updates=30000, lr=0.000730297, gnorm=0.545, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=197498
2024-08-06 22:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 30000 updates
2024-08-06 22:45:53 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_5_30000.pt
2024-08-06 22:46:33 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_5_30000.pt
2024-08-06 22:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_5_30000.pt (epoch 5 @ 30000 updates, score None) (writing took 115.50543908774853 seconds)
2024-08-06 22:58:56 | INFO | train_inner | epoch 005:   3082 / 6784 loss=4.523, ppl=22.99, wps=33441.5, ups=0.13, wpb=262144, bsz=512, num_updates=30100, lr=0.000729083, gnorm=0.549, clip=0, loss_scale=8, train_wall=668, gb_free=10.3, wall=198282
2024-08-06 23:10:02 | INFO | train_inner | epoch 005:   3182 / 6784 loss=4.52, ppl=22.95, wps=39389.1, ups=0.15, wpb=262144, bsz=512, num_updates=30200, lr=0.000727875, gnorm=0.541, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=198947
2024-08-06 23:21:07 | INFO | train_inner | epoch 005:   3282 / 6784 loss=4.515, ppl=22.86, wps=39428.5, ups=0.15, wpb=262144, bsz=512, num_updates=30300, lr=0.000726672, gnorm=0.535, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=199612
2024-08-06 23:32:13 | INFO | train_inner | epoch 005:   3382 / 6784 loss=4.522, ppl=22.97, wps=39340.1, ups=0.15, wpb=262144, bsz=512, num_updates=30400, lr=0.000725476, gnorm=0.554, clip=0, loss_scale=8, train_wall=666, gb_free=10.3, wall=200279
2024-08-06 23:43:17 | INFO | train_inner | epoch 005:   3482 / 6784 loss=4.516, ppl=22.88, wps=39519.5, ups=0.15, wpb=262144, bsz=512, num_updates=30500, lr=0.000724286, gnorm=0.545, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=200942
2024-08-06 23:54:18 | INFO | train_inner | epoch 005:   3582 / 6784 loss=4.517, ppl=22.89, wps=39646.2, ups=0.15, wpb=262144, bsz=512, num_updates=30600, lr=0.000723102, gnorm=0.54, clip=0, loss_scale=8, train_wall=661, gb_free=10.3, wall=201603
2024-08-07 00:05:13 | INFO | train_inner | epoch 005:   3682 / 6784 loss=4.52, ppl=22.94, wps=40016.7, ups=0.15, wpb=262144, bsz=512, num_updates=30700, lr=0.000721923, gnorm=0.549, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=202258
2024-08-07 00:16:06 | INFO | train_inner | epoch 005:   3782 / 6784 loss=4.515, ppl=22.87, wps=40110.5, ups=0.15, wpb=262144, bsz=512, num_updates=30800, lr=0.00072075, gnorm=0.545, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=202912
2024-08-07 00:26:59 | INFO | train_inner | epoch 005:   3882 / 6784 loss=4.513, ppl=22.84, wps=40169.9, ups=0.15, wpb=262144, bsz=512, num_updates=30900, lr=0.000719583, gnorm=0.544, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=203564
2024-08-07 00:37:52 | INFO | train_inner | epoch 005:   3982 / 6784 loss=4.518, ppl=22.92, wps=40067.7, ups=0.15, wpb=261847, bsz=511.4, num_updates=31000, lr=0.000718421, gnorm=0.549, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=204218
2024-08-07 00:48:45 | INFO | train_inner | epoch 005:   4082 / 6784 loss=4.515, ppl=22.86, wps=40152.7, ups=0.15, wpb=262144, bsz=512, num_updates=31100, lr=0.000717265, gnorm=0.58, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=204871
2024-08-07 00:59:41 | INFO | train_inner | epoch 005:   4182 / 6784 loss=4.514, ppl=22.84, wps=39957.6, ups=0.15, wpb=262144, bsz=512, num_updates=31200, lr=0.000716115, gnorm=0.552, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=205527
2024-08-07 01:10:36 | INFO | train_inner | epoch 005:   4282 / 6784 loss=4.513, ppl=22.83, wps=40037.2, ups=0.15, wpb=262144, bsz=512, num_updates=31300, lr=0.00071497, gnorm=0.546, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=206181
2024-08-07 01:21:30 | INFO | train_inner | epoch 005:   4382 / 6784 loss=4.513, ppl=22.83, wps=40106.3, ups=0.15, wpb=262144, bsz=512, num_updates=31400, lr=0.000713831, gnorm=0.535, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=206835
2024-08-07 01:32:23 | INFO | train_inner | epoch 005:   4482 / 6784 loss=4.511, ppl=22.8, wps=40116.2, ups=0.15, wpb=262144, bsz=512, num_updates=31500, lr=0.000712697, gnorm=0.588, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=207489
2024-08-07 01:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-07 01:43:26 | INFO | train_inner | epoch 005:   4583 / 6784 loss=4.517, ppl=22.9, wps=39583, ups=0.15, wpb=262144, bsz=512, num_updates=31600, lr=0.000711568, gnorm=0.544, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=208151
2024-08-07 01:54:23 | INFO | train_inner | epoch 005:   4683 / 6784 loss=4.514, ppl=22.85, wps=39870.3, ups=0.15, wpb=262144, bsz=512, num_updates=31700, lr=0.000710445, gnorm=0.553, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=208808
2024-08-07 02:05:11 | INFO | train_inner | epoch 005:   4783 / 6784 loss=4.508, ppl=22.76, wps=40460.2, ups=0.15, wpb=262144, bsz=512, num_updates=31800, lr=0.000709327, gnorm=0.57, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=209456
2024-08-07 02:16:03 | INFO | train_inner | epoch 005:   4883 / 6784 loss=4.513, ppl=22.84, wps=40192.7, ups=0.15, wpb=262144, bsz=512, num_updates=31900, lr=0.000708214, gnorm=0.561, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=210108
2024-08-07 02:26:53 | INFO | train_inner | epoch 005:   4983 / 6784 loss=4.512, ppl=22.82, wps=40323.8, ups=0.15, wpb=262144, bsz=512, num_updates=32000, lr=0.000707107, gnorm=0.562, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=210759
2024-08-07 02:37:45 | INFO | train_inner | epoch 005:   5083 / 6784 loss=4.511, ppl=22.8, wps=40249, ups=0.15, wpb=262144, bsz=512, num_updates=32100, lr=0.000706005, gnorm=0.542, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=211410
2024-08-07 02:48:36 | INFO | train_inner | epoch 005:   5183 / 6784 loss=4.509, ppl=22.76, wps=40265.3, ups=0.15, wpb=262144, bsz=512, num_updates=32200, lr=0.000704907, gnorm=0.592, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=212061
2024-08-07 02:59:27 | INFO | train_inner | epoch 005:   5283 / 6784 loss=4.511, ppl=22.8, wps=40223.4, ups=0.15, wpb=262144, bsz=512, num_updates=32300, lr=0.000703815, gnorm=0.56, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=212713
2024-08-07 03:10:16 | INFO | train_inner | epoch 005:   5383 / 6784 loss=4.506, ppl=22.72, wps=40402.9, ups=0.15, wpb=262144, bsz=512, num_updates=32400, lr=0.000702728, gnorm=0.538, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=213361
2024-08-07 03:21:06 | INFO | train_inner | epoch 005:   5483 / 6784 loss=4.51, ppl=22.79, wps=40323.9, ups=0.15, wpb=262144, bsz=512, num_updates=32500, lr=0.000701646, gnorm=0.578, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=214012
2024-08-07 03:32:00 | INFO | train_inner | epoch 005:   5583 / 6784 loss=4.507, ppl=22.73, wps=40106, ups=0.15, wpb=262144, bsz=512, num_updates=32600, lr=0.000700569, gnorm=0.539, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=214665
2024-08-07 03:42:52 | INFO | train_inner | epoch 005:   5683 / 6784 loss=4.507, ppl=22.73, wps=40226.8, ups=0.15, wpb=262144, bsz=512, num_updates=32700, lr=0.000699497, gnorm=0.526, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=215317
2024-08-07 03:53:43 | INFO | train_inner | epoch 005:   5783 / 6784 loss=4.513, ppl=22.83, wps=40227.8, ups=0.15, wpb=262144, bsz=512, num_updates=32800, lr=0.00069843, gnorm=0.548, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=215968
2024-08-07 04:04:34 | INFO | train_inner | epoch 005:   5883 / 6784 loss=4.511, ppl=22.8, wps=40255.1, ups=0.15, wpb=262142, bsz=512, num_updates=32900, lr=0.000697368, gnorm=0.541, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=216620
2024-08-07 04:15:24 | INFO | train_inner | epoch 005:   5983 / 6784 loss=4.507, ppl=22.73, wps=40335.2, ups=0.15, wpb=262144, bsz=512, num_updates=33000, lr=0.000696311, gnorm=0.588, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=217270
2024-08-07 04:26:20 | INFO | train_inner | epoch 005:   6083 / 6784 loss=4.508, ppl=22.76, wps=39950.1, ups=0.15, wpb=262144, bsz=512, num_updates=33100, lr=0.000695258, gnorm=0.541, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=217926
2024-08-07 04:37:28 | INFO | train_inner | epoch 005:   6183 / 6784 loss=4.505, ppl=22.7, wps=39290.5, ups=0.15, wpb=262144, bsz=512, num_updates=33200, lr=0.00069421, gnorm=0.553, clip=0, loss_scale=8, train_wall=667, gb_free=10.3, wall=218593
2024-08-07 04:48:30 | INFO | train_inner | epoch 005:   6283 / 6784 loss=4.505, ppl=22.71, wps=39551.6, ups=0.15, wpb=262144, bsz=512, num_updates=33300, lr=0.000693167, gnorm=0.555, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=219256
2024-08-07 04:59:33 | INFO | train_inner | epoch 005:   6383 / 6784 loss=4.505, ppl=22.7, wps=39569.8, ups=0.15, wpb=262144, bsz=512, num_updates=33400, lr=0.000692129, gnorm=0.562, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=219918
2024-08-07 05:10:37 | INFO | train_inner | epoch 005:   6483 / 6784 loss=4.5, ppl=22.63, wps=39455.5, ups=0.15, wpb=262144, bsz=512, num_updates=33500, lr=0.000691095, gnorm=0.572, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=220583
2024-08-07 05:21:40 | INFO | train_inner | epoch 005:   6583 / 6784 loss=4.501, ppl=22.64, wps=39565.9, ups=0.15, wpb=262144, bsz=512, num_updates=33600, lr=0.000690066, gnorm=0.558, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=221245
2024-08-07 05:25:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-07 05:32:43 | INFO | train_inner | epoch 005:   6684 / 6784 loss=4.503, ppl=22.67, wps=39563.1, ups=0.15, wpb=262144, bsz=512, num_updates=33700, lr=0.000689041, gnorm=0.549, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=221908
2024-08-07 05:43:35 | INFO | train_inner | epoch 005:   6784 / 6784 loss=4.504, ppl=22.68, wps=40046.9, ups=0.15, wpb=261489, bsz=510.7, num_updates=33800, lr=0.000688021, gnorm=0.552, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=222561
2024-08-07 05:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33800 updates
2024-08-07 05:43:35 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint5.pt
2024-08-07 05:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint5.pt
2024-08-07 05:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint5.pt (epoch 5 @ 33800 updates, score None) (writing took 144.05050436779857 seconds)
2024-08-07 05:46:00 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-08-07 05:46:00 | INFO | train | epoch 005 | loss 4.519 | ppl 22.92 | wps 39637.7 | ups 0.15 | wpb 262126 | bsz 512 | num_updates 33800 | lr 0.000688021 | gnorm 0.548 | clip 0 | loss_scale 8 | train_wall 44556 | gb_free 10.3 | wall 222705
2024-08-07 05:46:00 | INFO | fairseq.trainer | loading train data for epoch 6
2024-08-07 05:46:00 | INFO | fairseq.data.data_utils | loaded 52,348,000 examples from: ./data/data-bin/5/train
2024-08-07 05:46:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6735
2024-08-07 05:46:01 | INFO | fairseq.trainer | begin training epoch 6
2024-08-07 05:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-07 05:56:56 | INFO | train_inner | epoch 006:    100 / 6735 loss=4.507, ppl=22.73, wps=32733.1, ups=0.12, wpb=262144, bsz=512, num_updates=33900, lr=0.000687005, gnorm=0.584, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=223362
2024-08-07 06:07:48 | INFO | train_inner | epoch 006:    200 / 6735 loss=4.503, ppl=22.67, wps=40244.6, ups=0.15, wpb=262144, bsz=512, num_updates=34000, lr=0.000685994, gnorm=0.537, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=224013
2024-08-07 06:18:40 | INFO | train_inner | epoch 006:    300 / 6735 loss=4.503, ppl=22.67, wps=40209.8, ups=0.15, wpb=262144, bsz=512, num_updates=34100, lr=0.000684988, gnorm=0.569, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=224665
2024-08-07 06:29:37 | INFO | train_inner | epoch 006:    400 / 6735 loss=4.5, ppl=22.62, wps=39890.1, ups=0.15, wpb=262144, bsz=512, num_updates=34200, lr=0.000683986, gnorm=0.543, clip=0, loss_scale=8, train_wall=657, gb_free=10.3, wall=225322
2024-08-07 06:40:30 | INFO | train_inner | epoch 006:    500 / 6735 loss=4.503, ppl=22.67, wps=40113.1, ups=0.15, wpb=262144, bsz=512, num_updates=34300, lr=0.000682988, gnorm=0.585, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=225976
2024-08-07 06:51:31 | INFO | train_inner | epoch 006:    600 / 6735 loss=4.506, ppl=22.72, wps=39648.6, ups=0.15, wpb=262144, bsz=512, num_updates=34400, lr=0.000681994, gnorm=0.557, clip=0, loss_scale=8, train_wall=661, gb_free=10.3, wall=226637
2024-08-07 07:02:30 | INFO | train_inner | epoch 006:    700 / 6735 loss=4.503, ppl=22.68, wps=39815.9, ups=0.15, wpb=262144, bsz=512, num_updates=34500, lr=0.000681005, gnorm=0.565, clip=0, loss_scale=8, train_wall=658, gb_free=10.3, wall=227295
2024-08-07 07:13:19 | INFO | train_inner | epoch 006:    800 / 6735 loss=4.505, ppl=22.7, wps=40397.4, ups=0.15, wpb=262144, bsz=512, num_updates=34600, lr=0.00068002, gnorm=0.551, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=227944
2024-08-07 07:24:09 | INFO | train_inner | epoch 006:    900 / 6735 loss=4.506, ppl=22.72, wps=40341.8, ups=0.15, wpb=262144, bsz=512, num_updates=34700, lr=0.00067904, gnorm=0.55, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=228594
2024-08-07 07:34:59 | INFO | train_inner | epoch 006:   1000 / 6735 loss=4.503, ppl=22.67, wps=40336.3, ups=0.15, wpb=262144, bsz=512, num_updates=34800, lr=0.000678064, gnorm=0.601, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=229244
2024-08-07 07:45:48 | INFO | train_inner | epoch 006:   1100 / 6735 loss=4.503, ppl=22.68, wps=40317.8, ups=0.15, wpb=261898, bsz=511.5, num_updates=34900, lr=0.000677091, gnorm=0.559, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=229893
2024-08-07 07:56:39 | INFO | train_inner | epoch 006:   1200 / 6735 loss=4.504, ppl=22.69, wps=40265.6, ups=0.15, wpb=262144, bsz=512, num_updates=35000, lr=0.000676123, gnorm=0.549, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=230544
2024-08-07 08:07:32 | INFO | train_inner | epoch 006:   1300 / 6735 loss=4.501, ppl=22.64, wps=40180.3, ups=0.15, wpb=262144, bsz=512, num_updates=35100, lr=0.00067516, gnorm=0.554, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=231197
2024-08-07 08:18:20 | INFO | train_inner | epoch 006:   1400 / 6735 loss=4.499, ppl=22.61, wps=40413.5, ups=0.15, wpb=262144, bsz=512, num_updates=35200, lr=0.0006742, gnorm=0.587, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=231846
2024-08-07 08:29:14 | INFO | train_inner | epoch 006:   1500 / 6735 loss=4.502, ppl=22.65, wps=40092.9, ups=0.15, wpb=262144, bsz=512, num_updates=35300, lr=0.000673244, gnorm=0.569, clip=0, loss_scale=8, train_wall=654, gb_free=10.3, wall=232499
2024-08-07 08:40:06 | INFO | train_inner | epoch 006:   1600 / 6735 loss=4.498, ppl=22.6, wps=40197.2, ups=0.15, wpb=262144, bsz=512, num_updates=35400, lr=0.000672293, gnorm=0.601, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=233151
2024-08-07 08:50:58 | INFO | train_inner | epoch 006:   1700 / 6735 loss=4.496, ppl=22.57, wps=40218, ups=0.15, wpb=262144, bsz=512, num_updates=35500, lr=0.000671345, gnorm=0.543, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=233803
2024-08-07 09:01:49 | INFO | train_inner | epoch 006:   1800 / 6735 loss=4.499, ppl=22.61, wps=40283.9, ups=0.15, wpb=262144, bsz=512, num_updates=35600, lr=0.000670402, gnorm=0.556, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=234454
2024-08-07 09:11:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-07 09:12:45 | INFO | train_inner | epoch 006:   1901 / 6735 loss=4.5, ppl=22.62, wps=39936.1, ups=0.15, wpb=262144, bsz=512, num_updates=35700, lr=0.000669462, gnorm=0.552, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=235110
2024-08-07 09:23:37 | INFO | train_inner | epoch 006:   2001 / 6735 loss=4.498, ppl=22.6, wps=40237.1, ups=0.15, wpb=262144, bsz=512, num_updates=35800, lr=0.000668526, gnorm=0.564, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=235762
2024-08-07 09:34:32 | INFO | train_inner | epoch 006:   2101 / 6735 loss=4.499, ppl=22.61, wps=39986.3, ups=0.15, wpb=262144, bsz=512, num_updates=35900, lr=0.000667595, gnorm=0.538, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=236418
2024-08-07 09:45:32 | INFO | train_inner | epoch 006:   2201 / 6735 loss=4.497, ppl=22.58, wps=39713.9, ups=0.15, wpb=262144, bsz=512, num_updates=36000, lr=0.000666667, gnorm=0.589, clip=0, loss_scale=8, train_wall=660, gb_free=10.3, wall=237078
2024-08-07 09:56:25 | INFO | train_inner | epoch 006:   2301 / 6735 loss=4.492, ppl=22.5, wps=40164.7, ups=0.15, wpb=262144, bsz=512, num_updates=36100, lr=0.000665743, gnorm=0.596, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=237730
2024-08-07 10:07:20 | INFO | train_inner | epoch 006:   2401 / 6735 loss=4.498, ppl=22.6, wps=40012.3, ups=0.15, wpb=262144, bsz=512, num_updates=36200, lr=0.000664822, gnorm=0.566, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=238385
2024-08-07 10:18:20 | INFO | train_inner | epoch 006:   2501 / 6735 loss=4.491, ppl=22.48, wps=39732.8, ups=0.15, wpb=262144, bsz=512, num_updates=36300, lr=0.000663906, gnorm=0.587, clip=0, loss_scale=8, train_wall=659, gb_free=10.3, wall=239045
2024-08-07 10:29:10 | INFO | train_inner | epoch 006:   2601 / 6735 loss=4.492, ppl=22.5, wps=40332.3, ups=0.15, wpb=262144, bsz=512, num_updates=36400, lr=0.000662994, gnorm=0.533, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=239695
2024-08-07 10:39:59 | INFO | train_inner | epoch 006:   2701 / 6735 loss=4.49, ppl=22.47, wps=40374, ups=0.15, wpb=262144, bsz=512, num_updates=36500, lr=0.000662085, gnorm=0.561, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=240344
2024-08-07 10:50:50 | INFO | train_inner | epoch 006:   2801 / 6735 loss=4.491, ppl=22.48, wps=40257.9, ups=0.15, wpb=262144, bsz=512, num_updates=36600, lr=0.00066118, gnorm=0.556, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=240996
2024-08-07 11:01:43 | INFO | train_inner | epoch 006:   2901 / 6735 loss=4.495, ppl=22.55, wps=40162.7, ups=0.15, wpb=262144, bsz=512, num_updates=36700, lr=0.000660278, gnorm=0.546, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=241648
2024-08-07 11:12:36 | INFO | train_inner | epoch 006:   3001 / 6735 loss=4.486, ppl=22.4, wps=40170.8, ups=0.15, wpb=262144, bsz=512, num_updates=36800, lr=0.00065938, gnorm=0.571, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=242301
2024-08-07 11:23:30 | INFO | train_inner | epoch 006:   3101 / 6735 loss=4.491, ppl=22.48, wps=40035, ups=0.15, wpb=262144, bsz=512, num_updates=36900, lr=0.000658486, gnorm=0.574, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=242956
2024-08-07 11:34:24 | INFO | train_inner | epoch 006:   3201 / 6735 loss=4.493, ppl=22.51, wps=40127.5, ups=0.15, wpb=262144, bsz=512, num_updates=37000, lr=0.000657596, gnorm=0.573, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=243609
2024-08-07 11:45:19 | INFO | train_inner | epoch 006:   3301 / 6735 loss=4.496, ppl=22.57, wps=40003.4, ups=0.15, wpb=262144, bsz=512, num_updates=37100, lr=0.000656709, gnorm=0.566, clip=0, loss_scale=8, train_wall=655, gb_free=10.3, wall=244264
2024-08-07 11:56:15 | INFO | train_inner | epoch 006:   3401 / 6735 loss=4.494, ppl=22.53, wps=39967.6, ups=0.15, wpb=262144, bsz=512, num_updates=37200, lr=0.000655826, gnorm=0.561, clip=0, loss_scale=8, train_wall=656, gb_free=10.3, wall=244920
2024-08-07 12:07:08 | INFO | train_inner | epoch 006:   3501 / 6735 loss=4.494, ppl=22.53, wps=40111.8, ups=0.15, wpb=262144, bsz=512, num_updates=37300, lr=0.000654946, gnorm=0.577, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=245574
2024-08-07 12:18:00 | INFO | train_inner | epoch 006:   3601 / 6735 loss=4.486, ppl=22.42, wps=40261.7, ups=0.15, wpb=262144, bsz=512, num_updates=37400, lr=0.00065407, gnorm=0.577, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=246225
2024-08-07 12:28:53 | INFO | train_inner | epoch 006:   3701 / 6735 loss=4.486, ppl=22.42, wps=40121.4, ups=0.15, wpb=262144, bsz=512, num_updates=37500, lr=0.000653197, gnorm=0.558, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=246878
2024-08-07 12:40:01 | INFO | train_inner | epoch 006:   3801 / 6735 loss=4.486, ppl=22.42, wps=39230.1, ups=0.15, wpb=262144, bsz=512, num_updates=37600, lr=0.000652328, gnorm=0.544, clip=0, loss_scale=8, train_wall=668, gb_free=10.3, wall=247546
2024-08-07 12:51:14 | INFO | train_inner | epoch 006:   3901 / 6735 loss=4.488, ppl=22.43, wps=38938.5, ups=0.15, wpb=262144, bsz=512, num_updates=37700, lr=0.000651462, gnorm=0.57, clip=0, loss_scale=8, train_wall=673, gb_free=10.3, wall=248220
2024-08-07 13:00:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-07 13:02:34 | INFO | train_inner | epoch 006:   4002 / 6735 loss=4.486, ppl=22.41, wps=38544.7, ups=0.15, wpb=262144, bsz=512, num_updates=37800, lr=0.0006506, gnorm=0.534, clip=0, loss_scale=8, train_wall=680, gb_free=10.3, wall=248900
2024-08-07 13:13:48 | INFO | train_inner | epoch 006:   4102 / 6735 loss=4.484, ppl=22.37, wps=38919.2, ups=0.15, wpb=262144, bsz=512, num_updates=37900, lr=0.000649741, gnorm=0.585, clip=0, loss_scale=8, train_wall=673, gb_free=10.3, wall=249573
2024-08-07 13:24:57 | INFO | train_inner | epoch 006:   4202 / 6735 loss=4.492, ppl=22.5, wps=39184.6, ups=0.15, wpb=262144, bsz=512, num_updates=38000, lr=0.000648886, gnorm=0.583, clip=0, loss_scale=8, train_wall=669, gb_free=10.3, wall=250242
2024-08-07 13:36:10 | INFO | train_inner | epoch 006:   4302 / 6735 loss=4.49, ppl=22.47, wps=38970.4, ups=0.15, wpb=262144, bsz=512, num_updates=38100, lr=0.000648034, gnorm=0.565, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=250915
2024-08-07 13:47:17 | INFO | train_inner | epoch 006:   4402 / 6735 loss=4.486, ppl=22.41, wps=39310.4, ups=0.15, wpb=262144, bsz=512, num_updates=38200, lr=0.000647185, gnorm=0.573, clip=0, loss_scale=8, train_wall=667, gb_free=10.3, wall=251582
2024-08-07 13:58:20 | INFO | train_inner | epoch 006:   4502 / 6735 loss=4.486, ppl=22.41, wps=39507.9, ups=0.15, wpb=262144, bsz=512, num_updates=38300, lr=0.000646339, gnorm=0.586, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=252245
2024-08-07 14:09:25 | INFO | train_inner | epoch 006:   4602 / 6735 loss=4.483, ppl=22.36, wps=39436.5, ups=0.15, wpb=262144, bsz=512, num_updates=38400, lr=0.000645497, gnorm=0.573, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=252910
2024-08-07 14:20:28 | INFO | train_inner | epoch 006:   4702 / 6735 loss=4.489, ppl=22.46, wps=39551.5, ups=0.15, wpb=262144, bsz=512, num_updates=38500, lr=0.000644658, gnorm=0.573, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=253573
2024-08-07 14:31:33 | INFO | train_inner | epoch 006:   4802 / 6735 loss=4.487, ppl=22.42, wps=39405.1, ups=0.15, wpb=262144, bsz=512, num_updates=38600, lr=0.000643823, gnorm=0.557, clip=0, loss_scale=8, train_wall=665, gb_free=10.3, wall=254238
2024-08-07 14:42:38 | INFO | train_inner | epoch 006:   4902 / 6735 loss=4.481, ppl=22.33, wps=39433, ups=0.15, wpb=262144, bsz=512, num_updates=38700, lr=0.00064299, gnorm=0.552, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=254903
2024-08-07 14:53:42 | INFO | train_inner | epoch 006:   5002 / 6735 loss=4.483, ppl=22.36, wps=39448.7, ups=0.15, wpb=262144, bsz=512, num_updates=38800, lr=0.000642161, gnorm=0.592, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=255567
2024-08-07 15:04:46 | INFO | train_inner | epoch 006:   5102 / 6735 loss=4.486, ppl=22.4, wps=39487, ups=0.15, wpb=262144, bsz=512, num_updates=38900, lr=0.000641335, gnorm=0.562, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=256231
2024-08-07 15:15:51 | INFO | train_inner | epoch 006:   5202 / 6735 loss=4.49, ppl=22.48, wps=39443.8, ups=0.15, wpb=262144, bsz=512, num_updates=39000, lr=0.000640513, gnorm=0.576, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=256896
2024-08-07 15:26:55 | INFO | train_inner | epoch 006:   5302 / 6735 loss=4.485, ppl=22.39, wps=39465.3, ups=0.15, wpb=262144, bsz=512, num_updates=39100, lr=0.000639693, gnorm=0.568, clip=0, loss_scale=8, train_wall=664, gb_free=10.3, wall=257560
2024-08-07 15:37:58 | INFO | train_inner | epoch 006:   5402 / 6735 loss=4.482, ppl=22.35, wps=39523.3, ups=0.15, wpb=262144, bsz=512, num_updates=39200, lr=0.000638877, gnorm=0.554, clip=0, loss_scale=8, train_wall=663, gb_free=10.3, wall=258223
2024-08-07 15:49:04 | INFO | train_inner | epoch 006:   5502 / 6735 loss=4.484, ppl=22.37, wps=39348.1, ups=0.15, wpb=262140, bsz=512, num_updates=39300, lr=0.000638063, gnorm=0.593, clip=0, loss_scale=8, train_wall=666, gb_free=10.3, wall=258890
2024-08-07 16:00:04 | INFO | train_inner | epoch 006:   5602 / 6735 loss=4.484, ppl=22.37, wps=39710.9, ups=0.15, wpb=262144, bsz=512, num_updates=39400, lr=0.000637253, gnorm=0.577, clip=0, loss_scale=8, train_wall=660, gb_free=10.3, wall=259550
2024-08-07 16:11:07 | INFO | train_inner | epoch 006:   5702 / 6735 loss=4.482, ppl=22.35, wps=39559.9, ups=0.15, wpb=262144, bsz=512, num_updates=39500, lr=0.000636446, gnorm=0.572, clip=0, loss_scale=8, train_wall=662, gb_free=10.3, wall=260212
2024-08-07 16:22:13 | INFO | train_inner | epoch 006:   5802 / 6735 loss=4.48, ppl=22.32, wps=39349, ups=0.15, wpb=262144, bsz=512, num_updates=39600, lr=0.000635642, gnorm=0.582, clip=0, loss_scale=8, train_wall=666, gb_free=10.3, wall=260879
2024-08-07 16:33:24 | INFO | train_inner | epoch 006:   5902 / 6735 loss=4.48, ppl=22.32, wps=39081, ups=0.15, wpb=262144, bsz=512, num_updates=39700, lr=0.000634841, gnorm=0.568, clip=0, loss_scale=8, train_wall=670, gb_free=10.3, wall=261549
2024-08-07 16:44:37 | INFO | train_inner | epoch 006:   6002 / 6735 loss=4.48, ppl=22.31, wps=38977.2, ups=0.15, wpb=262144, bsz=512, num_updates=39800, lr=0.000634043, gnorm=0.561, clip=0, loss_scale=8, train_wall=672, gb_free=10.3, wall=262222
2024-08-07 16:55:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-08-07 16:55:45 | INFO | train_inner | epoch 006:   6103 / 6735 loss=4.479, ppl=22.31, wps=39195.2, ups=0.15, wpb=262144, bsz=512, num_updates=39900, lr=0.000633248, gnorm=0.561, clip=0, loss_scale=8, train_wall=669, gb_free=10.3, wall=262891
2024-08-07 17:06:52 | INFO | train_inner | epoch 006:   6203 / 6735 loss=4.481, ppl=22.33, wps=39323.2, ups=0.15, wpb=262144, bsz=512, num_updates=40000, lr=0.000632456, gnorm=0.602, clip=0, loss_scale=8, train_wall=666, gb_free=10.3, wall=263557
2024-08-07 17:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40000 updates
2024-08-07 17:06:52 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_6_40000.pt
2024-08-07 17:07:33 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_6_40000.pt
2024-08-07 17:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_6_40000.pt (epoch 6 @ 40000 updates, score None) (writing took 117.23620974831283 seconds)
2024-08-07 17:19:40 | INFO | train_inner | epoch 006:   6303 / 6735 loss=4.481, ppl=22.32, wps=34144.9, ups=0.13, wpb=262144, bsz=512, num_updates=40100, lr=0.000631666, gnorm=0.573, clip=0, loss_scale=8, train_wall=650, gb_free=10.3, wall=264325
2024-08-07 17:30:29 | INFO | train_inner | epoch 006:   6403 / 6735 loss=4.484, ppl=22.37, wps=40362, ups=0.15, wpb=261847, bsz=511.4, num_updates=40200, lr=0.00063088, gnorm=0.558, clip=0, loss_scale=8, train_wall=648, gb_free=10.3, wall=264974
2024-08-07 17:41:22 | INFO | train_inner | epoch 006:   6503 / 6735 loss=4.479, ppl=22.3, wps=40130.6, ups=0.15, wpb=262144, bsz=512, num_updates=40300, lr=0.000630097, gnorm=0.567, clip=0, loss_scale=8, train_wall=653, gb_free=10.3, wall=265627
2024-08-07 17:52:13 | INFO | train_inner | epoch 006:   6603 / 6735 loss=4.485, ppl=22.39, wps=40233, ups=0.15, wpb=262144, bsz=512, num_updates=40400, lr=0.000629317, gnorm=0.579, clip=0, loss_scale=8, train_wall=651, gb_free=10.3, wall=266279
2024-08-07 18:03:03 | INFO | train_inner | epoch 006:   6703 / 6735 loss=4.481, ppl=22.33, wps=40346.9, ups=0.15, wpb=262144, bsz=512, num_updates=40500, lr=0.000628539, gnorm=0.572, clip=0, loss_scale=8, train_wall=649, gb_free=10.3, wall=266928
2024-08-07 18:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40532 updates
2024-08-07 18:06:32 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint6.pt
2024-08-07 18:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint6.pt
2024-08-07 18:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint6.pt (epoch 6 @ 40532 updates, score None) (writing took 115.01651642471552 seconds)
2024-08-07 18:08:27 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-08-07 18:08:27 | INFO | train | epoch 006 | loss 4.491 | ppl 22.49 | wps 39610.8 | ups 0.15 | wpb 262116 | bsz 511.9 | num_updates 40532 | lr 0.000628291 | gnorm 0.567 | clip 0 | loss_scale 8 | train_wall 44295 | gb_free 10.3 | wall 267252
2024-08-07 18:08:27 | INFO | fairseq.trainer | loading train data for epoch 7
2024-08-07 18:08:28 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-08-07 18:08:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-08-07 18:08:29 | INFO | fairseq.trainer | begin training epoch 7
2024-08-07 18:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2024-08-07 18:15:52 | INFO | train_inner | epoch 007:     68 / 6796 loss=4.481, ppl=22.33, wps=33913, ups=0.13, wpb=260833, bsz=509.4, num_updates=40600, lr=0.000627765, gnorm=0.57, clip=0, loss_scale=8, train_wall=652, gb_free=10.3, wall=267698
2024-08-07 18:15:52 | INFO | fairseq_cli.train | Stopping training due to num_updates: 40600 >= max_update: 40600
2024-08-07 18:15:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 40600 updates
2024-08-07 18:15:52 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_last.pt
2024-08-07 18:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_last.pt
2024-08-07 18:16:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_small/checkpoint_last.pt (epoch 7 @ 40600 updates, score None) (writing took 41.5095165874809 seconds)
2024-08-07 18:16:34 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-08-07 18:16:34 | INFO | train | epoch 007 | loss 4.482 | ppl 22.35 | wps 36631.7 | ups 0.14 | wpb 262144 | bsz 512 | num_updates 40600 | lr 0.000627765 | gnorm 0.564 | clip 0 | loss_scale 8 | train_wall 443 | gb_free 10.3 | wall 267739
2024-08-07 18:16:34 | INFO | fairseq_cli.train | done training in 267737.3 seconds
Amaitu da
