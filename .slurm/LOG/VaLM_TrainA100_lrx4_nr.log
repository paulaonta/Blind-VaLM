Hasi da
2024-05-24 23:17:14 | INFO | fairseq.distributed.utils | setting CUDA device=1 on rank 1
2024-05-24 23:17:14 | INFO | fairseq.distributed.utils | setting CUDA device=3 on rank 3
2024-05-24 23:17:14 | INFO | fairseq.distributed.utils | setting CUDA device=2 on rank 2
2024-05-24 23:17:14 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-05-24 23:17:14 | INFO | fairseq.distributed.utils | initialized host trumoi as rank 0
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | initialized host trumoi as rank 1
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | initialized host trumoi as rank 3
2024-05-24 23:17:15 | INFO | fairseq.distributed.utils | initialized host trumoi as rank 2
NCCL version 2.18.1+cuda12.1
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-05-24 23:17:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'VaLM-baseline', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 65536, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 65536, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40600, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './CHECKPOINTS/checkpoint_valmA100_40600upd_nr', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 12, 'decoder_attention_heads': 12, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False, 'use_knn_datastore': False, 'load_knn_datastore': False, 'dstore_fp16': False, 'use_gpu_to_search': False, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 8, 'probe': 32, 'dstore_filename': 'data/datastore', 'use_joint_attention': True, 'joint_layer_index': 2}, 'task': {'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-05-24 23:17:30 | INFO | fairseq.tasks.language_modeling | dictionary: 49412 types
2024-05-24 23:17:34 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(49412, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-9): 10 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerwithJointAttention(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_k_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_v_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=49412, bias=False)
  )
)
2024-05-24 23:17:34 | INFO | fairseq_cli.train | task: LanguageModelingTask
2024-05-24 23:17:34 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2024-05-24 23:17:34 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2024-05-24 23:17:34 | INFO | fairseq_cli.train | num. shared model params: 124,187,136 (num. trained: 124,187,136)
2024-05-24 23:17:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-05-24 23:17:35 | INFO | fairseq.data.data_utils | loaded 5,000 examples from: ./data/data-bin/0/valid
2024-05-24 23:17:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-05-24 23:17:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-05-24 23:17:45 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.150 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-05-24 23:17:45 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.150 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-05-24 23:17:45 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.150 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-05-24 23:17:45 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.150 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-05-24 23:17:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-05-24 23:17:45 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2024-05-24 23:17:45 | INFO | fairseq_cli.train | max tokens per device = 65536 and max sentences per device = None
2024-05-24 23:17:45 | INFO | fairseq.trainer | Preparing to load checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_last.pt
2024-05-24 23:17:45 | INFO | fairseq.trainer | No existing checkpoint found ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_last.pt
2024-05-24 23:17:45 | INFO | fairseq.trainer | loading train data for epoch 1
2024-05-24 23:19:41 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-05-24 23:19:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-05-24 23:20:21 | INFO | fairseq.trainer | begin training epoch 1
2024-05-24 23:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-24 23:20:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2024-05-24 23:20:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2024-05-24 23:20:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-05-24 23:20:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-05-24 23:20:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-24 23:21:38 | INFO | train_inner | epoch 001:    105 / 6796 loss=12.436, ppl=5539.5, wps=428193, ups=1.63, wpb=262144, bsz=512, num_updates=100, lr=0.000125098, gnorm=10.356, clip=75, loss_scale=4, train_wall=77, gb_free=12.6, wall=233
2024-05-24 23:22:38 | INFO | train_inner | epoch 001:    205 / 6796 loss=9.019, ppl=518.72, wps=435140, ups=1.66, wpb=262144, bsz=512, num_updates=200, lr=0.000250095, gnorm=1.792, clip=37, loss_scale=4, train_wall=60, gb_free=12.6, wall=293
2024-05-24 23:23:38 | INFO | train_inner | epoch 001:    305 / 6796 loss=8.319, ppl=319.27, wps=435408, ups=1.66, wpb=262144, bsz=512, num_updates=300, lr=0.000375093, gnorm=1.919, clip=26, loss_scale=4, train_wall=60, gb_free=12.6, wall=353
2024-05-24 23:24:38 | INFO | train_inner | epoch 001:    405 / 6796 loss=7.883, ppl=236.02, wps=435489, ups=1.66, wpb=262144, bsz=512, num_updates=400, lr=0.00050009, gnorm=1.804, clip=33, loss_scale=4, train_wall=60, gb_free=12.6, wall=413
2024-05-24 23:25:39 | INFO | train_inner | epoch 001:    505 / 6796 loss=7.436, ppl=173.21, wps=435327, ups=1.66, wpb=262144, bsz=512, num_updates=500, lr=0.000625087, gnorm=1.594, clip=17, loss_scale=4, train_wall=60, gb_free=12.6, wall=474
2024-05-24 23:26:39 | INFO | train_inner | epoch 001:    605 / 6796 loss=7.103, ppl=137.47, wps=435838, ups=1.66, wpb=262144, bsz=512, num_updates=600, lr=0.000750085, gnorm=1.522, clip=18, loss_scale=4, train_wall=60, gb_free=12.6, wall=534
2024-05-24 23:27:39 | INFO | train_inner | epoch 001:    705 / 6796 loss=6.793, ppl=110.86, wps=434917, ups=1.66, wpb=261530, bsz=510.8, num_updates=700, lr=0.000875082, gnorm=1.251, clip=1, loss_scale=4, train_wall=60, gb_free=12.6, wall=594
2024-05-24 23:28:39 | INFO | train_inner | epoch 001:    805 / 6796 loss=6.544, ppl=93.3, wps=436021, ups=1.66, wpb=262144, bsz=512, num_updates=800, lr=0.00100008, gnorm=1.18, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=654
2024-05-24 23:29:39 | INFO | train_inner | epoch 001:    905 / 6796 loss=6.365, ppl=82.43, wps=435626, ups=1.66, wpb=262144, bsz=512, num_updates=900, lr=0.00112508, gnorm=1.133, clip=2, loss_scale=4, train_wall=60, gb_free=12.6, wall=714
2024-05-24 23:30:39 | INFO | train_inner | epoch 001:   1005 / 6796 loss=6.193, ppl=73.17, wps=435593, ups=1.66, wpb=262144, bsz=512, num_updates=1000, lr=0.00125008, gnorm=1.002, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=774
2024-05-24 23:31:40 | INFO | train_inner | epoch 001:   1105 / 6796 loss=6.059, ppl=66.69, wps=435573, ups=1.66, wpb=262144, bsz=512, num_updates=1100, lr=0.00137507, gnorm=0.919, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=835
2024-05-24 23:32:40 | INFO | train_inner | epoch 001:   1205 / 6796 loss=5.957, ppl=62.14, wps=435960, ups=1.66, wpb=262144, bsz=512, num_updates=1200, lr=0.00150007, gnorm=0.883, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=895
2024-05-24 23:33:40 | INFO | train_inner | epoch 001:   1305 / 6796 loss=5.885, ppl=59.09, wps=435906, ups=1.66, wpb=262144, bsz=512, num_updates=1300, lr=0.00162507, gnorm=0.84, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=955
2024-05-24 23:34:40 | INFO | train_inner | epoch 001:   1405 / 6796 loss=5.82, ppl=56.47, wps=436072, ups=1.66, wpb=262144, bsz=512, num_updates=1400, lr=0.00175007, gnorm=0.795, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1015
2024-05-24 23:35:40 | INFO | train_inner | epoch 001:   1505 / 6796 loss=5.767, ppl=54.46, wps=436051, ups=1.66, wpb=262144, bsz=512, num_updates=1500, lr=0.00187506, gnorm=0.766, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1075
2024-05-24 23:36:40 | INFO | train_inner | epoch 001:   1605 / 6796 loss=5.728, ppl=53, wps=436066, ups=1.66, wpb=262144, bsz=512, num_updates=1600, lr=0.00200006, gnorm=0.771, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1135
2024-05-24 23:37:40 | INFO | train_inner | epoch 001:   1705 / 6796 loss=5.683, ppl=51.38, wps=436312, ups=1.66, wpb=262144, bsz=512, num_updates=1700, lr=0.00212506, gnorm=0.737, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1195
2024-05-24 23:38:40 | INFO | train_inner | epoch 001:   1805 / 6796 loss=5.652, ppl=50.3, wps=435966, ups=1.66, wpb=262144, bsz=512, num_updates=1800, lr=0.00225005, gnorm=0.72, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1255
2024-05-24 23:39:41 | INFO | train_inner | epoch 001:   1905 / 6796 loss=5.617, ppl=49.08, wps=435719, ups=1.66, wpb=262144, bsz=512, num_updates=1900, lr=0.00237505, gnorm=0.702, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1316
2024-05-24 23:40:41 | INFO | train_inner | epoch 001:   2005 / 6796 loss=5.589, ppl=48.14, wps=436150, ups=1.66, wpb=262144, bsz=512, num_updates=2000, lr=0.00250005, gnorm=0.685, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1376
2024-05-24 23:41:41 | INFO | train_inner | epoch 001:   2105 / 6796 loss=5.565, ppl=47.34, wps=436182, ups=1.66, wpb=262144, bsz=512, num_updates=2100, lr=0.00262505, gnorm=0.665, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1436
2024-05-24 23:42:41 | INFO | train_inner | epoch 001:   2205 / 6796 loss=5.546, ppl=46.71, wps=436121, ups=1.66, wpb=262144, bsz=512, num_updates=2200, lr=0.00275005, gnorm=0.637, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1496
2024-05-24 23:43:41 | INFO | train_inner | epoch 001:   2305 / 6796 loss=5.525, ppl=46.04, wps=435645, ups=1.66, wpb=262144, bsz=512, num_updates=2300, lr=0.00287504, gnorm=0.619, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1556
2024-05-24 23:44:41 | INFO | train_inner | epoch 001:   2405 / 6796 loss=5.502, ppl=45.32, wps=436377, ups=1.66, wpb=262144, bsz=512, num_updates=2400, lr=0.00300004, gnorm=0.582, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1616
2024-05-24 23:45:41 | INFO | train_inner | epoch 001:   2505 / 6796 loss=5.485, ppl=44.78, wps=436098, ups=1.66, wpb=262144, bsz=512, num_updates=2500, lr=0.00312504, gnorm=0.564, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1676
2024-05-24 23:46:41 | INFO | train_inner | epoch 001:   2605 / 6796 loss=5.469, ppl=44.29, wps=436349, ups=1.66, wpb=262144, bsz=512, num_updates=2600, lr=0.00325004, gnorm=0.532, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1736
2024-05-24 23:47:42 | INFO | train_inner | epoch 001:   2705 / 6796 loss=5.454, ppl=43.82, wps=435867, ups=1.66, wpb=262144, bsz=512, num_updates=2700, lr=0.00337503, gnorm=0.511, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1797
2024-05-24 23:48:42 | INFO | train_inner | epoch 001:   2805 / 6796 loss=5.443, ppl=43.51, wps=435931, ups=1.66, wpb=262144, bsz=512, num_updates=2800, lr=0.00350003, gnorm=0.483, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1857
2024-05-24 23:49:42 | INFO | train_inner | epoch 001:   2905 / 6796 loss=5.427, ppl=43.02, wps=436480, ups=1.67, wpb=262144, bsz=512, num_updates=2900, lr=0.00362503, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1917
2024-05-24 23:50:42 | INFO | train_inner | epoch 001:   3005 / 6796 loss=5.41, ppl=42.52, wps=436307, ups=1.66, wpb=262144, bsz=512, num_updates=3000, lr=0.00375003, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=1977
2024-05-24 23:51:42 | INFO | train_inner | epoch 001:   3105 / 6796 loss=5.401, ppl=42.26, wps=436303, ups=1.66, wpb=262144, bsz=512, num_updates=3100, lr=0.00387502, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2037
2024-05-24 23:52:42 | INFO | train_inner | epoch 001:   3205 / 6796 loss=5.389, ppl=41.91, wps=436157, ups=1.66, wpb=262144, bsz=512, num_updates=3200, lr=0.00400002, gnorm=0.418, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2097
2024-05-24 23:53:42 | INFO | train_inner | epoch 001:   3305 / 6796 loss=5.374, ppl=41.48, wps=436683, ups=1.67, wpb=262144, bsz=512, num_updates=3300, lr=0.00412502, gnorm=0.404, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2157
2024-05-24 23:54:42 | INFO | train_inner | epoch 001:   3405 / 6796 loss=5.366, ppl=41.24, wps=436171, ups=1.66, wpb=262144, bsz=512, num_updates=3400, lr=0.00425002, gnorm=0.388, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2217
2024-05-24 23:55:42 | INFO | train_inner | epoch 001:   3505 / 6796 loss=5.363, ppl=41.15, wps=435806, ups=1.66, wpb=262144, bsz=512, num_updates=3500, lr=0.00437501, gnorm=0.393, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2277
2024-05-24 23:56:42 | INFO | train_inner | epoch 001:   3605 / 6796 loss=5.351, ppl=40.8, wps=436088, ups=1.66, wpb=262144, bsz=512, num_updates=3600, lr=0.00450001, gnorm=0.379, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2337
2024-05-24 23:57:43 | INFO | train_inner | epoch 001:   3705 / 6796 loss=5.341, ppl=40.52, wps=435937, ups=1.66, wpb=262144, bsz=512, num_updates=3700, lr=0.00462501, gnorm=0.39, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2398
2024-05-24 23:58:43 | INFO | train_inner | epoch 001:   3805 / 6796 loss=5.333, ppl=40.3, wps=435894, ups=1.66, wpb=262141, bsz=512, num_updates=3800, lr=0.00475001, gnorm=0.378, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2458
2024-05-24 23:59:43 | INFO | train_inner | epoch 001:   3905 / 6796 loss=5.326, ppl=40.12, wps=435956, ups=1.66, wpb=262144, bsz=512, num_updates=3900, lr=0.004875, gnorm=0.394, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2518
2024-05-25 00:00:43 | INFO | train_inner | epoch 001:   4005 / 6796 loss=5.315, ppl=39.8, wps=436208, ups=1.66, wpb=262144, bsz=512, num_updates=4000, lr=0.005, gnorm=0.396, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2578
2024-05-25 00:01:43 | INFO | train_inner | epoch 001:   4105 / 6796 loss=5.301, ppl=39.41, wps=436095, ups=1.66, wpb=262144, bsz=512, num_updates=4100, lr=0.00493865, gnorm=0.393, clip=0, loss_scale=8, train_wall=60, gb_free=12.6, wall=2638
2024-05-25 00:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 00:02:44 | INFO | train_inner | epoch 001:   4206 / 6796 loss=5.291, ppl=39.16, wps=431904, ups=1.65, wpb=262144, bsz=512, num_updates=4200, lr=0.0048795, gnorm=0.399, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2699
2024-05-25 00:03:44 | INFO | train_inner | epoch 001:   4306 / 6796 loss=5.279, ppl=38.83, wps=436572, ups=1.67, wpb=262144, bsz=512, num_updates=4300, lr=0.00482243, gnorm=0.377, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2759
2024-05-25 00:04:44 | INFO | train_inner | epoch 001:   4406 / 6796 loss=5.265, ppl=38.44, wps=436553, ups=1.67, wpb=262144, bsz=512, num_updates=4400, lr=0.00476731, gnorm=0.382, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2819
2024-05-25 00:05:44 | INFO | train_inner | epoch 001:   4506 / 6796 loss=5.249, ppl=38.03, wps=436372, ups=1.66, wpb=262144, bsz=512, num_updates=4500, lr=0.00471405, gnorm=0.401, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2879
2024-05-25 00:06:44 | INFO | train_inner | epoch 001:   4606 / 6796 loss=5.245, ppl=37.92, wps=436152, ups=1.66, wpb=262144, bsz=512, num_updates=4600, lr=0.00466252, gnorm=0.395, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2939
2024-05-25 00:07:44 | INFO | train_inner | epoch 001:   4706 / 6796 loss=5.235, ppl=37.66, wps=436543, ups=1.67, wpb=262144, bsz=512, num_updates=4700, lr=0.00461266, gnorm=0.386, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=2999
2024-05-25 00:08:44 | INFO | train_inner | epoch 001:   4806 / 6796 loss=5.222, ppl=37.33, wps=436699, ups=1.67, wpb=262144, bsz=512, num_updates=4800, lr=0.00456435, gnorm=0.388, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3059
2024-05-25 00:09:44 | INFO | train_inner | epoch 001:   4906 / 6796 loss=5.216, ppl=37.17, wps=436407, ups=1.66, wpb=262144, bsz=512, num_updates=4900, lr=0.00451754, gnorm=0.39, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3119
2024-05-25 00:10:44 | INFO | train_inner | epoch 001:   5006 / 6796 loss=5.201, ppl=36.79, wps=436322, ups=1.66, wpb=262144, bsz=512, num_updates=5000, lr=0.00447214, gnorm=0.407, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3179
2024-05-25 00:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 5000 updates
2024-05-25 00:10:44 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_1_5000.pt
2024-05-25 00:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_1_5000.pt
2024-05-25 00:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score None) (writing took 51.15524907037616 seconds)
2024-05-25 00:12:35 | INFO | train_inner | epoch 001:   5106 / 6796 loss=5.191, ppl=36.54, wps=235913, ups=0.9, wpb=262144, bsz=512, num_updates=5100, lr=0.00442807, gnorm=0.4, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3290
2024-05-25 00:13:35 | INFO | train_inner | epoch 001:   5206 / 6796 loss=5.186, ppl=36.4, wps=436588, ups=1.67, wpb=262144, bsz=512, num_updates=5200, lr=0.00438529, gnorm=0.399, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3350
2024-05-25 00:14:35 | INFO | train_inner | epoch 001:   5306 / 6796 loss=5.177, ppl=36.17, wps=437009, ups=1.67, wpb=262144, bsz=512, num_updates=5300, lr=0.00434372, gnorm=0.408, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3410
2024-05-25 00:15:35 | INFO | train_inner | epoch 001:   5406 / 6796 loss=5.177, ppl=36.17, wps=437128, ups=1.67, wpb=262144, bsz=512, num_updates=5400, lr=0.00430331, gnorm=0.401, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3470
2024-05-25 00:16:35 | INFO | train_inner | epoch 001:   5506 / 6796 loss=5.162, ppl=35.81, wps=436216, ups=1.66, wpb=262144, bsz=512, num_updates=5500, lr=0.00426401, gnorm=0.414, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3530
2024-05-25 00:17:35 | INFO | train_inner | epoch 001:   5606 / 6796 loss=5.158, ppl=35.72, wps=436853, ups=1.67, wpb=262144, bsz=512, num_updates=5600, lr=0.00422577, gnorm=0.436, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3590
2024-05-25 00:18:36 | INFO | train_inner | epoch 001:   5706 / 6796 loss=5.15, ppl=35.5, wps=436172, ups=1.66, wpb=262144, bsz=512, num_updates=5700, lr=0.00418854, gnorm=0.4, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3651
2024-05-25 00:19:36 | INFO | train_inner | epoch 001:   5806 / 6796 loss=5.145, ppl=35.39, wps=435727, ups=1.67, wpb=261524, bsz=510.8, num_updates=5800, lr=0.00415227, gnorm=0.385, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3711
2024-05-25 00:20:36 | INFO | train_inner | epoch 001:   5906 / 6796 loss=5.138, ppl=35.22, wps=436500, ups=1.67, wpb=262144, bsz=512, num_updates=5900, lr=0.00411693, gnorm=0.388, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3771
2024-05-25 00:21:36 | INFO | train_inner | epoch 001:   6006 / 6796 loss=5.133, ppl=35.09, wps=436653, ups=1.67, wpb=262144, bsz=512, num_updates=6000, lr=0.00408248, gnorm=0.413, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3831
2024-05-25 00:22:36 | INFO | train_inner | epoch 001:   6106 / 6796 loss=5.126, ppl=34.92, wps=436496, ups=1.67, wpb=262144, bsz=512, num_updates=6100, lr=0.00404888, gnorm=0.421, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3891
2024-05-25 00:23:36 | INFO | train_inner | epoch 001:   6206 / 6796 loss=5.121, ppl=34.8, wps=436743, ups=1.67, wpb=262144, bsz=512, num_updates=6200, lr=0.0040161, gnorm=0.425, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=3951
2024-05-25 00:24:36 | INFO | train_inner | epoch 001:   6306 / 6796 loss=5.118, ppl=34.72, wps=436670, ups=1.67, wpb=262144, bsz=512, num_updates=6300, lr=0.0039841, gnorm=0.41, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4011
2024-05-25 00:25:36 | INFO | train_inner | epoch 001:   6406 / 6796 loss=5.107, ppl=34.45, wps=436499, ups=1.67, wpb=262144, bsz=512, num_updates=6400, lr=0.00395285, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4071
2024-05-25 00:26:36 | INFO | train_inner | epoch 001:   6506 / 6796 loss=5.102, ppl=34.34, wps=436794, ups=1.67, wpb=262144, bsz=512, num_updates=6500, lr=0.00392232, gnorm=0.412, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4131
2024-05-25 00:27:36 | INFO | train_inner | epoch 001:   6606 / 6796 loss=5.103, ppl=34.37, wps=436569, ups=1.67, wpb=262144, bsz=512, num_updates=6600, lr=0.00389249, gnorm=0.428, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4191
2024-05-25 00:28:36 | INFO | train_inner | epoch 001:   6706 / 6796 loss=5.098, ppl=34.24, wps=436541, ups=1.67, wpb=262144, bsz=512, num_updates=6700, lr=0.00386334, gnorm=0.421, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4251
2024-05-25 00:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6790 updates
2024-05-25 00:29:30 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint1.pt
2024-05-25 00:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint1.pt
2024-05-25 00:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint1.pt (epoch 1 @ 6790 updates, score None) (writing took 88.93164832144976 seconds)
2024-05-25 00:30:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-05-25 00:30:59 | INFO | train | epoch 001 | loss 5.725 | ppl 52.88 | wps 421511 | ups 1.61 | wpb 262116 | bsz 511.9 | num_updates 6790 | lr 0.00383765 | gnorm 0.768 | clip 3.1 | loss_scale 4 | train_wall 4083 | gb_free 12.6 | wall 4394
2024-05-25 00:30:59 | INFO | fairseq.trainer | loading train data for epoch 2
2024-05-25 00:31:01 | INFO | fairseq.data.data_utils | loaded 52,734,000 examples from: ./data/data-bin/1/train
2024-05-25 00:31:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6776
2024-05-25 00:31:02 | INFO | fairseq.trainer | begin training epoch 2
2024-05-25 00:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 00:31:08 | INFO | train_inner | epoch 002:     10 / 6776 loss=5.093, ppl=34.14, wps=172322, ups=0.66, wpb=261489, bsz=510.7, num_updates=6800, lr=0.00383482, gnorm=0.423, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4403
2024-05-25 00:32:08 | INFO | train_inner | epoch 002:    110 / 6776 loss=5.087, ppl=33.99, wps=437123, ups=1.67, wpb=262144, bsz=512, num_updates=6900, lr=0.00380693, gnorm=0.411, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4463
2024-05-25 00:33:08 | INFO | train_inner | epoch 002:    210 / 6776 loss=5.084, ppl=33.92, wps=436205, ups=1.66, wpb=262144, bsz=512, num_updates=7000, lr=0.00377964, gnorm=0.446, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4523
2024-05-25 00:34:08 | INFO | train_inner | epoch 002:    310 / 6776 loss=5.078, ppl=33.78, wps=436482, ups=1.67, wpb=262144, bsz=512, num_updates=7100, lr=0.00375293, gnorm=0.424, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4583
2024-05-25 00:35:08 | INFO | train_inner | epoch 002:    410 / 6776 loss=5.075, ppl=33.7, wps=436348, ups=1.66, wpb=262144, bsz=512, num_updates=7200, lr=0.00372678, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4643
2024-05-25 00:36:08 | INFO | train_inner | epoch 002:    510 / 6776 loss=5.076, ppl=33.73, wps=435608, ups=1.66, wpb=262144, bsz=512, num_updates=7300, lr=0.00370117, gnorm=0.418, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4703
2024-05-25 00:37:08 | INFO | train_inner | epoch 002:    610 / 6776 loss=5.068, ppl=33.55, wps=436313, ups=1.66, wpb=262144, bsz=512, num_updates=7400, lr=0.00367607, gnorm=0.435, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4763
2024-05-25 00:38:08 | INFO | train_inner | epoch 002:    710 / 6776 loss=5.062, ppl=33.41, wps=436491, ups=1.67, wpb=262144, bsz=512, num_updates=7500, lr=0.00365148, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4823
2024-05-25 00:39:08 | INFO | train_inner | epoch 002:    810 / 6776 loss=5.057, ppl=33.29, wps=436158, ups=1.66, wpb=262144, bsz=512, num_updates=7600, lr=0.00362738, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4883
2024-05-25 00:40:08 | INFO | train_inner | epoch 002:    910 / 6776 loss=5.054, ppl=33.22, wps=436486, ups=1.67, wpb=262144, bsz=512, num_updates=7700, lr=0.00360375, gnorm=0.403, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=4943
2024-05-25 00:41:08 | INFO | train_inner | epoch 002:   1010 / 6776 loss=5.053, ppl=33.2, wps=436646, ups=1.67, wpb=262144, bsz=512, num_updates=7800, lr=0.00358057, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5003
2024-05-25 00:42:08 | INFO | train_inner | epoch 002:   1110 / 6776 loss=5.05, ppl=33.14, wps=436533, ups=1.67, wpb=262144, bsz=512, num_updates=7900, lr=0.00355784, gnorm=0.425, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5064
2024-05-25 00:43:09 | INFO | train_inner | epoch 002:   1210 / 6776 loss=5.044, ppl=33, wps=436504, ups=1.67, wpb=262144, bsz=512, num_updates=8000, lr=0.00353553, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5124
2024-05-25 00:44:09 | INFO | train_inner | epoch 002:   1310 / 6776 loss=5.042, ppl=32.94, wps=436364, ups=1.66, wpb=262144, bsz=512, num_updates=8100, lr=0.00351364, gnorm=0.417, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5184
2024-05-25 00:45:09 | INFO | train_inner | epoch 002:   1410 / 6776 loss=5.038, ppl=32.87, wps=436846, ups=1.67, wpb=262144, bsz=512, num_updates=8200, lr=0.00349215, gnorm=0.426, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5244
2024-05-25 00:45:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 00:46:09 | INFO | train_inner | epoch 002:   1511 / 6776 loss=5.038, ppl=32.85, wps=433675, ups=1.65, wpb=262144, bsz=512, num_updates=8300, lr=0.00347105, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5304
2024-05-25 00:47:09 | INFO | train_inner | epoch 002:   1611 / 6776 loss=5.035, ppl=32.79, wps=437115, ups=1.67, wpb=262144, bsz=512, num_updates=8400, lr=0.00345033, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5364
2024-05-25 00:48:09 | INFO | train_inner | epoch 002:   1711 / 6776 loss=5.033, ppl=32.75, wps=436387, ups=1.66, wpb=262144, bsz=512, num_updates=8500, lr=0.00342997, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5424
2024-05-25 00:49:09 | INFO | train_inner | epoch 002:   1811 / 6776 loss=5.029, ppl=32.65, wps=436330, ups=1.66, wpb=262144, bsz=512, num_updates=8600, lr=0.00340997, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5484
2024-05-25 00:50:09 | INFO | train_inner | epoch 002:   1911 / 6776 loss=5.031, ppl=32.7, wps=436519, ups=1.67, wpb=262144, bsz=512, num_updates=8700, lr=0.00339032, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5544
2024-05-25 00:51:09 | INFO | train_inner | epoch 002:   2011 / 6776 loss=5.024, ppl=32.55, wps=436495, ups=1.67, wpb=262144, bsz=512, num_updates=8800, lr=0.003371, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5604
2024-05-25 00:52:09 | INFO | train_inner | epoch 002:   2111 / 6776 loss=5.023, ppl=32.5, wps=436544, ups=1.67, wpb=262144, bsz=512, num_updates=8900, lr=0.00335201, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5664
2024-05-25 00:53:09 | INFO | train_inner | epoch 002:   2211 / 6776 loss=5.02, ppl=32.44, wps=436536, ups=1.67, wpb=262144, bsz=512, num_updates=9000, lr=0.00333333, gnorm=0.447, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5724
2024-05-25 00:54:09 | INFO | train_inner | epoch 002:   2311 / 6776 loss=5.015, ppl=32.33, wps=436606, ups=1.67, wpb=262144, bsz=512, num_updates=9100, lr=0.00331497, gnorm=0.447, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5784
2024-05-25 00:55:09 | INFO | train_inner | epoch 002:   2411 / 6776 loss=5.012, ppl=32.26, wps=436740, ups=1.67, wpb=262144, bsz=512, num_updates=9200, lr=0.0032969, gnorm=0.424, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5845
2024-05-25 00:56:10 | INFO | train_inner | epoch 002:   2511 / 6776 loss=5.01, ppl=32.23, wps=436378, ups=1.66, wpb=262144, bsz=512, num_updates=9300, lr=0.00327913, gnorm=0.452, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5905
2024-05-25 00:57:10 | INFO | train_inner | epoch 002:   2611 / 6776 loss=5.01, ppl=32.21, wps=436450, ups=1.66, wpb=262144, bsz=512, num_updates=9400, lr=0.00326164, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=5965
2024-05-25 00:58:10 | INFO | train_inner | epoch 002:   2711 / 6776 loss=5.009, ppl=32.2, wps=436307, ups=1.66, wpb=262144, bsz=512, num_updates=9500, lr=0.00324443, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6025
2024-05-25 00:59:10 | INFO | train_inner | epoch 002:   2811 / 6776 loss=5.005, ppl=32.12, wps=436725, ups=1.67, wpb=262144, bsz=512, num_updates=9600, lr=0.00322749, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6085
2024-05-25 01:00:10 | INFO | train_inner | epoch 002:   2911 / 6776 loss=5.004, ppl=32.08, wps=436446, ups=1.66, wpb=262144, bsz=512, num_updates=9700, lr=0.00321081, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6145
2024-05-25 01:01:10 | INFO | train_inner | epoch 002:   3011 / 6776 loss=5, ppl=32, wps=436625, ups=1.67, wpb=262144, bsz=512, num_updates=9800, lr=0.00319438, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6205
2024-05-25 01:02:10 | INFO | train_inner | epoch 002:   3111 / 6776 loss=5.003, ppl=32.07, wps=436284, ups=1.66, wpb=262144, bsz=512, num_updates=9900, lr=0.00317821, gnorm=0.419, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6265
2024-05-25 01:03:10 | INFO | train_inner | epoch 002:   3211 / 6776 loss=5, ppl=31.99, wps=436481, ups=1.67, wpb=262144, bsz=512, num_updates=10000, lr=0.00316228, gnorm=0.433, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6325
2024-05-25 01:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 10000 updates
2024-05-25 01:03:10 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_2_10000.pt
2024-05-25 01:03:25 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_2_10000.pt
2024-05-25 01:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score None) (writing took 44.011908788233995 seconds)
2024-05-25 01:04:54 | INFO | train_inner | epoch 002:   3311 / 6776 loss=4.994, ppl=31.87, wps=252111, ups=0.96, wpb=262144, bsz=512, num_updates=10100, lr=0.00314658, gnorm=0.462, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6429
2024-05-25 01:05:54 | INFO | train_inner | epoch 002:   3411 / 6776 loss=4.99, ppl=31.78, wps=437354, ups=1.67, wpb=262144, bsz=512, num_updates=10200, lr=0.00313112, gnorm=0.458, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6489
2024-05-25 01:06:54 | INFO | train_inner | epoch 002:   3511 / 6776 loss=4.992, ppl=31.83, wps=437015, ups=1.67, wpb=262144, bsz=512, num_updates=10300, lr=0.00311588, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6549
2024-05-25 01:07:54 | INFO | train_inner | epoch 002:   3611 / 6776 loss=4.991, ppl=31.8, wps=437218, ups=1.67, wpb=262144, bsz=512, num_updates=10400, lr=0.00310087, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6609
2024-05-25 01:08:54 | INFO | train_inner | epoch 002:   3711 / 6776 loss=4.987, ppl=31.72, wps=436813, ups=1.67, wpb=262142, bsz=512, num_updates=10500, lr=0.00308607, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6669
2024-05-25 01:09:54 | INFO | train_inner | epoch 002:   3811 / 6776 loss=4.989, ppl=31.77, wps=436677, ups=1.67, wpb=262144, bsz=512, num_updates=10600, lr=0.00307148, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6729
2024-05-25 01:10:54 | INFO | train_inner | epoch 002:   3911 / 6776 loss=4.984, ppl=31.65, wps=436912, ups=1.67, wpb=262144, bsz=512, num_updates=10700, lr=0.00305709, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6789
2024-05-25 01:11:54 | INFO | train_inner | epoch 002:   4011 / 6776 loss=4.984, ppl=31.66, wps=437062, ups=1.67, wpb=262144, bsz=512, num_updates=10800, lr=0.0030429, gnorm=0.446, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6849
2024-05-25 01:12:54 | INFO | train_inner | epoch 002:   4111 / 6776 loss=4.977, ppl=31.5, wps=436960, ups=1.67, wpb=262144, bsz=512, num_updates=10900, lr=0.00302891, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6909
2024-05-25 01:13:54 | INFO | train_inner | epoch 002:   4211 / 6776 loss=4.983, ppl=31.63, wps=437017, ups=1.67, wpb=262144, bsz=512, num_updates=11000, lr=0.00301511, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=6969
2024-05-25 01:14:54 | INFO | train_inner | epoch 002:   4311 / 6776 loss=4.975, ppl=31.45, wps=437114, ups=1.67, wpb=262144, bsz=512, num_updates=11100, lr=0.0030015, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7029
2024-05-25 01:15:54 | INFO | train_inner | epoch 002:   4411 / 6776 loss=4.974, ppl=31.42, wps=436932, ups=1.67, wpb=262144, bsz=512, num_updates=11200, lr=0.00298807, gnorm=0.413, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7089
2024-05-25 01:16:54 | INFO | train_inner | epoch 002:   4511 / 6776 loss=4.969, ppl=31.31, wps=437060, ups=1.67, wpb=262144, bsz=512, num_updates=11300, lr=0.00297482, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7149
2024-05-25 01:17:54 | INFO | train_inner | epoch 002:   4611 / 6776 loss=4.968, ppl=31.29, wps=437007, ups=1.67, wpb=262144, bsz=512, num_updates=11400, lr=0.00296174, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7209
2024-05-25 01:18:54 | INFO | train_inner | epoch 002:   4711 / 6776 loss=4.967, ppl=31.27, wps=436903, ups=1.67, wpb=262144, bsz=512, num_updates=11500, lr=0.00294884, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7269
2024-05-25 01:19:54 | INFO | train_inner | epoch 002:   4811 / 6776 loss=4.97, ppl=31.34, wps=437306, ups=1.67, wpb=262144, bsz=512, num_updates=11600, lr=0.0029361, gnorm=0.435, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7329
2024-05-25 01:20:54 | INFO | train_inner | epoch 002:   4911 / 6776 loss=4.963, ppl=31.18, wps=437190, ups=1.67, wpb=262144, bsz=512, num_updates=11700, lr=0.00292353, gnorm=0.411, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7389
2024-05-25 01:21:54 | INFO | train_inner | epoch 002:   5011 / 6776 loss=4.963, ppl=31.2, wps=436893, ups=1.67, wpb=262144, bsz=512, num_updates=11800, lr=0.00291111, gnorm=0.473, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7449
2024-05-25 01:22:54 | INFO | train_inner | epoch 002:   5111 / 6776 loss=4.964, ppl=31.22, wps=436784, ups=1.67, wpb=262144, bsz=512, num_updates=11900, lr=0.00289886, gnorm=0.474, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7509
2024-05-25 01:23:54 | INFO | train_inner | epoch 002:   5211 / 6776 loss=4.962, ppl=31.18, wps=437566, ups=1.67, wpb=262144, bsz=512, num_updates=12000, lr=0.00288675, gnorm=0.473, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7569
2024-05-25 01:24:54 | INFO | train_inner | epoch 002:   5311 / 6776 loss=4.964, ppl=31.21, wps=437441, ups=1.67, wpb=262144, bsz=512, num_updates=12100, lr=0.0028748, gnorm=0.492, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7629
2024-05-25 01:25:53 | INFO | train_inner | epoch 002:   5411 / 6776 loss=4.961, ppl=31.14, wps=437512, ups=1.67, wpb=262144, bsz=512, num_updates=12200, lr=0.00286299, gnorm=0.415, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7689
2024-05-25 01:26:54 | INFO | train_inner | epoch 002:   5511 / 6776 loss=4.957, ppl=31.05, wps=436756, ups=1.67, wpb=262144, bsz=512, num_updates=12300, lr=0.00285133, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7749
2024-05-25 01:27:54 | INFO | train_inner | epoch 002:   5611 / 6776 loss=4.955, ppl=31.01, wps=436758, ups=1.67, wpb=262144, bsz=512, num_updates=12400, lr=0.00283981, gnorm=0.444, clip=0, loss_scale=8, train_wall=60, gb_free=12.6, wall=7809
2024-05-25 01:28:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 01:28:54 | INFO | train_inner | epoch 002:   5712 / 6776 loss=4.954, ppl=30.99, wps=432945, ups=1.65, wpb=262144, bsz=512, num_updates=12500, lr=0.00282843, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7869
2024-05-25 01:29:54 | INFO | train_inner | epoch 002:   5812 / 6776 loss=4.954, ppl=31, wps=437440, ups=1.67, wpb=262144, bsz=512, num_updates=12600, lr=0.00281718, gnorm=0.435, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7929
2024-05-25 01:30:54 | INFO | train_inner | epoch 002:   5912 / 6776 loss=4.954, ppl=31, wps=437118, ups=1.67, wpb=262144, bsz=512, num_updates=12700, lr=0.00280607, gnorm=0.41, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=7989
2024-05-25 01:31:54 | INFO | train_inner | epoch 002:   6012 / 6776 loss=4.946, ppl=30.83, wps=437288, ups=1.67, wpb=262144, bsz=512, num_updates=12800, lr=0.00279508, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8049
2024-05-25 01:32:54 | INFO | train_inner | epoch 002:   6112 / 6776 loss=4.947, ppl=30.85, wps=437325, ups=1.67, wpb=262144, bsz=512, num_updates=12900, lr=0.00278423, gnorm=0.45, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8109
2024-05-25 01:33:54 | INFO | train_inner | epoch 002:   6212 / 6776 loss=4.948, ppl=30.86, wps=437019, ups=1.67, wpb=262021, bsz=511.8, num_updates=13000, lr=0.0027735, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8169
2024-05-25 01:34:54 | INFO | train_inner | epoch 002:   6312 / 6776 loss=4.95, ppl=30.92, wps=435639, ups=1.67, wpb=261524, bsz=510.8, num_updates=13100, lr=0.00276289, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8229
2024-05-25 01:35:54 | INFO | train_inner | epoch 002:   6412 / 6776 loss=4.944, ppl=30.78, wps=436852, ups=1.67, wpb=262144, bsz=512, num_updates=13200, lr=0.00275241, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8289
2024-05-25 01:36:54 | INFO | train_inner | epoch 002:   6512 / 6776 loss=4.94, ppl=30.7, wps=435893, ups=1.66, wpb=262144, bsz=512, num_updates=13300, lr=0.00274204, gnorm=0.491, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8349
2024-05-25 01:37:54 | INFO | train_inner | epoch 002:   6612 / 6776 loss=4.943, ppl=30.75, wps=437277, ups=1.67, wpb=262144, bsz=512, num_updates=13400, lr=0.00273179, gnorm=0.452, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8409
2024-05-25 01:38:54 | INFO | train_inner | epoch 002:   6712 / 6776 loss=4.942, ppl=30.75, wps=437204, ups=1.67, wpb=262144, bsz=512, num_updates=13500, lr=0.00272166, gnorm=0.447, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8469
2024-05-25 01:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13564 updates
2024-05-25 01:39:32 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint2.pt
2024-05-25 01:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint2.pt
2024-05-25 01:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint2.pt (epoch 2 @ 13564 updates, score None) (writing took 75.54939821735024 seconds)
2024-05-25 01:40:48 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-05-25 01:40:48 | INFO | train | epoch 002 | loss 4.999 | ppl 31.98 | wps 423853 | ups 1.62 | wpb 262104 | bsz 511.9 | num_updates 13564 | lr 0.00271523 | gnorm 0.442 | clip 0 | loss_scale 4 | train_wall 4052 | gb_free 12.6 | wall 8583
2024-05-25 01:40:48 | INFO | fairseq.trainer | loading train data for epoch 3
2024-05-25 01:40:48 | INFO | fairseq.data.data_utils | loaded 52,350,000 examples from: ./data/data-bin/2/train
2024-05-25 01:40:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6724
2024-05-25 01:40:49 | INFO | fairseq.trainer | begin training epoch 3
2024-05-25 01:40:49 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 01:41:11 | INFO | train_inner | epoch 003:     36 / 6724 loss=4.937, ppl=30.62, wps=190040, ups=0.73, wpb=260178, bsz=508.2, num_updates=13600, lr=0.00271163, gnorm=0.483, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8606
2024-05-25 01:42:11 | INFO | train_inner | epoch 003:    136 / 6724 loss=4.942, ppl=30.74, wps=437270, ups=1.67, wpb=262144, bsz=512, num_updates=13700, lr=0.00270172, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8666
2024-05-25 01:43:11 | INFO | train_inner | epoch 003:    236 / 6724 loss=4.942, ppl=30.74, wps=436977, ups=1.67, wpb=262144, bsz=512, num_updates=13800, lr=0.00269191, gnorm=0.458, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8726
2024-05-25 01:44:11 | INFO | train_inner | epoch 003:    336 / 6724 loss=4.935, ppl=30.6, wps=437103, ups=1.67, wpb=262144, bsz=512, num_updates=13900, lr=0.00268221, gnorm=0.485, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8786
2024-05-25 01:45:11 | INFO | train_inner | epoch 003:    436 / 6724 loss=4.935, ppl=30.58, wps=437214, ups=1.67, wpb=262144, bsz=512, num_updates=14000, lr=0.00267261, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8846
2024-05-25 01:46:11 | INFO | train_inner | epoch 003:    536 / 6724 loss=4.932, ppl=30.53, wps=436821, ups=1.67, wpb=262140, bsz=512, num_updates=14100, lr=0.00266312, gnorm=0.469, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8906
2024-05-25 01:47:11 | INFO | train_inner | epoch 003:    636 / 6724 loss=4.931, ppl=30.5, wps=437121, ups=1.67, wpb=262144, bsz=512, num_updates=14200, lr=0.00265372, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=8966
2024-05-25 01:48:11 | INFO | train_inner | epoch 003:    736 / 6724 loss=4.931, ppl=30.52, wps=437068, ups=1.67, wpb=262144, bsz=512, num_updates=14300, lr=0.00264443, gnorm=0.426, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9026
2024-05-25 01:49:11 | INFO | train_inner | epoch 003:    836 / 6724 loss=4.935, ppl=30.59, wps=437173, ups=1.67, wpb=262144, bsz=512, num_updates=14400, lr=0.00263523, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9086
2024-05-25 01:50:11 | INFO | train_inner | epoch 003:    936 / 6724 loss=4.93, ppl=30.49, wps=436944, ups=1.67, wpb=262144, bsz=512, num_updates=14500, lr=0.00262613, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9146
2024-05-25 01:51:11 | INFO | train_inner | epoch 003:   1036 / 6724 loss=4.929, ppl=30.46, wps=436362, ups=1.66, wpb=262144, bsz=512, num_updates=14600, lr=0.00261712, gnorm=0.429, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9206
2024-05-25 01:52:11 | INFO | train_inner | epoch 003:   1136 / 6724 loss=4.93, ppl=30.49, wps=437139, ups=1.67, wpb=262144, bsz=512, num_updates=14700, lr=0.0026082, gnorm=0.468, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9266
2024-05-25 01:53:11 | INFO | train_inner | epoch 003:   1236 / 6724 loss=4.929, ppl=30.46, wps=437305, ups=1.67, wpb=262144, bsz=512, num_updates=14800, lr=0.00259938, gnorm=0.425, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9326
2024-05-25 01:54:11 | INFO | train_inner | epoch 003:   1336 / 6724 loss=4.929, ppl=30.46, wps=437302, ups=1.67, wpb=262144, bsz=512, num_updates=14900, lr=0.00259064, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9386
2024-05-25 01:55:11 | INFO | train_inner | epoch 003:   1436 / 6724 loss=4.927, ppl=30.43, wps=437264, ups=1.67, wpb=262144, bsz=512, num_updates=15000, lr=0.00258199, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9446
2024-05-25 01:55:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 15000 updates
2024-05-25 01:55:11 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_15000.pt
2024-05-25 01:55:26 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_15000.pt
2024-05-25 01:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_15000.pt (epoch 3 @ 15000 updates, score None) (writing took 44.04516049101949 seconds)
2024-05-25 01:56:54 | INFO | train_inner | epoch 003:   1536 / 6724 loss=4.924, ppl=30.36, wps=252197, ups=0.96, wpb=262144, bsz=512, num_updates=15100, lr=0.00257343, gnorm=0.433, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9550
2024-05-25 01:57:54 | INFO | train_inner | epoch 003:   1636 / 6724 loss=4.924, ppl=30.37, wps=436762, ups=1.67, wpb=262144, bsz=512, num_updates=15200, lr=0.00256495, gnorm=0.471, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9610
2024-05-25 01:58:55 | INFO | train_inner | epoch 003:   1736 / 6724 loss=4.922, ppl=30.33, wps=436658, ups=1.67, wpb=262144, bsz=512, num_updates=15300, lr=0.00255655, gnorm=0.422, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9670
2024-05-25 01:59:55 | INFO | train_inner | epoch 003:   1836 / 6724 loss=4.922, ppl=30.31, wps=436731, ups=1.67, wpb=262144, bsz=512, num_updates=15400, lr=0.00254824, gnorm=0.494, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9730
2024-05-25 02:00:55 | INFO | train_inner | epoch 003:   1936 / 6724 loss=4.922, ppl=30.31, wps=436459, ups=1.66, wpb=262144, bsz=512, num_updates=15500, lr=0.00254, gnorm=0.47, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9790
2024-05-25 02:01:55 | INFO | train_inner | epoch 003:   2036 / 6724 loss=4.923, ppl=30.34, wps=436689, ups=1.67, wpb=262144, bsz=512, num_updates=15600, lr=0.00253185, gnorm=0.45, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9850
2024-05-25 02:02:55 | INFO | train_inner | epoch 003:   2136 / 6724 loss=4.923, ppl=30.34, wps=436823, ups=1.67, wpb=262144, bsz=512, num_updates=15700, lr=0.00252377, gnorm=0.451, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9910
2024-05-25 02:03:55 | INFO | train_inner | epoch 003:   2236 / 6724 loss=4.916, ppl=30.2, wps=436765, ups=1.67, wpb=262144, bsz=512, num_updates=15800, lr=0.00251577, gnorm=0.466, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=9970
2024-05-25 02:04:55 | INFO | train_inner | epoch 003:   2336 / 6724 loss=4.917, ppl=30.2, wps=436299, ups=1.66, wpb=262144, bsz=512, num_updates=15900, lr=0.00250785, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10030
2024-05-25 02:05:55 | INFO | train_inner | epoch 003:   2436 / 6724 loss=4.913, ppl=30.13, wps=436531, ups=1.67, wpb=262144, bsz=512, num_updates=16000, lr=0.0025, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10090
2024-05-25 02:06:55 | INFO | train_inner | epoch 003:   2536 / 6724 loss=4.914, ppl=30.14, wps=436803, ups=1.67, wpb=262144, bsz=512, num_updates=16100, lr=0.00249222, gnorm=0.494, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10150
2024-05-25 02:07:55 | INFO | train_inner | epoch 003:   2636 / 6724 loss=4.912, ppl=30.1, wps=436202, ups=1.66, wpb=262144, bsz=512, num_updates=16200, lr=0.00248452, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10210
2024-05-25 02:08:55 | INFO | train_inner | epoch 003:   2736 / 6724 loss=4.911, ppl=30.08, wps=436364, ups=1.66, wpb=262144, bsz=512, num_updates=16300, lr=0.00247689, gnorm=0.45, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10270
2024-05-25 02:09:55 | INFO | train_inner | epoch 003:   2836 / 6724 loss=4.91, ppl=30.06, wps=436522, ups=1.67, wpb=262144, bsz=512, num_updates=16400, lr=0.00246932, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10330
2024-05-25 02:10:55 | INFO | train_inner | epoch 003:   2936 / 6724 loss=4.911, ppl=30.08, wps=436802, ups=1.67, wpb=262144, bsz=512, num_updates=16500, lr=0.00246183, gnorm=0.429, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10390
2024-05-25 02:11:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 02:11:56 | INFO | train_inner | epoch 003:   3037 / 6724 loss=4.911, ppl=30.09, wps=432492, ups=1.65, wpb=262144, bsz=512, num_updates=16600, lr=0.0024544, gnorm=0.449, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10451
2024-05-25 02:12:56 | INFO | train_inner | epoch 003:   3137 / 6724 loss=4.908, ppl=30.03, wps=436908, ups=1.67, wpb=262144, bsz=512, num_updates=16700, lr=0.00244704, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10511
2024-05-25 02:13:56 | INFO | train_inner | epoch 003:   3237 / 6724 loss=4.91, ppl=30.07, wps=436868, ups=1.67, wpb=262144, bsz=512, num_updates=16800, lr=0.00243975, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10571
2024-05-25 02:14:56 | INFO | train_inner | epoch 003:   3337 / 6724 loss=4.909, ppl=30.04, wps=436933, ups=1.67, wpb=262144, bsz=512, num_updates=16900, lr=0.00243252, gnorm=0.494, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10631
2024-05-25 02:15:56 | INFO | train_inner | epoch 003:   3437 / 6724 loss=4.907, ppl=30, wps=435442, ups=1.67, wpb=261519, bsz=510.8, num_updates=17000, lr=0.00242536, gnorm=0.432, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10691
2024-05-25 02:16:56 | INFO | train_inner | epoch 003:   3537 / 6724 loss=4.905, ppl=29.97, wps=436574, ups=1.67, wpb=262144, bsz=512, num_updates=17100, lr=0.00241825, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10751
2024-05-25 02:17:56 | INFO | train_inner | epoch 003:   3637 / 6724 loss=4.907, ppl=29.99, wps=436537, ups=1.67, wpb=262144, bsz=512, num_updates=17200, lr=0.00241121, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10811
2024-05-25 02:18:56 | INFO | train_inner | epoch 003:   3737 / 6724 loss=4.904, ppl=29.93, wps=436298, ups=1.66, wpb=262144, bsz=512, num_updates=17300, lr=0.00240424, gnorm=0.45, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10871
2024-05-25 02:19:56 | INFO | train_inner | epoch 003:   3837 / 6724 loss=4.905, ppl=29.97, wps=436398, ups=1.66, wpb=262144, bsz=512, num_updates=17400, lr=0.00239732, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10931
2024-05-25 02:20:56 | INFO | train_inner | epoch 003:   3937 / 6724 loss=4.9, ppl=29.85, wps=436955, ups=1.67, wpb=262144, bsz=512, num_updates=17500, lr=0.00239046, gnorm=0.459, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=10991
2024-05-25 02:21:56 | INFO | train_inner | epoch 003:   4037 / 6724 loss=4.898, ppl=29.81, wps=436463, ups=1.66, wpb=262144, bsz=512, num_updates=17600, lr=0.00238366, gnorm=0.475, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11051
2024-05-25 02:22:56 | INFO | train_inner | epoch 003:   4137 / 6724 loss=4.906, ppl=29.98, wps=436738, ups=1.67, wpb=262144, bsz=512, num_updates=17700, lr=0.00237691, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11111
2024-05-25 02:23:56 | INFO | train_inner | epoch 003:   4237 / 6724 loss=4.901, ppl=29.89, wps=436105, ups=1.66, wpb=262144, bsz=512, num_updates=17800, lr=0.00237023, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11171
2024-05-25 02:24:56 | INFO | train_inner | epoch 003:   4337 / 6724 loss=4.898, ppl=29.82, wps=436754, ups=1.67, wpb=262144, bsz=512, num_updates=17900, lr=0.0023636, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11231
2024-05-25 02:25:56 | INFO | train_inner | epoch 003:   4437 / 6724 loss=4.903, ppl=29.92, wps=436445, ups=1.66, wpb=262144, bsz=512, num_updates=18000, lr=0.00235702, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11291
2024-05-25 02:26:56 | INFO | train_inner | epoch 003:   4537 / 6724 loss=4.895, ppl=29.74, wps=436884, ups=1.67, wpb=262144, bsz=512, num_updates=18100, lr=0.0023505, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11351
2024-05-25 02:27:56 | INFO | train_inner | epoch 003:   4637 / 6724 loss=4.897, ppl=29.79, wps=436542, ups=1.67, wpb=262144, bsz=512, num_updates=18200, lr=0.00234404, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11411
2024-05-25 02:28:56 | INFO | train_inner | epoch 003:   4737 / 6724 loss=4.892, ppl=29.7, wps=436606, ups=1.67, wpb=262144, bsz=512, num_updates=18300, lr=0.00233762, gnorm=0.422, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11471
2024-05-25 02:29:56 | INFO | train_inner | epoch 003:   4837 / 6724 loss=4.896, ppl=29.78, wps=437183, ups=1.67, wpb=262144, bsz=512, num_updates=18400, lr=0.00233126, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11531
2024-05-25 02:30:56 | INFO | train_inner | epoch 003:   4937 / 6724 loss=4.898, ppl=29.82, wps=436346, ups=1.66, wpb=262144, bsz=512, num_updates=18500, lr=0.00232495, gnorm=0.436, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11591
2024-05-25 02:31:57 | INFO | train_inner | epoch 003:   5037 / 6724 loss=4.895, ppl=29.74, wps=436450, ups=1.66, wpb=262144, bsz=512, num_updates=18600, lr=0.00231869, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11652
2024-05-25 02:32:57 | INFO | train_inner | epoch 003:   5137 / 6724 loss=4.893, ppl=29.71, wps=436226, ups=1.66, wpb=262144, bsz=512, num_updates=18700, lr=0.00231249, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11712
2024-05-25 02:33:57 | INFO | train_inner | epoch 003:   5237 / 6724 loss=4.899, ppl=29.83, wps=436519, ups=1.67, wpb=262144, bsz=512, num_updates=18800, lr=0.00230633, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11772
2024-05-25 02:34:57 | INFO | train_inner | epoch 003:   5337 / 6724 loss=4.893, ppl=29.72, wps=435940, ups=1.66, wpb=262144, bsz=512, num_updates=18900, lr=0.00230022, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11832
2024-05-25 02:35:57 | INFO | train_inner | epoch 003:   5437 / 6724 loss=4.892, ppl=29.69, wps=437297, ups=1.67, wpb=262144, bsz=512, num_updates=19000, lr=0.00229416, gnorm=0.496, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11892
2024-05-25 02:36:57 | INFO | train_inner | epoch 003:   5537 / 6724 loss=4.889, ppl=29.64, wps=437190, ups=1.67, wpb=262144, bsz=512, num_updates=19100, lr=0.00228814, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=11952
2024-05-25 02:37:57 | INFO | train_inner | epoch 003:   5637 / 6724 loss=4.891, ppl=29.66, wps=436499, ups=1.67, wpb=262144, bsz=512, num_updates=19200, lr=0.00228218, gnorm=0.426, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12012
2024-05-25 02:38:57 | INFO | train_inner | epoch 003:   5737 / 6724 loss=4.889, ppl=29.62, wps=435864, ups=1.66, wpb=262144, bsz=512, num_updates=19300, lr=0.00227626, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12072
2024-05-25 02:39:57 | INFO | train_inner | epoch 003:   5837 / 6724 loss=4.887, ppl=29.59, wps=436456, ups=1.66, wpb=262144, bsz=512, num_updates=19400, lr=0.00227038, gnorm=0.428, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12132
2024-05-25 02:40:57 | INFO | train_inner | epoch 003:   5937 / 6724 loss=4.886, ppl=29.57, wps=435711, ups=1.66, wpb=262144, bsz=512, num_updates=19500, lr=0.00226455, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12192
2024-05-25 02:41:57 | INFO | train_inner | epoch 003:   6037 / 6724 loss=4.887, ppl=29.58, wps=436840, ups=1.67, wpb=262144, bsz=512, num_updates=19600, lr=0.00225877, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12252
2024-05-25 02:42:57 | INFO | train_inner | epoch 003:   6137 / 6724 loss=4.886, ppl=29.56, wps=437053, ups=1.67, wpb=262144, bsz=512, num_updates=19700, lr=0.00225303, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12312
2024-05-25 02:43:57 | INFO | train_inner | epoch 003:   6237 / 6724 loss=4.885, ppl=29.54, wps=436120, ups=1.66, wpb=262144, bsz=512, num_updates=19800, lr=0.00224733, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12372
2024-05-25 02:44:57 | INFO | train_inner | epoch 003:   6337 / 6724 loss=4.882, ppl=29.49, wps=436504, ups=1.67, wpb=262144, bsz=512, num_updates=19900, lr=0.00224168, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12432
2024-05-25 02:45:57 | INFO | train_inner | epoch 003:   6437 / 6724 loss=4.886, ppl=29.56, wps=436272, ups=1.66, wpb=262144, bsz=512, num_updates=20000, lr=0.00223607, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12492
2024-05-25 02:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20000 updates
2024-05-25 02:45:57 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_20000.pt
2024-05-25 02:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_20000.pt
2024-05-25 02:46:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_3_20000.pt (epoch 3 @ 20000 updates, score None) (writing took 44.24966507777572 seconds)
2024-05-25 02:47:42 | INFO | train_inner | epoch 003:   6537 / 6724 loss=4.883, ppl=29.51, wps=251310, ups=0.96, wpb=262144, bsz=512, num_updates=20100, lr=0.0022305, gnorm=0.449, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12597
2024-05-25 02:48:42 | INFO | train_inner | epoch 003:   6637 / 6724 loss=4.884, ppl=29.54, wps=435845, ups=1.66, wpb=262144, bsz=512, num_updates=20200, lr=0.00222497, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12657
2024-05-25 02:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20287 updates
2024-05-25 02:49:34 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint3.pt
2024-05-25 02:49:50 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint3.pt
2024-05-25 02:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint3.pt (epoch 3 @ 20287 updates, score None) (writing took 75.59494343027472 seconds)
2024-05-25 02:50:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-05-25 02:50:50 | INFO | train | epoch 003 | loss 4.909 | ppl 30.04 | wps 419384 | ups 1.6 | wpb 262115 | bsz 511.9 | num_updates 20287 | lr 0.00222019 | gnorm 0.45 | clip 0 | loss_scale 4 | train_wall 4022 | gb_free 12.6 | wall 12785
2024-05-25 02:50:50 | INFO | fairseq.trainer | loading train data for epoch 4
2024-05-25 02:50:50 | INFO | fairseq.data.data_utils | loaded 52,445,000 examples from: ./data/data-bin/3/train
2024-05-25 02:50:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6739
2024-05-25 02:50:51 | INFO | fairseq.trainer | begin training epoch 4
2024-05-25 02:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 02:50:59 | INFO | train_inner | epoch 004:     13 / 6739 loss=4.887, ppl=29.58, wps=190333, ups=0.73, wpb=260833, bsz=509.4, num_updates=20300, lr=0.00221948, gnorm=0.421, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12794
2024-05-25 02:51:59 | INFO | train_inner | epoch 004:    113 / 6739 loss=4.881, ppl=29.47, wps=438166, ups=1.67, wpb=262144, bsz=512, num_updates=20400, lr=0.00221404, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12854
2024-05-25 02:52:59 | INFO | train_inner | epoch 004:    213 / 6739 loss=4.875, ppl=29.33, wps=437350, ups=1.67, wpb=262144, bsz=512, num_updates=20500, lr=0.00220863, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12914
2024-05-25 02:53:59 | INFO | train_inner | epoch 004:    313 / 6739 loss=4.879, ppl=29.43, wps=437243, ups=1.67, wpb=262144, bsz=512, num_updates=20600, lr=0.00220326, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=12974
2024-05-25 02:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 02:54:59 | INFO | train_inner | epoch 004:    414 / 6739 loss=4.878, ppl=29.4, wps=433095, ups=1.65, wpb=262144, bsz=512, num_updates=20700, lr=0.00219793, gnorm=0.485, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13034
2024-05-25 02:55:59 | INFO | train_inner | epoch 004:    514 / 6739 loss=4.875, ppl=29.35, wps=437974, ups=1.67, wpb=262144, bsz=512, num_updates=20800, lr=0.00219265, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13094
2024-05-25 02:56:59 | INFO | train_inner | epoch 004:    614 / 6739 loss=4.874, ppl=29.33, wps=437482, ups=1.67, wpb=262144, bsz=512, num_updates=20900, lr=0.00218739, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13154
2024-05-25 02:57:59 | INFO | train_inner | epoch 004:    714 / 6739 loss=4.874, ppl=29.31, wps=437423, ups=1.67, wpb=262144, bsz=512, num_updates=21000, lr=0.00218218, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13214
2024-05-25 02:58:59 | INFO | train_inner | epoch 004:    814 / 6739 loss=4.879, ppl=29.42, wps=437340, ups=1.67, wpb=262144, bsz=512, num_updates=21100, lr=0.002177, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13274
2024-05-25 02:59:59 | INFO | train_inner | epoch 004:    914 / 6739 loss=4.873, ppl=29.3, wps=437009, ups=1.67, wpb=262144, bsz=512, num_updates=21200, lr=0.00217186, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13334
2024-05-25 03:00:59 | INFO | train_inner | epoch 004:   1014 / 6739 loss=4.871, ppl=29.27, wps=437392, ups=1.67, wpb=262144, bsz=512, num_updates=21300, lr=0.00216676, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13394
2024-05-25 03:01:59 | INFO | train_inner | epoch 004:   1114 / 6739 loss=4.873, ppl=29.31, wps=437056, ups=1.67, wpb=262144, bsz=512, num_updates=21400, lr=0.00216169, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13454
2024-05-25 03:02:59 | INFO | train_inner | epoch 004:   1214 / 6739 loss=4.872, ppl=29.29, wps=437388, ups=1.67, wpb=262144, bsz=512, num_updates=21500, lr=0.00215666, gnorm=0.459, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13514
2024-05-25 03:03:59 | INFO | train_inner | epoch 004:   1314 / 6739 loss=4.867, ppl=29.17, wps=437175, ups=1.67, wpb=262144, bsz=512, num_updates=21600, lr=0.00215166, gnorm=0.456, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13574
2024-05-25 03:04:59 | INFO | train_inner | epoch 004:   1414 / 6739 loss=4.877, ppl=29.39, wps=437040, ups=1.67, wpb=262144, bsz=512, num_updates=21700, lr=0.00214669, gnorm=0.433, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13634
2024-05-25 03:05:59 | INFO | train_inner | epoch 004:   1514 / 6739 loss=4.878, ppl=29.41, wps=437268, ups=1.67, wpb=262144, bsz=512, num_updates=21800, lr=0.00214176, gnorm=0.428, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13694
2024-05-25 03:06:58 | INFO | train_inner | epoch 004:   1614 / 6739 loss=4.874, ppl=29.33, wps=437239, ups=1.67, wpb=262144, bsz=512, num_updates=21900, lr=0.00213687, gnorm=0.421, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13754
2024-05-25 03:07:58 | INFO | train_inner | epoch 004:   1714 / 6739 loss=4.872, ppl=29.29, wps=437184, ups=1.67, wpb=262144, bsz=512, num_updates=22000, lr=0.00213201, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13813
2024-05-25 03:08:58 | INFO | train_inner | epoch 004:   1814 / 6739 loss=4.868, ppl=29.2, wps=436718, ups=1.67, wpb=262144, bsz=512, num_updates=22100, lr=0.00212718, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13874
2024-05-25 03:09:58 | INFO | train_inner | epoch 004:   1914 / 6739 loss=4.869, ppl=29.22, wps=437306, ups=1.67, wpb=262144, bsz=512, num_updates=22200, lr=0.00212238, gnorm=0.473, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13933
2024-05-25 03:10:58 | INFO | train_inner | epoch 004:   2014 / 6739 loss=4.867, ppl=29.18, wps=437164, ups=1.67, wpb=262144, bsz=512, num_updates=22300, lr=0.00211762, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=13993
2024-05-25 03:11:58 | INFO | train_inner | epoch 004:   2114 / 6739 loss=4.87, ppl=29.25, wps=436406, ups=1.66, wpb=262144, bsz=512, num_updates=22400, lr=0.00211289, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14053
2024-05-25 03:12:58 | INFO | train_inner | epoch 004:   2214 / 6739 loss=4.869, ppl=29.21, wps=437369, ups=1.67, wpb=262144, bsz=512, num_updates=22500, lr=0.00210819, gnorm=0.449, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14113
2024-05-25 03:13:58 | INFO | train_inner | epoch 004:   2314 / 6739 loss=4.871, ppl=29.25, wps=437276, ups=1.67, wpb=262144, bsz=512, num_updates=22600, lr=0.00210352, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14173
2024-05-25 03:14:58 | INFO | train_inner | epoch 004:   2414 / 6739 loss=4.87, ppl=29.24, wps=437352, ups=1.67, wpb=262144, bsz=512, num_updates=22700, lr=0.00209888, gnorm=0.411, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14233
2024-05-25 03:15:58 | INFO | train_inner | epoch 004:   2514 / 6739 loss=4.867, ppl=29.19, wps=437304, ups=1.67, wpb=262144, bsz=512, num_updates=22800, lr=0.00209427, gnorm=0.417, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14293
2024-05-25 03:16:58 | INFO | train_inner | epoch 004:   2614 / 6739 loss=4.865, ppl=29.15, wps=436962, ups=1.67, wpb=262144, bsz=512, num_updates=22900, lr=0.00208969, gnorm=0.453, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14353
2024-05-25 03:17:58 | INFO | train_inner | epoch 004:   2714 / 6739 loss=4.865, ppl=29.13, wps=437334, ups=1.67, wpb=262144, bsz=512, num_updates=23000, lr=0.00208514, gnorm=0.503, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14413
2024-05-25 03:18:58 | INFO | train_inner | epoch 004:   2814 / 6739 loss=4.862, ppl=29.08, wps=437336, ups=1.67, wpb=262144, bsz=512, num_updates=23100, lr=0.00208063, gnorm=0.484, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14473
2024-05-25 03:19:58 | INFO | train_inner | epoch 004:   2914 / 6739 loss=4.865, ppl=29.13, wps=437244, ups=1.67, wpb=262142, bsz=512, num_updates=23200, lr=0.00207614, gnorm=0.438, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14533
2024-05-25 03:20:58 | INFO | train_inner | epoch 004:   3014 / 6739 loss=4.866, ppl=29.16, wps=437034, ups=1.67, wpb=262144, bsz=512, num_updates=23300, lr=0.00207168, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14593
2024-05-25 03:21:58 | INFO | train_inner | epoch 004:   3114 / 6739 loss=4.864, ppl=29.13, wps=437326, ups=1.67, wpb=262144, bsz=512, num_updates=23400, lr=0.00206725, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14653
2024-05-25 03:22:58 | INFO | train_inner | epoch 004:   3214 / 6739 loss=4.865, ppl=29.14, wps=437217, ups=1.67, wpb=262144, bsz=512, num_updates=23500, lr=0.00206284, gnorm=0.43, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14713
2024-05-25 03:23:58 | INFO | train_inner | epoch 004:   3314 / 6739 loss=4.861, ppl=29.07, wps=437088, ups=1.67, wpb=262144, bsz=512, num_updates=23600, lr=0.00205847, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14773
2024-05-25 03:24:58 | INFO | train_inner | epoch 004:   3414 / 6739 loss=4.864, ppl=29.13, wps=436987, ups=1.67, wpb=262144, bsz=512, num_updates=23700, lr=0.00205412, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14833
2024-05-25 03:25:58 | INFO | train_inner | epoch 004:   3514 / 6739 loss=4.862, ppl=29.07, wps=437121, ups=1.67, wpb=262144, bsz=512, num_updates=23800, lr=0.0020498, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14893
2024-05-25 03:26:58 | INFO | train_inner | epoch 004:   3614 / 6739 loss=4.86, ppl=29.04, wps=437027, ups=1.67, wpb=262144, bsz=512, num_updates=23900, lr=0.00204551, gnorm=0.448, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=14953
2024-05-25 03:27:58 | INFO | train_inner | epoch 004:   3714 / 6739 loss=4.859, ppl=29.03, wps=437200, ups=1.67, wpb=262144, bsz=512, num_updates=24000, lr=0.00204124, gnorm=0.451, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15013
2024-05-25 03:28:58 | INFO | train_inner | epoch 004:   3814 / 6739 loss=4.862, ppl=29.09, wps=437205, ups=1.67, wpb=262144, bsz=512, num_updates=24100, lr=0.002037, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15073
2024-05-25 03:29:58 | INFO | train_inner | epoch 004:   3914 / 6739 loss=4.86, ppl=29.04, wps=437098, ups=1.67, wpb=262144, bsz=512, num_updates=24200, lr=0.00203279, gnorm=0.436, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15133
2024-05-25 03:30:58 | INFO | train_inner | epoch 004:   4014 / 6739 loss=4.854, ppl=28.93, wps=436808, ups=1.67, wpb=262144, bsz=512, num_updates=24300, lr=0.0020286, gnorm=0.452, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15193
2024-05-25 03:31:58 | INFO | train_inner | epoch 004:   4114 / 6739 loss=4.858, ppl=29, wps=436496, ups=1.67, wpb=262144, bsz=512, num_updates=24400, lr=0.00202444, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15253
2024-05-25 03:32:58 | INFO | train_inner | epoch 004:   4214 / 6739 loss=4.86, ppl=29.05, wps=437112, ups=1.67, wpb=262144, bsz=512, num_updates=24500, lr=0.00202031, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15313
2024-05-25 03:33:58 | INFO | train_inner | epoch 004:   4314 / 6739 loss=4.859, ppl=29.01, wps=436935, ups=1.67, wpb=262144, bsz=512, num_updates=24600, lr=0.00201619, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15373
2024-05-25 03:34:58 | INFO | train_inner | epoch 004:   4414 / 6739 loss=4.854, ppl=28.92, wps=436835, ups=1.67, wpb=262144, bsz=512, num_updates=24700, lr=0.00201211, gnorm=0.484, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15433
2024-05-25 03:35:58 | INFO | train_inner | epoch 004:   4514 / 6739 loss=4.86, ppl=29.03, wps=437179, ups=1.67, wpb=262144, bsz=512, num_updates=24800, lr=0.00200805, gnorm=0.439, clip=0, loss_scale=8, train_wall=60, gb_free=12.6, wall=15493
2024-05-25 03:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 03:36:58 | INFO | train_inner | epoch 004:   4615 / 6739 loss=4.857, ppl=28.99, wps=432714, ups=1.65, wpb=262144, bsz=512, num_updates=24900, lr=0.00200401, gnorm=0.469, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15553
2024-05-25 03:37:58 | INFO | train_inner | epoch 004:   4715 / 6739 loss=4.856, ppl=28.97, wps=437086, ups=1.67, wpb=262144, bsz=512, num_updates=25000, lr=0.002, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15613
2024-05-25 03:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 25000 updates
2024-05-25 03:37:58 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_4_25000.pt
2024-05-25 03:38:14 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_4_25000.pt
2024-05-25 03:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_4_25000.pt (epoch 4 @ 25000 updates, score None) (writing took 44.196833457797766 seconds)
2024-05-25 03:39:42 | INFO | train_inner | epoch 004:   4815 / 6739 loss=4.854, ppl=28.91, wps=251786, ups=0.96, wpb=262144, bsz=512, num_updates=25100, lr=0.00199601, gnorm=0.488, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15718
2024-05-25 03:40:42 | INFO | train_inner | epoch 004:   4915 / 6739 loss=4.853, ppl=28.9, wps=437152, ups=1.67, wpb=262103, bsz=511.9, num_updates=25200, lr=0.00199205, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15777
2024-05-25 03:41:42 | INFO | train_inner | epoch 004:   5015 / 6739 loss=4.851, ppl=28.85, wps=436743, ups=1.67, wpb=262144, bsz=512, num_updates=25300, lr=0.00198811, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15837
2024-05-25 03:42:42 | INFO | train_inner | epoch 004:   5115 / 6739 loss=4.852, ppl=28.88, wps=436976, ups=1.67, wpb=262144, bsz=512, num_updates=25400, lr=0.00198419, gnorm=0.447, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15897
2024-05-25 03:43:42 | INFO | train_inner | epoch 004:   5215 / 6739 loss=4.858, ppl=28.99, wps=436640, ups=1.67, wpb=262144, bsz=512, num_updates=25500, lr=0.0019803, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=15958
2024-05-25 03:44:43 | INFO | train_inner | epoch 004:   5315 / 6739 loss=4.856, ppl=28.96, wps=436250, ups=1.66, wpb=262144, bsz=512, num_updates=25600, lr=0.00197642, gnorm=0.495, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16018
2024-05-25 03:45:43 | INFO | train_inner | epoch 004:   5415 / 6739 loss=4.851, ppl=28.86, wps=436967, ups=1.67, wpb=262144, bsz=512, num_updates=25700, lr=0.00197257, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16078
2024-05-25 03:46:43 | INFO | train_inner | epoch 004:   5515 / 6739 loss=4.853, ppl=28.9, wps=437372, ups=1.67, wpb=262144, bsz=512, num_updates=25800, lr=0.00196875, gnorm=0.485, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16138
2024-05-25 03:47:43 | INFO | train_inner | epoch 004:   5615 / 6739 loss=4.854, ppl=28.91, wps=436818, ups=1.67, wpb=262144, bsz=512, num_updates=25900, lr=0.00196494, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16198
2024-05-25 03:48:43 | INFO | train_inner | epoch 004:   5715 / 6739 loss=4.854, ppl=28.92, wps=436656, ups=1.67, wpb=262144, bsz=512, num_updates=26000, lr=0.00196116, gnorm=0.469, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16258
2024-05-25 03:49:43 | INFO | train_inner | epoch 004:   5815 / 6739 loss=4.851, ppl=28.86, wps=436989, ups=1.67, wpb=262144, bsz=512, num_updates=26100, lr=0.0019574, gnorm=0.475, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16318
2024-05-25 03:50:43 | INFO | train_inner | epoch 004:   5915 / 6739 loss=4.849, ppl=28.82, wps=437058, ups=1.67, wpb=262144, bsz=512, num_updates=26200, lr=0.00195366, gnorm=0.432, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16378
2024-05-25 03:51:43 | INFO | train_inner | epoch 004:   6015 / 6739 loss=4.85, ppl=28.84, wps=436841, ups=1.67, wpb=262144, bsz=512, num_updates=26300, lr=0.00194994, gnorm=0.414, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16438
2024-05-25 03:52:43 | INFO | train_inner | epoch 004:   6115 / 6739 loss=4.848, ppl=28.81, wps=436294, ups=1.66, wpb=262144, bsz=512, num_updates=26400, lr=0.00194625, gnorm=0.456, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16498
2024-05-25 03:53:43 | INFO | train_inner | epoch 004:   6215 / 6739 loss=4.848, ppl=28.79, wps=437436, ups=1.67, wpb=262144, bsz=512, num_updates=26500, lr=0.00194257, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16558
2024-05-25 03:54:43 | INFO | train_inner | epoch 004:   6315 / 6739 loss=4.846, ppl=28.77, wps=437153, ups=1.67, wpb=262144, bsz=512, num_updates=26600, lr=0.00193892, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16618
2024-05-25 03:55:43 | INFO | train_inner | epoch 004:   6415 / 6739 loss=4.846, ppl=28.76, wps=436040, ups=1.66, wpb=262144, bsz=512, num_updates=26700, lr=0.00193528, gnorm=0.475, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16678
2024-05-25 03:56:43 | INFO | train_inner | epoch 004:   6515 / 6739 loss=4.851, ppl=28.85, wps=436731, ups=1.67, wpb=262144, bsz=512, num_updates=26800, lr=0.00193167, gnorm=0.482, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16738
2024-05-25 03:57:43 | INFO | train_inner | epoch 004:   6615 / 6739 loss=4.85, ppl=28.84, wps=436803, ups=1.67, wpb=262144, bsz=512, num_updates=26900, lr=0.00192807, gnorm=0.466, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16798
2024-05-25 03:58:43 | INFO | train_inner | epoch 004:   6715 / 6739 loss=4.847, ppl=28.78, wps=436616, ups=1.67, wpb=262144, bsz=512, num_updates=27000, lr=0.0019245, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16858
2024-05-25 03:58:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 27024 updates
2024-05-25 03:58:57 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint4.pt
2024-05-25 03:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint4.pt
2024-05-25 04:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint4.pt (epoch 4 @ 27024 updates, score None) (writing took 78.28903534263372 seconds)
2024-05-25 04:00:15 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-05-25 04:00:15 | INFO | train | epoch 004 | loss 4.862 | ppl 29.09 | wps 423937 | ups 1.62 | wpb 262134 | bsz 512 | num_updates 27024 | lr 0.00192365 | gnorm 0.452 | clip 0 | loss_scale 4 | train_wall 4027 | gb_free 12.6 | wall 16950
2024-05-25 04:00:15 | INFO | fairseq.trainer | loading train data for epoch 5
2024-05-25 04:00:16 | INFO | fairseq.data.data_utils | loaded 52,822,000 examples from: ./data/data-bin/4/train
2024-05-25 04:00:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6784
2024-05-25 04:00:17 | INFO | fairseq.trainer | begin training epoch 5
2024-05-25 04:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 04:01:03 | INFO | train_inner | epoch 005:     76 / 6784 loss=4.851, ppl=28.87, wps=186813, ups=0.71, wpb=261489, bsz=510.7, num_updates=27100, lr=0.00192095, gnorm=0.458, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=16998
2024-05-25 04:02:03 | INFO | train_inner | epoch 005:    176 / 6784 loss=4.852, ppl=28.87, wps=436764, ups=1.67, wpb=262144, bsz=512, num_updates=27200, lr=0.00191741, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17058
2024-05-25 04:03:03 | INFO | train_inner | epoch 005:    276 / 6784 loss=4.848, ppl=28.8, wps=436548, ups=1.67, wpb=262144, bsz=512, num_updates=27300, lr=0.0019139, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17118
2024-05-25 04:04:03 | INFO | train_inner | epoch 005:    376 / 6784 loss=4.854, ppl=28.93, wps=436597, ups=1.67, wpb=262144, bsz=512, num_updates=27400, lr=0.0019104, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17178
2024-05-25 04:05:03 | INFO | train_inner | epoch 005:    476 / 6784 loss=4.846, ppl=28.75, wps=437021, ups=1.67, wpb=262144, bsz=512, num_updates=27500, lr=0.00190693, gnorm=0.484, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17238
2024-05-25 04:06:03 | INFO | train_inner | epoch 005:    576 / 6784 loss=4.844, ppl=28.71, wps=436863, ups=1.67, wpb=262144, bsz=512, num_updates=27600, lr=0.00190347, gnorm=0.47, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17298
2024-05-25 04:07:03 | INFO | train_inner | epoch 005:    676 / 6784 loss=4.851, ppl=28.86, wps=436853, ups=1.67, wpb=262144, bsz=512, num_updates=27700, lr=0.00190003, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17358
2024-05-25 04:08:03 | INFO | train_inner | epoch 005:    776 / 6784 loss=4.843, ppl=28.7, wps=436712, ups=1.67, wpb=262144, bsz=512, num_updates=27800, lr=0.00189661, gnorm=0.483, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17418
2024-05-25 04:09:03 | INFO | train_inner | epoch 005:    876 / 6784 loss=4.85, ppl=28.83, wps=437343, ups=1.67, wpb=262144, bsz=512, num_updates=27900, lr=0.00189321, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17478
2024-05-25 04:10:03 | INFO | train_inner | epoch 005:    976 / 6784 loss=4.844, ppl=28.72, wps=436075, ups=1.67, wpb=261519, bsz=510.8, num_updates=28000, lr=0.00188982, gnorm=0.458, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17538
2024-05-25 04:11:03 | INFO | train_inner | epoch 005:   1076 / 6784 loss=4.844, ppl=28.72, wps=436629, ups=1.67, wpb=262144, bsz=512, num_updates=28100, lr=0.00188646, gnorm=0.484, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17598
2024-05-25 04:12:03 | INFO | train_inner | epoch 005:   1176 / 6784 loss=4.842, ppl=28.68, wps=436735, ups=1.67, wpb=262144, bsz=512, num_updates=28200, lr=0.00188311, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17658
2024-05-25 04:13:03 | INFO | train_inner | epoch 005:   1276 / 6784 loss=4.844, ppl=28.73, wps=437203, ups=1.67, wpb=262144, bsz=512, num_updates=28300, lr=0.00187978, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17718
2024-05-25 04:14:03 | INFO | train_inner | epoch 005:   1376 / 6784 loss=4.842, ppl=28.68, wps=437531, ups=1.67, wpb=262144, bsz=512, num_updates=28400, lr=0.00187647, gnorm=0.444, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17778
2024-05-25 04:15:03 | INFO | train_inner | epoch 005:   1476 / 6784 loss=4.845, ppl=28.73, wps=437548, ups=1.67, wpb=262144, bsz=512, num_updates=28500, lr=0.00187317, gnorm=0.466, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17838
2024-05-25 04:16:03 | INFO | train_inner | epoch 005:   1576 / 6784 loss=4.834, ppl=28.51, wps=437652, ups=1.67, wpb=262144, bsz=512, num_updates=28600, lr=0.00186989, gnorm=0.47, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17898
2024-05-25 04:17:02 | INFO | train_inner | epoch 005:   1676 / 6784 loss=4.845, ppl=28.74, wps=437474, ups=1.67, wpb=262144, bsz=512, num_updates=28700, lr=0.00186663, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=17957
2024-05-25 04:18:02 | INFO | train_inner | epoch 005:   1776 / 6784 loss=4.842, ppl=28.67, wps=437605, ups=1.67, wpb=262144, bsz=512, num_updates=28800, lr=0.00186339, gnorm=0.475, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18017
2024-05-25 04:19:02 | INFO | train_inner | epoch 005:   1876 / 6784 loss=4.843, ppl=28.7, wps=437378, ups=1.67, wpb=262144, bsz=512, num_updates=28900, lr=0.00186016, gnorm=0.486, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18077
2024-05-25 04:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 04:20:03 | INFO | train_inner | epoch 005:   1977 / 6784 loss=4.846, ppl=28.76, wps=433065, ups=1.65, wpb=262144, bsz=512, num_updates=29000, lr=0.00185695, gnorm=0.469, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18138
2024-05-25 04:21:03 | INFO | train_inner | epoch 005:   2077 / 6784 loss=4.844, ppl=28.72, wps=437480, ups=1.67, wpb=262144, bsz=512, num_updates=29100, lr=0.00185376, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18198
2024-05-25 04:22:03 | INFO | train_inner | epoch 005:   2177 / 6784 loss=4.843, ppl=28.71, wps=437638, ups=1.67, wpb=262144, bsz=512, num_updates=29200, lr=0.00185058, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18258
2024-05-25 04:23:03 | INFO | train_inner | epoch 005:   2277 / 6784 loss=4.839, ppl=28.62, wps=437267, ups=1.67, wpb=262144, bsz=512, num_updates=29300, lr=0.00184742, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18318
2024-05-25 04:24:03 | INFO | train_inner | epoch 005:   2377 / 6784 loss=4.843, ppl=28.71, wps=437239, ups=1.67, wpb=262144, bsz=512, num_updates=29400, lr=0.00184428, gnorm=0.481, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18378
2024-05-25 04:25:02 | INFO | train_inner | epoch 005:   2477 / 6784 loss=4.843, ppl=28.7, wps=437604, ups=1.67, wpb=262144, bsz=512, num_updates=29500, lr=0.00184115, gnorm=0.437, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18437
2024-05-25 04:26:02 | INFO | train_inner | epoch 005:   2577 / 6784 loss=4.839, ppl=28.62, wps=437406, ups=1.67, wpb=262144, bsz=512, num_updates=29600, lr=0.00183804, gnorm=0.45, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18497
2024-05-25 04:27:02 | INFO | train_inner | epoch 005:   2677 / 6784 loss=4.84, ppl=28.65, wps=437329, ups=1.67, wpb=262144, bsz=512, num_updates=29700, lr=0.00183494, gnorm=0.456, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18557
2024-05-25 04:28:02 | INFO | train_inner | epoch 005:   2777 / 6784 loss=4.837, ppl=28.58, wps=437389, ups=1.67, wpb=262144, bsz=512, num_updates=29800, lr=0.00183186, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18617
2024-05-25 04:29:02 | INFO | train_inner | epoch 005:   2877 / 6784 loss=4.837, ppl=28.59, wps=437554, ups=1.67, wpb=262144, bsz=512, num_updates=29900, lr=0.00182879, gnorm=0.474, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18677
2024-05-25 04:30:02 | INFO | train_inner | epoch 005:   2977 / 6784 loss=4.838, ppl=28.6, wps=437270, ups=1.67, wpb=262144, bsz=512, num_updates=30000, lr=0.00182574, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18737
2024-05-25 04:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 30000 updates
2024-05-25 04:30:02 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_5_30000.pt
2024-05-25 04:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_5_30000.pt
2024-05-25 04:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_5_30000.pt (epoch 5 @ 30000 updates, score None) (writing took 45.10638913884759 seconds)
2024-05-25 04:31:47 | INFO | train_inner | epoch 005:   3077 / 6784 loss=4.837, ppl=28.57, wps=249755, ups=0.95, wpb=262144, bsz=512, num_updates=30100, lr=0.00182271, gnorm=0.451, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18842
2024-05-25 04:32:47 | INFO | train_inner | epoch 005:   3177 / 6784 loss=4.84, ppl=28.65, wps=436839, ups=1.67, wpb=262144, bsz=512, num_updates=30200, lr=0.00181969, gnorm=0.417, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18902
2024-05-25 04:33:47 | INFO | train_inner | epoch 005:   3277 / 6784 loss=4.833, ppl=28.5, wps=436792, ups=1.67, wpb=262144, bsz=512, num_updates=30300, lr=0.00181668, gnorm=0.497, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=18962
2024-05-25 04:34:47 | INFO | train_inner | epoch 005:   3377 / 6784 loss=4.833, ppl=28.51, wps=436901, ups=1.67, wpb=262144, bsz=512, num_updates=30400, lr=0.00181369, gnorm=0.448, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19022
2024-05-25 04:35:47 | INFO | train_inner | epoch 005:   3477 / 6784 loss=4.835, ppl=28.53, wps=436656, ups=1.67, wpb=262144, bsz=512, num_updates=30500, lr=0.00181071, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19082
2024-05-25 04:36:47 | INFO | train_inner | epoch 005:   3577 / 6784 loss=4.83, ppl=28.44, wps=436508, ups=1.67, wpb=262144, bsz=512, num_updates=30600, lr=0.00180775, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19142
2024-05-25 04:37:47 | INFO | train_inner | epoch 005:   3677 / 6784 loss=4.836, ppl=28.55, wps=436910, ups=1.67, wpb=262144, bsz=512, num_updates=30700, lr=0.00180481, gnorm=0.528, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19202
2024-05-25 04:38:47 | INFO | train_inner | epoch 005:   3777 / 6784 loss=4.834, ppl=28.52, wps=436906, ups=1.67, wpb=262144, bsz=512, num_updates=30800, lr=0.00180187, gnorm=0.399, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19262
2024-05-25 04:39:47 | INFO | train_inner | epoch 005:   3877 / 6784 loss=4.833, ppl=28.5, wps=436678, ups=1.67, wpb=262144, bsz=512, num_updates=30900, lr=0.00179896, gnorm=0.495, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19322
2024-05-25 04:40:47 | INFO | train_inner | epoch 005:   3977 / 6784 loss=4.83, ppl=28.45, wps=436986, ups=1.67, wpb=262144, bsz=512, num_updates=31000, lr=0.00179605, gnorm=0.447, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19382
2024-05-25 04:41:47 | INFO | train_inner | epoch 005:   4077 / 6784 loss=4.835, ppl=28.53, wps=436547, ups=1.67, wpb=262144, bsz=512, num_updates=31100, lr=0.00179316, gnorm=0.486, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19442
2024-05-25 04:42:47 | INFO | train_inner | epoch 005:   4177 / 6784 loss=4.833, ppl=28.51, wps=436655, ups=1.67, wpb=262144, bsz=512, num_updates=31200, lr=0.00179029, gnorm=0.421, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19502
2024-05-25 04:43:47 | INFO | train_inner | epoch 005:   4277 / 6784 loss=4.833, ppl=28.5, wps=436927, ups=1.67, wpb=262144, bsz=512, num_updates=31300, lr=0.00178743, gnorm=0.449, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19562
2024-05-25 04:44:47 | INFO | train_inner | epoch 005:   4377 / 6784 loss=4.835, ppl=28.53, wps=436983, ups=1.67, wpb=262144, bsz=512, num_updates=31400, lr=0.00178458, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19622
2024-05-25 04:45:47 | INFO | train_inner | epoch 005:   4477 / 6784 loss=4.832, ppl=28.49, wps=436993, ups=1.67, wpb=262144, bsz=512, num_updates=31500, lr=0.00178174, gnorm=0.434, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19682
2024-05-25 04:46:47 | INFO | train_inner | epoch 005:   4577 / 6784 loss=4.829, ppl=28.43, wps=436777, ups=1.67, wpb=262144, bsz=512, num_updates=31600, lr=0.00177892, gnorm=0.433, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19742
2024-05-25 04:47:47 | INFO | train_inner | epoch 005:   4677 / 6784 loss=4.827, ppl=28.39, wps=437034, ups=1.67, wpb=262144, bsz=512, num_updates=31700, lr=0.00177611, gnorm=0.461, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19802
2024-05-25 04:48:47 | INFO | train_inner | epoch 005:   4777 / 6784 loss=4.832, ppl=28.49, wps=436643, ups=1.67, wpb=262144, bsz=512, num_updates=31800, lr=0.00177332, gnorm=0.458, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19862
2024-05-25 04:49:47 | INFO | train_inner | epoch 005:   4877 / 6784 loss=4.832, ppl=28.48, wps=436926, ups=1.67, wpb=262144, bsz=512, num_updates=31900, lr=0.00177054, gnorm=0.429, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19922
2024-05-25 04:50:47 | INFO | train_inner | epoch 005:   4977 / 6784 loss=4.83, ppl=28.45, wps=436981, ups=1.67, wpb=262144, bsz=512, num_updates=32000, lr=0.00176777, gnorm=0.468, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=19982
2024-05-25 04:51:47 | INFO | train_inner | epoch 005:   5077 / 6784 loss=4.83, ppl=28.44, wps=436959, ups=1.67, wpb=262144, bsz=512, num_updates=32100, lr=0.00176501, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20042
2024-05-25 04:52:47 | INFO | train_inner | epoch 005:   5177 / 6784 loss=4.831, ppl=28.45, wps=436466, ups=1.66, wpb=262144, bsz=512, num_updates=32200, lr=0.00176227, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20102
2024-05-25 04:53:48 | INFO | train_inner | epoch 005:   5277 / 6784 loss=4.835, ppl=28.54, wps=435922, ups=1.66, wpb=262144, bsz=512, num_updates=32300, lr=0.00175954, gnorm=0.474, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20163
2024-05-25 04:54:48 | INFO | train_inner | epoch 005:   5377 / 6784 loss=4.83, ppl=28.45, wps=436848, ups=1.67, wpb=262144, bsz=512, num_updates=32400, lr=0.00175682, gnorm=0.502, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20223
2024-05-25 04:55:48 | INFO | train_inner | epoch 005:   5477 / 6784 loss=4.828, ppl=28.41, wps=436908, ups=1.67, wpb=262144, bsz=512, num_updates=32500, lr=0.00175412, gnorm=0.473, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20283
2024-05-25 04:56:48 | INFO | train_inner | epoch 005:   5577 / 6784 loss=4.83, ppl=28.44, wps=436973, ups=1.67, wpb=262142, bsz=512, num_updates=32600, lr=0.00175142, gnorm=0.427, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20343
2024-05-25 04:57:48 | INFO | train_inner | epoch 005:   5677 / 6784 loss=4.827, ppl=28.38, wps=436886, ups=1.67, wpb=262144, bsz=512, num_updates=32700, lr=0.00174874, gnorm=0.459, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20403
2024-05-25 04:58:48 | INFO | train_inner | epoch 005:   5777 / 6784 loss=4.832, ppl=28.49, wps=436865, ups=1.67, wpb=262144, bsz=512, num_updates=32800, lr=0.00174608, gnorm=0.489, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20463
2024-05-25 04:59:48 | INFO | train_inner | epoch 005:   5877 / 6784 loss=4.826, ppl=28.36, wps=437013, ups=1.67, wpb=262144, bsz=512, num_updates=32900, lr=0.00174342, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20523
2024-05-25 05:00:48 | INFO | train_inner | epoch 005:   5977 / 6784 loss=4.828, ppl=28.4, wps=436910, ups=1.67, wpb=262144, bsz=512, num_updates=33000, lr=0.00174078, gnorm=0.477, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20583
2024-05-25 05:01:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 05:01:48 | INFO | train_inner | epoch 005:   6078 / 6784 loss=4.826, ppl=28.35, wps=432606, ups=1.65, wpb=262144, bsz=512, num_updates=33100, lr=0.00173814, gnorm=0.498, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20643
2024-05-25 05:02:48 | INFO | train_inner | epoch 005:   6178 / 6784 loss=4.823, ppl=28.31, wps=437041, ups=1.67, wpb=262144, bsz=512, num_updates=33200, lr=0.00173553, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20703
2024-05-25 05:03:48 | INFO | train_inner | epoch 005:   6278 / 6784 loss=4.825, ppl=28.35, wps=437026, ups=1.67, wpb=262144, bsz=512, num_updates=33300, lr=0.00173292, gnorm=0.448, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20763
2024-05-25 05:04:48 | INFO | train_inner | epoch 005:   6378 / 6784 loss=4.826, ppl=28.37, wps=435873, ups=1.67, wpb=261571, bsz=510.9, num_updates=33400, lr=0.00173032, gnorm=0.449, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20823
2024-05-25 05:05:48 | INFO | train_inner | epoch 005:   6478 / 6784 loss=4.823, ppl=28.3, wps=436971, ups=1.67, wpb=262144, bsz=512, num_updates=33500, lr=0.00172774, gnorm=0.494, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20883
2024-05-25 05:06:48 | INFO | train_inner | epoch 005:   6578 / 6784 loss=4.826, ppl=28.36, wps=436974, ups=1.67, wpb=262144, bsz=512, num_updates=33600, lr=0.00172516, gnorm=0.451, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=20943
2024-05-25 05:07:48 | INFO | train_inner | epoch 005:   6678 / 6784 loss=4.819, ppl=28.22, wps=436768, ups=1.67, wpb=262144, bsz=512, num_updates=33700, lr=0.0017226, gnorm=0.414, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21003
2024-05-25 05:08:48 | INFO | train_inner | epoch 005:   6778 / 6784 loss=4.824, ppl=28.32, wps=436897, ups=1.67, wpb=262144, bsz=512, num_updates=33800, lr=0.00172005, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21063
2024-05-25 05:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33806 updates
2024-05-25 05:08:52 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint5.pt
2024-05-25 05:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint5.pt
2024-05-25 05:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint5.pt (epoch 5 @ 33806 updates, score None) (writing took 78.76502312347293 seconds)
2024-05-25 05:10:10 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-05-25 05:10:10 | INFO | train | epoch 005 | loss 4.836 | ppl 28.56 | wps 423770 | ups 1.62 | wpb 262126 | bsz 512 | num_updates 33806 | lr 0.0017199 | gnorm 0.46 | clip 0 | loss_scale 4 | train_wall 4055 | gb_free 12.6 | wall 21146
2024-05-25 05:10:10 | INFO | fairseq.trainer | loading train data for epoch 6
2024-05-25 05:10:11 | INFO | fairseq.data.data_utils | loaded 52,348,000 examples from: ./data/data-bin/5/train
2024-05-25 05:10:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6735
2024-05-25 05:10:13 | INFO | fairseq.trainer | begin training epoch 6
2024-05-25 05:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 05:11:09 | INFO | train_inner | epoch 006:     94 / 6735 loss=4.828, ppl=28.4, wps=186027, ups=0.71, wpb=262144, bsz=512, num_updates=33900, lr=0.00171751, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21204
2024-05-25 05:12:09 | INFO | train_inner | epoch 006:    194 / 6735 loss=4.823, ppl=28.3, wps=436888, ups=1.67, wpb=262144, bsz=512, num_updates=34000, lr=0.00171499, gnorm=0.448, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21264
2024-05-25 05:13:09 | INFO | train_inner | epoch 006:    294 / 6735 loss=4.827, ppl=28.39, wps=436864, ups=1.67, wpb=262144, bsz=512, num_updates=34100, lr=0.00171247, gnorm=0.472, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21324
2024-05-25 05:14:09 | INFO | train_inner | epoch 006:    394 / 6735 loss=4.819, ppl=28.24, wps=436863, ups=1.67, wpb=262144, bsz=512, num_updates=34200, lr=0.00170996, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21384
2024-05-25 05:15:09 | INFO | train_inner | epoch 006:    494 / 6735 loss=4.824, ppl=28.33, wps=436762, ups=1.67, wpb=262144, bsz=512, num_updates=34300, lr=0.00170747, gnorm=0.489, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21444
2024-05-25 05:16:09 | INFO | train_inner | epoch 006:    594 / 6735 loss=4.822, ppl=28.29, wps=436305, ups=1.66, wpb=262144, bsz=512, num_updates=34400, lr=0.00170499, gnorm=0.459, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21504
2024-05-25 05:17:09 | INFO | train_inner | epoch 006:    694 / 6735 loss=4.823, ppl=28.31, wps=436728, ups=1.67, wpb=262144, bsz=512, num_updates=34500, lr=0.00170251, gnorm=0.494, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21564
2024-05-25 05:18:09 | INFO | train_inner | epoch 006:    794 / 6735 loss=4.827, ppl=28.38, wps=436929, ups=1.67, wpb=262144, bsz=512, num_updates=34600, lr=0.00170005, gnorm=0.435, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21624
2024-05-25 05:19:09 | INFO | train_inner | epoch 006:    894 / 6735 loss=4.823, ppl=28.3, wps=436787, ups=1.67, wpb=262144, bsz=512, num_updates=34700, lr=0.0016976, gnorm=0.475, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21684
2024-05-25 05:20:09 | INFO | train_inner | epoch 006:    994 / 6735 loss=4.826, ppl=28.37, wps=436545, ups=1.67, wpb=262144, bsz=512, num_updates=34800, lr=0.00169516, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21744
2024-05-25 05:21:09 | INFO | train_inner | epoch 006:   1094 / 6735 loss=4.819, ppl=28.22, wps=435866, ups=1.67, wpb=261519, bsz=510.8, num_updates=34900, lr=0.00169273, gnorm=0.489, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21804
2024-05-25 05:22:09 | INFO | train_inner | epoch 006:   1194 / 6735 loss=4.826, ppl=28.36, wps=437025, ups=1.67, wpb=262144, bsz=512, num_updates=35000, lr=0.00169031, gnorm=0.497, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21864
2024-05-25 05:22:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 35000 updates
2024-05-25 05:22:09 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_35000.pt
2024-05-25 05:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_35000.pt
2024-05-25 05:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_35000.pt (epoch 6 @ 35000 updates, score None) (writing took 44.252523832023144 seconds)
2024-05-25 05:23:53 | INFO | train_inner | epoch 006:   1294 / 6735 loss=4.821, ppl=28.26, wps=251634, ups=0.96, wpb=262144, bsz=512, num_updates=35100, lr=0.0016879, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=21968
2024-05-25 05:24:53 | INFO | train_inner | epoch 006:   1394 / 6735 loss=4.82, ppl=28.25, wps=436722, ups=1.67, wpb=262144, bsz=512, num_updates=35200, lr=0.0016855, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22028
2024-05-25 05:25:53 | INFO | train_inner | epoch 006:   1494 / 6735 loss=4.821, ppl=28.26, wps=437008, ups=1.67, wpb=262144, bsz=512, num_updates=35300, lr=0.00168311, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22088
2024-05-25 05:26:53 | INFO | train_inner | epoch 006:   1594 / 6735 loss=4.821, ppl=28.26, wps=436943, ups=1.67, wpb=262144, bsz=512, num_updates=35400, lr=0.00168073, gnorm=0.479, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22148
2024-05-25 05:27:53 | INFO | train_inner | epoch 006:   1694 / 6735 loss=4.825, ppl=28.34, wps=437003, ups=1.67, wpb=262144, bsz=512, num_updates=35500, lr=0.00167836, gnorm=0.452, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22208
2024-05-25 05:28:53 | INFO | train_inner | epoch 006:   1794 / 6735 loss=4.816, ppl=28.18, wps=436977, ups=1.67, wpb=262144, bsz=512, num_updates=35600, lr=0.001676, gnorm=0.489, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22268
2024-05-25 05:29:53 | INFO | train_inner | epoch 006:   1894 / 6735 loss=4.825, ppl=28.34, wps=436495, ups=1.67, wpb=262144, bsz=512, num_updates=35700, lr=0.00167365, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22329
2024-05-25 05:30:54 | INFO | train_inner | epoch 006:   1994 / 6735 loss=4.816, ppl=28.16, wps=436456, ups=1.66, wpb=262144, bsz=512, num_updates=35800, lr=0.00167132, gnorm=0.432, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22389
2024-05-25 05:31:54 | INFO | train_inner | epoch 006:   2094 / 6735 loss=4.82, ppl=28.26, wps=436760, ups=1.67, wpb=262144, bsz=512, num_updates=35900, lr=0.00166899, gnorm=0.479, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22449
2024-05-25 05:32:54 | INFO | train_inner | epoch 006:   2194 / 6735 loss=4.826, ppl=28.36, wps=436455, ups=1.66, wpb=262144, bsz=512, num_updates=36000, lr=0.00166667, gnorm=0.481, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22509
2024-05-25 05:33:54 | INFO | train_inner | epoch 006:   2294 / 6735 loss=4.819, ppl=28.22, wps=436833, ups=1.67, wpb=262144, bsz=512, num_updates=36100, lr=0.00166436, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22569
2024-05-25 05:34:54 | INFO | train_inner | epoch 006:   2394 / 6735 loss=4.82, ppl=28.24, wps=436954, ups=1.67, wpb=262144, bsz=512, num_updates=36200, lr=0.00166206, gnorm=0.491, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22629
2024-05-25 05:35:54 | INFO | train_inner | epoch 006:   2494 / 6735 loss=4.816, ppl=28.16, wps=437009, ups=1.67, wpb=262144, bsz=512, num_updates=36300, lr=0.00165977, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22689
2024-05-25 05:36:54 | INFO | train_inner | epoch 006:   2594 / 6735 loss=4.819, ppl=28.24, wps=436502, ups=1.67, wpb=262144, bsz=512, num_updates=36400, lr=0.00165748, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22749
2024-05-25 05:37:54 | INFO | train_inner | epoch 006:   2694 / 6735 loss=4.816, ppl=28.17, wps=436866, ups=1.67, wpb=262144, bsz=512, num_updates=36500, lr=0.00165521, gnorm=0.443, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22809
2024-05-25 05:38:54 | INFO | train_inner | epoch 006:   2794 / 6735 loss=4.817, ppl=28.19, wps=436202, ups=1.66, wpb=262144, bsz=512, num_updates=36600, lr=0.00165295, gnorm=0.482, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22869
2024-05-25 05:39:54 | INFO | train_inner | epoch 006:   2894 / 6735 loss=4.821, ppl=28.26, wps=436869, ups=1.67, wpb=262144, bsz=512, num_updates=36700, lr=0.0016507, gnorm=0.454, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22929
2024-05-25 05:40:54 | INFO | train_inner | epoch 006:   2994 / 6735 loss=4.818, ppl=28.2, wps=436376, ups=1.66, wpb=262144, bsz=512, num_updates=36800, lr=0.00164845, gnorm=0.473, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=22989
2024-05-25 05:41:54 | INFO | train_inner | epoch 006:   3094 / 6735 loss=4.817, ppl=28.18, wps=436456, ups=1.66, wpb=262144, bsz=512, num_updates=36900, lr=0.00164622, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23049
2024-05-25 05:42:54 | INFO | train_inner | epoch 006:   3194 / 6735 loss=4.816, ppl=28.16, wps=436838, ups=1.67, wpb=262144, bsz=512, num_updates=37000, lr=0.00164399, gnorm=0.474, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23109
2024-05-25 05:43:54 | INFO | train_inner | epoch 006:   3294 / 6735 loss=4.819, ppl=28.23, wps=436871, ups=1.67, wpb=262144, bsz=512, num_updates=37100, lr=0.00164177, gnorm=0.467, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23169
2024-05-25 05:44:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-05-25 05:44:55 | INFO | train_inner | epoch 006:   3395 / 6735 loss=4.813, ppl=28.12, wps=432626, ups=1.65, wpb=262144, bsz=512, num_updates=37200, lr=0.00163956, gnorm=0.514, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23230
2024-05-25 05:45:55 | INFO | train_inner | epoch 006:   3495 / 6735 loss=4.814, ppl=28.13, wps=436884, ups=1.67, wpb=262144, bsz=512, num_updates=37300, lr=0.00163737, gnorm=0.436, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23290
2024-05-25 05:46:55 | INFO | train_inner | epoch 006:   3595 / 6735 loss=4.814, ppl=28.12, wps=436769, ups=1.67, wpb=262144, bsz=512, num_updates=37400, lr=0.00163517, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23350
2024-05-25 05:47:55 | INFO | train_inner | epoch 006:   3695 / 6735 loss=4.813, ppl=28.11, wps=437048, ups=1.67, wpb=262144, bsz=512, num_updates=37500, lr=0.00163299, gnorm=0.464, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23410
2024-05-25 05:48:55 | INFO | train_inner | epoch 006:   3795 / 6735 loss=4.821, ppl=28.27, wps=436864, ups=1.67, wpb=262144, bsz=512, num_updates=37600, lr=0.00163082, gnorm=0.463, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23470
2024-05-25 05:49:55 | INFO | train_inner | epoch 006:   3895 / 6735 loss=4.812, ppl=28.09, wps=436541, ups=1.67, wpb=262144, bsz=512, num_updates=37700, lr=0.00162866, gnorm=0.442, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23530
2024-05-25 05:50:55 | INFO | train_inner | epoch 006:   3995 / 6735 loss=4.814, ppl=28.13, wps=437100, ups=1.67, wpb=262144, bsz=512, num_updates=37800, lr=0.0016265, gnorm=0.441, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23590
2024-05-25 05:51:55 | INFO | train_inner | epoch 006:   4095 / 6735 loss=4.811, ppl=28.06, wps=436742, ups=1.67, wpb=262144, bsz=512, num_updates=37900, lr=0.00162435, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23650
2024-05-25 05:52:55 | INFO | train_inner | epoch 006:   4195 / 6735 loss=4.815, ppl=28.14, wps=436926, ups=1.67, wpb=262144, bsz=512, num_updates=38000, lr=0.00162221, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23710
2024-05-25 05:53:55 | INFO | train_inner | epoch 006:   4295 / 6735 loss=4.819, ppl=28.22, wps=436930, ups=1.67, wpb=262144, bsz=512, num_updates=38100, lr=0.00162008, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23770
2024-05-25 05:54:55 | INFO | train_inner | epoch 006:   4395 / 6735 loss=4.816, ppl=28.18, wps=437250, ups=1.67, wpb=262140, bsz=512, num_updates=38200, lr=0.00161796, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23830
2024-05-25 05:55:55 | INFO | train_inner | epoch 006:   4495 / 6735 loss=4.817, ppl=28.18, wps=436944, ups=1.67, wpb=262144, bsz=512, num_updates=38300, lr=0.00161585, gnorm=0.455, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23890
2024-05-25 05:56:55 | INFO | train_inner | epoch 006:   4595 / 6735 loss=4.814, ppl=28.12, wps=436862, ups=1.67, wpb=262144, bsz=512, num_updates=38400, lr=0.00161374, gnorm=0.467, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=23950
2024-05-25 05:57:55 | INFO | train_inner | epoch 006:   4695 / 6735 loss=4.815, ppl=28.15, wps=436584, ups=1.67, wpb=262144, bsz=512, num_updates=38500, lr=0.00161165, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24010
2024-05-25 05:58:55 | INFO | train_inner | epoch 006:   4795 / 6735 loss=4.814, ppl=28.13, wps=436850, ups=1.67, wpb=262144, bsz=512, num_updates=38600, lr=0.00160956, gnorm=0.496, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24070
2024-05-25 05:59:55 | INFO | train_inner | epoch 006:   4895 / 6735 loss=4.808, ppl=28.02, wps=436549, ups=1.67, wpb=262144, bsz=512, num_updates=38700, lr=0.00160748, gnorm=0.457, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24130
2024-05-25 06:00:55 | INFO | train_inner | epoch 006:   4995 / 6735 loss=4.815, ppl=28.15, wps=436768, ups=1.67, wpb=262144, bsz=512, num_updates=38800, lr=0.0016054, gnorm=0.44, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24190
2024-05-25 06:01:55 | INFO | train_inner | epoch 006:   5095 / 6735 loss=4.813, ppl=28.1, wps=436731, ups=1.67, wpb=262144, bsz=512, num_updates=38900, lr=0.00160334, gnorm=0.481, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24250
2024-05-25 06:02:55 | INFO | train_inner | epoch 006:   5195 / 6735 loss=4.812, ppl=28.09, wps=436890, ups=1.67, wpb=262144, bsz=512, num_updates=39000, lr=0.00160128, gnorm=0.439, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24310
2024-05-25 06:03:55 | INFO | train_inner | epoch 006:   5295 / 6735 loss=4.806, ppl=27.97, wps=436386, ups=1.66, wpb=262144, bsz=512, num_updates=39100, lr=0.00159923, gnorm=0.445, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24370
2024-05-25 06:04:55 | INFO | train_inner | epoch 006:   5395 / 6735 loss=4.814, ppl=28.13, wps=436699, ups=1.67, wpb=262144, bsz=512, num_updates=39200, lr=0.00159719, gnorm=0.509, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24430
2024-05-25 06:05:55 | INFO | train_inner | epoch 006:   5495 / 6735 loss=4.817, ppl=28.19, wps=436864, ups=1.67, wpb=262144, bsz=512, num_updates=39300, lr=0.00159516, gnorm=0.485, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24490
2024-05-25 06:06:55 | INFO | train_inner | epoch 006:   5595 / 6735 loss=4.809, ppl=28.04, wps=436996, ups=1.67, wpb=262144, bsz=512, num_updates=39400, lr=0.00159313, gnorm=0.446, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24550
2024-05-25 06:07:55 | INFO | train_inner | epoch 006:   5695 / 6735 loss=4.809, ppl=28.03, wps=436545, ups=1.67, wpb=262144, bsz=512, num_updates=39500, lr=0.00159111, gnorm=0.46, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24610
2024-05-25 06:08:55 | INFO | train_inner | epoch 006:   5795 / 6735 loss=4.812, ppl=28.08, wps=436928, ups=1.67, wpb=262144, bsz=512, num_updates=39600, lr=0.0015891, gnorm=0.472, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24670
2024-05-25 06:09:55 | INFO | train_inner | epoch 006:   5895 / 6735 loss=4.811, ppl=28.08, wps=437121, ups=1.67, wpb=262144, bsz=512, num_updates=39700, lr=0.0015871, gnorm=0.431, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24730
2024-05-25 06:10:55 | INFO | train_inner | epoch 006:   5995 / 6735 loss=4.813, ppl=28.12, wps=436123, ups=1.67, wpb=261571, bsz=510.9, num_updates=39800, lr=0.00158511, gnorm=0.465, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24790
2024-05-25 06:11:55 | INFO | train_inner | epoch 006:   6095 / 6735 loss=4.808, ppl=28, wps=436652, ups=1.67, wpb=262144, bsz=512, num_updates=39900, lr=0.00158312, gnorm=0.487, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24850
2024-05-25 06:12:55 | INFO | train_inner | epoch 006:   6195 / 6735 loss=4.803, ppl=27.91, wps=436850, ups=1.67, wpb=262144, bsz=512, num_updates=40000, lr=0.00158114, gnorm=0.467, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=24910
2024-05-25 06:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40000 updates
2024-05-25 06:12:55 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_40000.pt
2024-05-25 06:13:10 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_40000.pt
2024-05-25 06:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_6_40000.pt (epoch 6 @ 40000 updates, score None) (writing took 43.54121084138751 seconds)
2024-05-25 06:14:38 | INFO | train_inner | epoch 006:   6295 / 6735 loss=4.807, ppl=28, wps=253374, ups=0.97, wpb=262144, bsz=512, num_updates=40100, lr=0.00157917, gnorm=0.487, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25013
2024-05-25 06:15:38 | INFO | train_inner | epoch 006:   6395 / 6735 loss=4.809, ppl=28.03, wps=436852, ups=1.67, wpb=262144, bsz=512, num_updates=40200, lr=0.0015772, gnorm=0.472, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25073
2024-05-25 06:16:38 | INFO | train_inner | epoch 006:   6495 / 6735 loss=4.811, ppl=28.06, wps=436625, ups=1.67, wpb=262144, bsz=512, num_updates=40300, lr=0.00157524, gnorm=0.472, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25133
2024-05-25 06:17:38 | INFO | train_inner | epoch 006:   6595 / 6735 loss=4.805, ppl=27.96, wps=436503, ups=1.67, wpb=262144, bsz=512, num_updates=40400, lr=0.00157329, gnorm=0.47, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25193
2024-05-25 06:18:38 | INFO | train_inner | epoch 006:   6695 / 6735 loss=4.803, ppl=27.92, wps=437020, ups=1.67, wpb=262144, bsz=512, num_updates=40500, lr=0.00157135, gnorm=0.483, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25253
2024-05-25 06:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 40540 updates
2024-05-25 06:19:02 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint6.pt
2024-05-25 06:19:18 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint6.pt
2024-05-25 06:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint6.pt (epoch 6 @ 40540 updates, score None) (writing took 44.20236187428236 seconds)
2024-05-25 06:19:47 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-05-25 06:19:47 | INFO | train | epoch 006 | loss 4.816 | ppl 28.18 | wps 422662 | ups 1.61 | wpb 262116 | bsz 511.9 | num_updates 40540 | lr 0.00157057 | gnorm 0.463 | clip 0 | loss_scale 4 | train_wall 4027 | gb_free 12.6 | wall 25322
2024-05-25 06:19:47 | INFO | fairseq.trainer | loading train data for epoch 7
2024-05-25 06:19:47 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-05-25 06:19:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-05-25 06:19:51 | INFO | fairseq.trainer | begin training epoch 7
2024-05-25 06:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2024-05-25 06:20:27 | INFO | train_inner | epoch 007:     60 / 6796 loss=4.809, ppl=28.03, wps=241707, ups=0.92, wpb=261489, bsz=510.7, num_updates=40600, lr=0.00156941, gnorm=0.48, clip=0, loss_scale=4, train_wall=60, gb_free=12.6, wall=25362
2024-05-25 06:20:27 | INFO | fairseq_cli.train | Stopping training due to num_updates: 40600 >= max_update: 40600
2024-05-25 06:20:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 40600 updates
2024-05-25 06:20:27 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_last.pt
2024-05-25 06:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_last.pt
2024-05-25 06:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_nr/checkpoint_last.pt (epoch 7 @ 40600 updates, score None) (writing took 15.534581266343594 seconds)
2024-05-25 06:20:42 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-05-25 06:20:42 | INFO | train | epoch 007 | loss 4.809 | ppl 28.03 | wps 283239 | ups 1.08 | wpb 262144 | bsz 512 | num_updates 40600 | lr 0.00156941 | gnorm 0.471 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 12.6 | wall 25377
2024-05-25 06:20:42 | INFO | fairseq_cli.train | done training in 25256.2 seconds
Amaitu da
