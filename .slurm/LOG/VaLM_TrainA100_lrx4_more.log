Hasi da
2024-03-26 15:32:48 | INFO | fairseq.distributed.utils | setting CUDA device=3 on rank 3
2024-03-26 15:32:48 | INFO | fairseq.distributed.utils | setting CUDA device=2 on rank 2
2024-03-26 15:32:48 | INFO | fairseq.distributed.utils | setting CUDA device=1 on rank 1
2024-03-26 15:32:48 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-03-26 15:32:48 | INFO | fairseq.distributed.utils | initialized host durunda as rank 0
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | initialized host durunda as rank 3
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | initialized host durunda as rank 1
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-03-26 15:32:49 | INFO | fairseq.distributed.utils | initialized host durunda as rank 2
NCCL version 2.18.1+cuda12.1
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5:./data/data-bin/6:./data/data-bin/7:./data/data-bin/8:./data/data-bin/9:./data/data-bin/10:./data/data-bin/11:./data/data-bin/12:./data/data-bin/13:./data/data-bin/14', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-03-26 15:32:58 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'VaLM-baseline', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 65536, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 65536, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 88255, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more', 'restore_file': './CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 12, 'decoder_attention_heads': 12, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False, 'use_knn_datastore': True, 'load_knn_datastore': False, 'dstore_fp16': False, 'use_gpu_to_search': False, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 8, 'probe': 32, 'dstore_filename': 'data/datastore', 'use_joint_attention': True, 'joint_layer_index': 2}, 'task': {'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5:./data/data-bin/6:./data/data-bin/7:./data/data-bin/8:./data/data-bin/9:./data/data-bin/10:./data/data-bin/11:./data/data-bin/12:./data/data-bin/13:./data/data-bin/14', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5:./data/data-bin/6:./data/data-bin/7:./data/data-bin/8:./data/data-bin/9:./data/data-bin/10:./data/data-bin/11:./data/data-bin/12:./data/data-bin/13:./data/data-bin/14', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5:./data/data-bin/6:./data/data-bin/7:./data/data-bin/8:./data/data-bin/9:./data/data-bin/10:./data/data-bin/11:./data/data-bin/12:./data/data-bin/13:./data/data-bin/14', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5:./data/data-bin/6:./data/data-bin/7:./data/data-bin/8:./data/data-bin/9:./data/data-bin/10:./data/data-bin/11:./data/data-bin/12:./data/data-bin/13:./data/data-bin/14', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-03-26 15:32:59 | INFO | fairseq.tasks.language_modeling | dictionary: 49412 types
2024-03-26 15:33:03 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(49412, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-9): 10 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerwithJointAttention(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_k_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_v_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=49412, bias=False)
  )
)
2024-03-26 15:33:03 | INFO | fairseq_cli.train | task: LanguageModelingTask
2024-03-26 15:33:03 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2024-03-26 15:33:03 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2024-03-26 15:33:03 | INFO | fairseq_cli.train | num. shared model params: 124,187,136 (num. trained: 124,187,136)
2024-03-26 15:33:03 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-03-26 15:33:03 | INFO | fairseq.data.data_utils | loaded 5,000 examples from: ./data/data-bin/0/valid
2024-03-26 15:33:03 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-03-26 15:33:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-03-26 15:33:11 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-03-26 15:33:11 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-03-26 15:33:11 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-03-26 15:33:11 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.325 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-03-26 15:33:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-03-26 15:33:11 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2024-03-26 15:33:11 | INFO | fairseq_cli.train | max tokens per device = 65536 and max sentences per device = None
2024-03-26 15:33:12 | INFO | fairseq.trainer | Preparing to load checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4/checkpoint_last.pt
2024-03-26 15:33:13 | INFO | fairseq.trainer | Loaded checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4/checkpoint_last.pt (epoch 7 @ 40600 updates)
2024-03-26 15:33:13 | INFO | fairseq.trainer | loading train data for epoch 7
2024-03-26 15:33:14 | INFO | fairseq.data.data_utils | loaded 52,626,000 examples from: ./data/data-bin/6/train
2024-03-26 15:33:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6759
2024-03-26 15:33:38 | INFO | fairseq.trainer | begin training epoch 7
2024-03-26 15:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-26 15:54:29 | INFO | train_inner | epoch 007:    159 / 6759 loss=4.805, ppl=27.96, wps=20531.8, ups=0.08, wpb=262144, bsz=512, num_updates=40700, lr=0.000626993, gnorm=0.35, clip=0, loss_scale=8, train_wall=1251, gb_free=10.7, wall=0
2024-03-26 16:15:02 | INFO | train_inner | epoch 007:    259 / 6759 loss=4.804, ppl=27.93, wps=21259.5, ups=0.08, wpb=262144, bsz=512, num_updates=40800, lr=0.000626224, gnorm=0.336, clip=0, loss_scale=8, train_wall=1233, gb_free=10.7, wall=0
2024-03-26 16:35:15 | INFO | train_inner | epoch 007:    359 / 6759 loss=4.803, ppl=27.92, wps=21626.1, ups=0.08, wpb=262144, bsz=512, num_updates=40900, lr=0.000625458, gnorm=0.332, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-26 16:55:14 | INFO | train_inner | epoch 007:    459 / 6759 loss=4.806, ppl=27.97, wps=21849.4, ups=0.08, wpb=262144, bsz=512, num_updates=41000, lr=0.000624695, gnorm=0.342, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 17:15:31 | INFO | train_inner | epoch 007:    559 / 6759 loss=4.802, ppl=27.9, wps=21542.5, ups=0.08, wpb=262144, bsz=512, num_updates=41100, lr=0.000623935, gnorm=0.338, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-26 17:35:53 | INFO | train_inner | epoch 007:    659 / 6759 loss=4.802, ppl=27.89, wps=21451.5, ups=0.08, wpb=262144, bsz=512, num_updates=41200, lr=0.000623177, gnorm=0.332, clip=0, loss_scale=8, train_wall=1222, gb_free=10.7, wall=0
2024-03-26 17:56:03 | INFO | train_inner | epoch 007:    759 / 6759 loss=4.804, ppl=27.93, wps=21666.5, ups=0.08, wpb=262144, bsz=512, num_updates=41300, lr=0.000622422, gnorm=0.35, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-26 18:16:15 | INFO | train_inner | epoch 007:    859 / 6759 loss=4.799, ppl=27.83, wps=21622.5, ups=0.08, wpb=262144, bsz=512, num_updates=41400, lr=0.00062167, gnorm=0.326, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-26 18:36:29 | INFO | train_inner | epoch 007:    959 / 6759 loss=4.805, ppl=27.96, wps=21608.2, ups=0.08, wpb=262144, bsz=512, num_updates=41500, lr=0.00062092, gnorm=0.329, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-26 18:56:24 | INFO | train_inner | epoch 007:   1059 / 6759 loss=4.8, ppl=27.86, wps=21933.6, ups=0.08, wpb=262144, bsz=512, num_updates=41600, lr=0.000620174, gnorm=0.338, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-26 19:16:22 | INFO | train_inner | epoch 007:   1159 / 6759 loss=4.797, ppl=27.8, wps=21884, ups=0.08, wpb=262144, bsz=512, num_updates=41700, lr=0.00061943, gnorm=0.34, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-26 19:36:22 | INFO | train_inner | epoch 007:   1259 / 6759 loss=4.796, ppl=27.78, wps=21837.6, ups=0.08, wpb=262144, bsz=512, num_updates=41800, lr=0.000618688, gnorm=0.353, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 19:56:24 | INFO | train_inner | epoch 007:   1359 / 6759 loss=4.799, ppl=27.84, wps=21753.2, ups=0.08, wpb=261494, bsz=510.7, num_updates=41900, lr=0.000617949, gnorm=0.334, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-26 20:16:25 | INFO | train_inner | epoch 007:   1459 / 6759 loss=4.799, ppl=27.84, wps=21833.1, ups=0.08, wpb=262144, bsz=512, num_updates=42000, lr=0.000617213, gnorm=0.34, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 20:36:25 | INFO | train_inner | epoch 007:   1559 / 6759 loss=4.797, ppl=27.8, wps=21839.2, ups=0.08, wpb=262144, bsz=512, num_updates=42100, lr=0.00061648, gnorm=0.339, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 20:56:24 | INFO | train_inner | epoch 007:   1659 / 6759 loss=4.801, ppl=27.87, wps=21869.7, ups=0.08, wpb=262144, bsz=512, num_updates=42200, lr=0.000615749, gnorm=0.332, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-26 21:16:25 | INFO | train_inner | epoch 007:   1759 / 6759 loss=4.8, ppl=27.85, wps=21823.6, ups=0.08, wpb=262144, bsz=512, num_updates=42300, lr=0.000615021, gnorm=0.337, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-26 21:36:26 | INFO | train_inner | epoch 007:   1859 / 6759 loss=4.793, ppl=27.71, wps=21835, ups=0.08, wpb=262144, bsz=512, num_updates=42400, lr=0.000614295, gnorm=0.345, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 21:56:26 | INFO | train_inner | epoch 007:   1959 / 6759 loss=4.8, ppl=27.86, wps=21844.3, ups=0.08, wpb=262144, bsz=512, num_updates=42500, lr=0.000613572, gnorm=0.338, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-26 22:16:22 | INFO | train_inner | epoch 007:   2059 / 6759 loss=4.799, ppl=27.83, wps=21918.2, ups=0.08, wpb=262144, bsz=512, num_updates=42600, lr=0.000612851, gnorm=0.338, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-26 22:36:20 | INFO | train_inner | epoch 007:   2159 / 6759 loss=4.795, ppl=27.76, wps=21882.2, ups=0.08, wpb=262139, bsz=512, num_updates=42700, lr=0.000612133, gnorm=0.348, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-26 22:56:32 | INFO | train_inner | epoch 007:   2259 / 6759 loss=4.794, ppl=27.75, wps=21621.5, ups=0.08, wpb=262144, bsz=512, num_updates=42800, lr=0.000611418, gnorm=0.332, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-26 23:16:35 | INFO | train_inner | epoch 007:   2359 / 6759 loss=4.8, ppl=27.86, wps=21795.9, ups=0.08, wpb=262144, bsz=512, num_updates=42900, lr=0.000610705, gnorm=0.34, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-26 23:36:46 | INFO | train_inner | epoch 007:   2459 / 6759 loss=4.798, ppl=27.83, wps=21646.9, ups=0.08, wpb=262144, bsz=512, num_updates=43000, lr=0.000609994, gnorm=0.324, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-26 23:56:40 | INFO | train_inner | epoch 007:   2559 / 6759 loss=4.798, ppl=27.82, wps=21949.7, ups=0.08, wpb=262144, bsz=512, num_updates=43100, lr=0.000609286, gnorm=0.347, clip=0, loss_scale=8, train_wall=1194, gb_free=10.7, wall=0
2024-03-27 00:16:41 | INFO | train_inner | epoch 007:   2659 / 6759 loss=4.797, ppl=27.8, wps=21829.7, ups=0.08, wpb=262144, bsz=512, num_updates=43200, lr=0.000608581, gnorm=0.338, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-27 00:36:45 | INFO | train_inner | epoch 007:   2759 / 6759 loss=4.792, ppl=27.71, wps=21768.6, ups=0.08, wpb=262144, bsz=512, num_updates=43300, lr=0.000607877, gnorm=0.352, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-27 00:56:54 | INFO | train_inner | epoch 007:   2859 / 6759 loss=4.798, ppl=27.83, wps=21686.7, ups=0.08, wpb=262144, bsz=512, num_updates=43400, lr=0.000607177, gnorm=0.341, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-27 01:17:05 | INFO | train_inner | epoch 007:   2959 / 6759 loss=4.798, ppl=27.82, wps=21644.9, ups=0.08, wpb=262144, bsz=512, num_updates=43500, lr=0.000606478, gnorm=0.339, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-27 01:37:15 | INFO | train_inner | epoch 007:   3059 / 6759 loss=4.792, ppl=27.7, wps=21666.3, ups=0.08, wpb=262144, bsz=512, num_updates=43600, lr=0.000605783, gnorm=0.341, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-27 01:57:21 | INFO | train_inner | epoch 007:   3159 / 6759 loss=4.798, ppl=27.81, wps=21730, ups=0.08, wpb=262144, bsz=512, num_updates=43700, lr=0.000605089, gnorm=0.338, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-27 02:17:06 | INFO | train_inner | epoch 007:   3259 / 6759 loss=4.799, ppl=27.84, wps=22121.4, ups=0.08, wpb=262144, bsz=512, num_updates=43800, lr=0.000604398, gnorm=0.342, clip=0, loss_scale=8, train_wall=1185, gb_free=10.7, wall=0
2024-03-27 02:37:02 | INFO | train_inner | epoch 007:   3359 / 6759 loss=4.798, ppl=27.81, wps=21929.8, ups=0.08, wpb=262144, bsz=512, num_updates=43900, lr=0.000603709, gnorm=0.337, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-27 02:57:02 | INFO | train_inner | epoch 007:   3459 / 6759 loss=4.792, ppl=27.71, wps=21833.7, ups=0.08, wpb=262144, bsz=512, num_updates=44000, lr=0.000603023, gnorm=0.356, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-27 03:17:05 | INFO | train_inner | epoch 007:   3559 / 6759 loss=4.794, ppl=27.75, wps=21804.7, ups=0.08, wpb=262144, bsz=512, num_updates=44100, lr=0.000602339, gnorm=0.337, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-27 03:37:12 | INFO | train_inner | epoch 007:   3659 / 6759 loss=4.79, ppl=27.67, wps=21713.1, ups=0.08, wpb=262144, bsz=512, num_updates=44200, lr=0.000601657, gnorm=0.34, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-27 03:57:05 | INFO | train_inner | epoch 007:   3759 / 6759 loss=4.797, ppl=27.79, wps=21969.6, ups=0.08, wpb=262144, bsz=512, num_updates=44300, lr=0.000600977, gnorm=0.338, clip=0, loss_scale=8, train_wall=1193, gb_free=10.7, wall=0
2024-03-27 04:16:56 | INFO | train_inner | epoch 007:   3859 / 6759 loss=4.802, ppl=27.9, wps=22023.1, ups=0.08, wpb=262144, bsz=512, num_updates=44400, lr=0.0006003, gnorm=0.343, clip=0, loss_scale=8, train_wall=1190, gb_free=10.7, wall=0
2024-03-27 04:36:38 | INFO | train_inner | epoch 007:   3959 / 6759 loss=4.793, ppl=27.73, wps=22169.9, ups=0.08, wpb=262144, bsz=512, num_updates=44500, lr=0.000599625, gnorm=0.348, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-27 04:56:27 | INFO | train_inner | epoch 007:   4059 / 6759 loss=4.793, ppl=27.73, wps=22048.4, ups=0.08, wpb=262144, bsz=512, num_updates=44600, lr=0.000598953, gnorm=0.332, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-27 05:16:13 | INFO | train_inner | epoch 007:   4159 / 6759 loss=4.794, ppl=27.75, wps=22097.8, ups=0.08, wpb=262144, bsz=512, num_updates=44700, lr=0.000598282, gnorm=0.338, clip=0, loss_scale=16, train_wall=1186, gb_free=10.7, wall=0
2024-03-27 05:20:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-27 05:36:11 | INFO | train_inner | epoch 007:   4260 / 6759 loss=4.794, ppl=27.73, wps=21877.1, ups=0.08, wpb=262144, bsz=512, num_updates=44800, lr=0.000597614, gnorm=0.333, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-27 05:55:57 | INFO | train_inner | epoch 007:   4360 / 6759 loss=4.795, ppl=27.76, wps=22115.3, ups=0.08, wpb=262144, bsz=512, num_updates=44900, lr=0.000596948, gnorm=0.346, clip=0, loss_scale=8, train_wall=1185, gb_free=10.7, wall=0
2024-03-27 06:15:58 | INFO | train_inner | epoch 007:   4460 / 6759 loss=4.794, ppl=27.74, wps=21829.2, ups=0.08, wpb=262144, bsz=512, num_updates=45000, lr=0.000596285, gnorm=0.344, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-27 06:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 45000 updates
2024-03-27 06:15:58 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_7_45000.pt
2024-03-27 06:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_7_45000.pt
2024-03-27 06:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_7_45000.pt (epoch 7 @ 45000 updates, score None) (writing took 44.29014561697841 seconds)
2024-03-27 06:36:37 | INFO | train_inner | epoch 007:   4560 / 6759 loss=4.792, ppl=27.71, wps=21145.8, ups=0.08, wpb=262144, bsz=512, num_updates=45100, lr=0.000595623, gnorm=0.356, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-27 06:56:33 | INFO | train_inner | epoch 007:   4660 / 6759 loss=4.795, ppl=27.76, wps=21920.6, ups=0.08, wpb=262144, bsz=512, num_updates=45200, lr=0.000594964, gnorm=0.345, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-27 07:16:52 | INFO | train_inner | epoch 007:   4760 / 6759 loss=4.788, ppl=27.63, wps=21506.1, ups=0.08, wpb=262144, bsz=512, num_updates=45300, lr=0.000594307, gnorm=0.339, clip=0, loss_scale=8, train_wall=1219, gb_free=10.7, wall=0
2024-03-27 07:37:17 | INFO | train_inner | epoch 007:   4860 / 6759 loss=4.792, ppl=27.71, wps=21395.6, ups=0.08, wpb=262144, bsz=512, num_updates=45400, lr=0.000593652, gnorm=0.341, clip=0, loss_scale=8, train_wall=1225, gb_free=10.7, wall=0
2024-03-27 07:57:34 | INFO | train_inner | epoch 007:   4960 / 6759 loss=4.79, ppl=27.66, wps=21543.2, ups=0.08, wpb=262144, bsz=512, num_updates=45500, lr=0.000592999, gnorm=0.359, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-27 08:17:52 | INFO | train_inner | epoch 007:   5060 / 6759 loss=4.796, ppl=27.77, wps=21530.4, ups=0.08, wpb=262144, bsz=512, num_updates=45600, lr=0.000592349, gnorm=0.348, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-27 08:38:01 | INFO | train_inner | epoch 007:   5160 / 6759 loss=4.791, ppl=27.68, wps=21674.9, ups=0.08, wpb=262144, bsz=512, num_updates=45700, lr=0.0005917, gnorm=0.342, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-27 08:58:12 | INFO | train_inner | epoch 007:   5260 / 6759 loss=4.794, ppl=27.75, wps=21659.2, ups=0.08, wpb=262144, bsz=512, num_updates=45800, lr=0.000591054, gnorm=0.346, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-27 09:18:36 | INFO | train_inner | epoch 007:   5360 / 6759 loss=4.79, ppl=27.67, wps=21417.4, ups=0.08, wpb=262144, bsz=512, num_updates=45900, lr=0.00059041, gnorm=0.339, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-27 09:38:47 | INFO | train_inner | epoch 007:   5460 / 6759 loss=4.789, ppl=27.64, wps=21636.6, ups=0.08, wpb=262144, bsz=512, num_updates=46000, lr=0.000589768, gnorm=0.343, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-27 09:58:19 | INFO | train_inner | epoch 007:   5560 / 6759 loss=4.792, ppl=27.7, wps=22376.5, ups=0.09, wpb=262144, bsz=512, num_updates=46100, lr=0.000589128, gnorm=0.344, clip=0, loss_scale=8, train_wall=1171, gb_free=10.7, wall=0
2024-03-27 10:18:36 | INFO | train_inner | epoch 007:   5660 / 6759 loss=4.791, ppl=27.69, wps=21541.5, ups=0.08, wpb=262144, bsz=512, num_updates=46200, lr=0.00058849, gnorm=0.347, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-27 10:39:09 | INFO | train_inner | epoch 007:   5760 / 6759 loss=4.791, ppl=27.69, wps=21251.4, ups=0.08, wpb=262144, bsz=512, num_updates=46300, lr=0.000587854, gnorm=0.343, clip=0, loss_scale=8, train_wall=1233, gb_free=10.7, wall=0
2024-03-27 10:59:12 | INFO | train_inner | epoch 007:   5860 / 6759 loss=4.791, ppl=27.68, wps=21789.9, ups=0.08, wpb=262144, bsz=512, num_updates=46400, lr=0.00058722, gnorm=0.343, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-27 11:19:55 | INFO | train_inner | epoch 007:   5960 / 6759 loss=4.794, ppl=27.75, wps=21092.3, ups=0.08, wpb=262144, bsz=512, num_updates=46500, lr=0.000586588, gnorm=0.346, clip=0, loss_scale=8, train_wall=1243, gb_free=10.7, wall=0
2024-03-27 11:40:09 | INFO | train_inner | epoch 007:   6060 / 6759 loss=4.79, ppl=27.66, wps=21590.3, ups=0.08, wpb=262144, bsz=512, num_updates=46600, lr=0.000585959, gnorm=0.341, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-27 12:00:47 | INFO | train_inner | epoch 007:   6160 / 6759 loss=4.788, ppl=27.62, wps=21175, ups=0.08, wpb=262144, bsz=512, num_updates=46700, lr=0.000585331, gnorm=0.347, clip=0, loss_scale=8, train_wall=1238, gb_free=10.7, wall=0
2024-03-27 12:21:14 | INFO | train_inner | epoch 007:   6260 / 6759 loss=4.787, ppl=27.6, wps=21364.4, ups=0.08, wpb=262144, bsz=512, num_updates=46800, lr=0.000584705, gnorm=0.351, clip=0, loss_scale=8, train_wall=1227, gb_free=10.7, wall=0
2024-03-27 12:41:17 | INFO | train_inner | epoch 007:   6360 / 6759 loss=4.788, ppl=27.63, wps=21800.9, ups=0.08, wpb=262144, bsz=512, num_updates=46900, lr=0.000584082, gnorm=0.341, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-27 13:01:05 | INFO | train_inner | epoch 007:   6460 / 6759 loss=4.787, ppl=27.61, wps=22055.4, ups=0.08, wpb=262144, bsz=512, num_updates=47000, lr=0.00058346, gnorm=0.361, clip=0, loss_scale=8, train_wall=1188, gb_free=10.7, wall=0
2024-03-27 13:21:19 | INFO | train_inner | epoch 007:   6560 / 6759 loss=4.785, ppl=27.57, wps=21555.2, ups=0.08, wpb=261530, bsz=510.8, num_updates=47100, lr=0.00058284, gnorm=0.351, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-27 13:41:14 | INFO | train_inner | epoch 007:   6660 / 6759 loss=4.789, ppl=27.64, wps=21929, ups=0.08, wpb=262144, bsz=512, num_updates=47200, lr=0.000582223, gnorm=0.347, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-27 14:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 47299 updates
2024-03-27 14:01:00 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint7.pt
2024-03-27 14:01:16 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint7.pt
2024-03-27 14:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint7.pt (epoch 7 @ 47299 updates, score None) (writing took 69.99468732113019 seconds)
2024-03-27 14:02:10 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-03-27 14:02:10 | INFO | train | epoch 007 | loss 4.795 | ppl 27.77 | wps 21698.9 | ups 0.08 | wpb 262116 | bsz 511.9 | num_updates 47299 | lr 0.000581613 | gnorm 0.342 | clip 0 | loss_scale 8 | train_wall 81479 | gb_free 10.7 | wall 0
2024-03-27 14:02:10 | INFO | fairseq.trainer | loading train data for epoch 8
2024-03-27 14:02:12 | INFO | fairseq.data.data_utils | loaded 52,433,000 examples from: ./data/data-bin/7/train
2024-03-27 14:02:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6736
2024-03-27 14:02:13 | INFO | fairseq.trainer | begin training epoch 8
2024-03-27 14:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-27 14:02:24 | INFO | train_inner | epoch 008:      1 / 6736 loss=4.783, ppl=27.53, wps=20586.9, ups=0.08, wpb=261489, bsz=510.7, num_updates=47300, lr=0.000581607, gnorm=0.346, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-27 14:22:36 | INFO | train_inner | epoch 008:    101 / 6736 loss=4.789, ppl=27.64, wps=21634.2, ups=0.08, wpb=262144, bsz=512, num_updates=47400, lr=0.000580993, gnorm=0.349, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-27 14:43:00 | INFO | train_inner | epoch 008:    201 / 6736 loss=4.788, ppl=27.62, wps=21410.9, ups=0.08, wpb=262144, bsz=512, num_updates=47500, lr=0.000580381, gnorm=0.351, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-27 15:03:15 | INFO | train_inner | epoch 008:    301 / 6736 loss=4.785, ppl=27.58, wps=21573.4, ups=0.08, wpb=262144, bsz=512, num_updates=47600, lr=0.000579771, gnorm=0.33, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-27 15:23:39 | INFO | train_inner | epoch 008:    401 / 6736 loss=4.786, ppl=27.58, wps=21416.5, ups=0.08, wpb=262144, bsz=512, num_updates=47700, lr=0.000579163, gnorm=0.349, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-27 15:44:24 | INFO | train_inner | epoch 008:    501 / 6736 loss=4.788, ppl=27.63, wps=21059.9, ups=0.08, wpb=262144, bsz=512, num_updates=47800, lr=0.000578557, gnorm=0.349, clip=0, loss_scale=8, train_wall=1245, gb_free=10.7, wall=0
2024-03-27 16:05:16 | INFO | train_inner | epoch 008:    601 / 6736 loss=4.795, ppl=27.77, wps=20945.6, ups=0.08, wpb=262144, bsz=512, num_updates=47900, lr=0.000577953, gnorm=0.339, clip=0, loss_scale=8, train_wall=1251, gb_free=10.7, wall=0
2024-03-27 16:25:42 | INFO | train_inner | epoch 008:    701 / 6736 loss=4.784, ppl=27.55, wps=21372.8, ups=0.08, wpb=262144, bsz=512, num_updates=48000, lr=0.00057735, gnorm=0.345, clip=0, loss_scale=8, train_wall=1226, gb_free=10.7, wall=0
2024-03-27 16:45:59 | INFO | train_inner | epoch 008:    801 / 6736 loss=4.786, ppl=27.59, wps=21537.8, ups=0.08, wpb=262144, bsz=512, num_updates=48100, lr=0.00057675, gnorm=0.353, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-27 17:06:15 | INFO | train_inner | epoch 008:    901 / 6736 loss=4.786, ppl=27.58, wps=21572.1, ups=0.08, wpb=262144, bsz=512, num_updates=48200, lr=0.000576151, gnorm=0.356, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-27 17:26:28 | INFO | train_inner | epoch 008:   1001 / 6736 loss=4.789, ppl=27.65, wps=21606.5, ups=0.08, wpb=262144, bsz=512, num_updates=48300, lr=0.000575554, gnorm=0.343, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-27 17:46:34 | INFO | train_inner | epoch 008:   1101 / 6736 loss=4.787, ppl=27.61, wps=21730.7, ups=0.08, wpb=262144, bsz=512, num_updates=48400, lr=0.00057496, gnorm=0.356, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-27 18:06:42 | INFO | train_inner | epoch 008:   1201 / 6736 loss=4.787, ppl=27.6, wps=21702.7, ups=0.08, wpb=262144, bsz=512, num_updates=48500, lr=0.000574367, gnorm=0.345, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-27 18:26:50 | INFO | train_inner | epoch 008:   1301 / 6736 loss=4.788, ppl=27.63, wps=21694.5, ups=0.08, wpb=262144, bsz=512, num_updates=48600, lr=0.000573775, gnorm=0.344, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-27 18:46:55 | INFO | train_inner | epoch 008:   1401 / 6736 loss=4.786, ppl=27.58, wps=21760.3, ups=0.08, wpb=262144, bsz=512, num_updates=48700, lr=0.000573186, gnorm=0.342, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-27 19:06:59 | INFO | train_inner | epoch 008:   1501 / 6736 loss=4.787, ppl=27.61, wps=21776.2, ups=0.08, wpb=262144, bsz=512, num_updates=48800, lr=0.000572598, gnorm=0.355, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-27 19:18:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-27 19:27:23 | INFO | train_inner | epoch 008:   1602 / 6736 loss=4.79, ppl=27.66, wps=21407, ups=0.08, wpb=262144, bsz=512, num_updates=48900, lr=0.000572013, gnorm=0.34, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-27 19:47:38 | INFO | train_inner | epoch 008:   1702 / 6736 loss=4.785, ppl=27.56, wps=21577, ups=0.08, wpb=262144, bsz=512, num_updates=49000, lr=0.000571429, gnorm=0.359, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-27 20:07:53 | INFO | train_inner | epoch 008:   1802 / 6736 loss=4.786, ppl=27.58, wps=21581.2, ups=0.08, wpb=262144, bsz=512, num_updates=49100, lr=0.000570846, gnorm=0.356, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-27 20:28:10 | INFO | train_inner | epoch 008:   1902 / 6736 loss=4.785, ppl=27.57, wps=21540.8, ups=0.08, wpb=262144, bsz=512, num_updates=49200, lr=0.000570266, gnorm=0.356, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-27 20:48:31 | INFO | train_inner | epoch 008:   2002 / 6736 loss=4.786, ppl=27.59, wps=21464.4, ups=0.08, wpb=262144, bsz=512, num_updates=49300, lr=0.000569687, gnorm=0.342, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-27 21:08:40 | INFO | train_inner | epoch 008:   2102 / 6736 loss=4.786, ppl=27.58, wps=21681.5, ups=0.08, wpb=262144, bsz=512, num_updates=49400, lr=0.00056911, gnorm=0.354, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-27 21:28:49 | INFO | train_inner | epoch 008:   2202 / 6736 loss=4.778, ppl=27.43, wps=21693, ups=0.08, wpb=262144, bsz=512, num_updates=49500, lr=0.000568535, gnorm=0.355, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-27 21:49:01 | INFO | train_inner | epoch 008:   2302 / 6736 loss=4.783, ppl=27.54, wps=21625, ups=0.08, wpb=262144, bsz=512, num_updates=49600, lr=0.000567962, gnorm=0.354, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-27 22:09:10 | INFO | train_inner | epoch 008:   2402 / 6736 loss=4.786, ppl=27.59, wps=21687.5, ups=0.08, wpb=262144, bsz=512, num_updates=49700, lr=0.00056739, gnorm=0.34, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-27 22:29:25 | INFO | train_inner | epoch 008:   2502 / 6736 loss=4.781, ppl=27.49, wps=21566.5, ups=0.08, wpb=262144, bsz=512, num_updates=49800, lr=0.00056682, gnorm=0.355, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-27 22:49:35 | INFO | train_inner | epoch 008:   2602 / 6736 loss=4.786, ppl=27.59, wps=21676.4, ups=0.08, wpb=262144, bsz=512, num_updates=49900, lr=0.000566252, gnorm=0.334, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-27 23:09:47 | INFO | train_inner | epoch 008:   2702 / 6736 loss=4.784, ppl=27.54, wps=21621.6, ups=0.08, wpb=262144, bsz=512, num_updates=50000, lr=0.000565685, gnorm=0.351, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-27 23:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 50000 updates
2024-03-27 23:09:47 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_8_50000.pt
2024-03-27 23:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_8_50000.pt
2024-03-27 23:10:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_8_50000.pt (epoch 8 @ 50000 updates, score None) (writing took 44.640096032992005 seconds)
2024-03-27 23:30:39 | INFO | train_inner | epoch 008:   2802 / 6736 loss=4.784, ppl=27.55, wps=20935.7, ups=0.08, wpb=262144, bsz=512, num_updates=50100, lr=0.000565121, gnorm=0.343, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-27 23:50:51 | INFO | train_inner | epoch 008:   2902 / 6736 loss=4.782, ppl=27.5, wps=21640.3, ups=0.08, wpb=262144, bsz=512, num_updates=50200, lr=0.000564557, gnorm=0.337, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-28 00:10:58 | INFO | train_inner | epoch 008:   3002 / 6736 loss=4.777, ppl=27.41, wps=21707.3, ups=0.08, wpb=262144, bsz=512, num_updates=50300, lr=0.000563996, gnorm=0.338, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-28 00:31:05 | INFO | train_inner | epoch 008:   3102 / 6736 loss=4.778, ppl=27.44, wps=21714, ups=0.08, wpb=262144, bsz=512, num_updates=50400, lr=0.000563436, gnorm=0.345, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-28 00:51:18 | INFO | train_inner | epoch 008:   3202 / 6736 loss=4.781, ppl=27.5, wps=21627.3, ups=0.08, wpb=262144, bsz=512, num_updates=50500, lr=0.000562878, gnorm=0.343, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-28 01:11:24 | INFO | train_inner | epoch 008:   3302 / 6736 loss=4.784, ppl=27.56, wps=21676.1, ups=0.08, wpb=261514, bsz=510.8, num_updates=50600, lr=0.000562322, gnorm=0.343, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-28 01:31:26 | INFO | train_inner | epoch 008:   3402 / 6736 loss=4.782, ppl=27.51, wps=21810.4, ups=0.08, wpb=262144, bsz=512, num_updates=50700, lr=0.000561767, gnorm=0.356, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-28 01:51:22 | INFO | train_inner | epoch 008:   3502 / 6736 loss=4.781, ppl=27.49, wps=21911.1, ups=0.08, wpb=262144, bsz=512, num_updates=50800, lr=0.000561214, gnorm=0.348, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-28 02:11:24 | INFO | train_inner | epoch 008:   3602 / 6736 loss=4.785, ppl=27.58, wps=21820.1, ups=0.08, wpb=262144, bsz=512, num_updates=50900, lr=0.000560662, gnorm=0.342, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-28 02:31:37 | INFO | train_inner | epoch 008:   3702 / 6736 loss=4.774, ppl=27.36, wps=21609.3, ups=0.08, wpb=262144, bsz=512, num_updates=51000, lr=0.000560112, gnorm=0.358, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-28 02:51:48 | INFO | train_inner | epoch 008:   3802 / 6736 loss=4.784, ppl=27.54, wps=21643.5, ups=0.08, wpb=262144, bsz=512, num_updates=51100, lr=0.000559564, gnorm=0.336, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-28 03:12:07 | INFO | train_inner | epoch 008:   3902 / 6736 loss=4.78, ppl=27.47, wps=21503.1, ups=0.08, wpb=262144, bsz=512, num_updates=51200, lr=0.000559017, gnorm=0.347, clip=0, loss_scale=8, train_wall=1219, gb_free=10.7, wall=0
2024-03-28 03:32:30 | INFO | train_inner | epoch 008:   4002 / 6736 loss=4.785, ppl=27.57, wps=21431.9, ups=0.08, wpb=262144, bsz=512, num_updates=51300, lr=0.000558472, gnorm=0.352, clip=0, loss_scale=8, train_wall=1223, gb_free=10.7, wall=0
2024-03-28 03:52:54 | INFO | train_inner | epoch 008:   4102 / 6736 loss=4.774, ppl=27.35, wps=21427.5, ups=0.08, wpb=262144, bsz=512, num_updates=51400, lr=0.000557928, gnorm=0.351, clip=0, loss_scale=8, train_wall=1223, gb_free=10.7, wall=0
2024-03-28 04:13:08 | INFO | train_inner | epoch 008:   4202 / 6736 loss=4.781, ppl=27.49, wps=21586.7, ups=0.08, wpb=262144, bsz=512, num_updates=51500, lr=0.000557386, gnorm=0.347, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-28 04:33:29 | INFO | train_inner | epoch 008:   4302 / 6736 loss=4.78, ppl=27.48, wps=21463.9, ups=0.08, wpb=262139, bsz=512, num_updates=51600, lr=0.000556846, gnorm=0.345, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-28 04:53:42 | INFO | train_inner | epoch 008:   4402 / 6736 loss=4.779, ppl=27.45, wps=21619.5, ups=0.08, wpb=262144, bsz=512, num_updates=51700, lr=0.000556307, gnorm=0.366, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-28 05:13:46 | INFO | train_inner | epoch 008:   4502 / 6736 loss=4.776, ppl=27.4, wps=21772.7, ups=0.08, wpb=262144, bsz=512, num_updates=51800, lr=0.00055577, gnorm=0.347, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-28 05:33:48 | INFO | train_inner | epoch 008:   4602 / 6736 loss=4.779, ppl=27.45, wps=21803.4, ups=0.08, wpb=262144, bsz=512, num_updates=51900, lr=0.000555234, gnorm=0.34, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-28 05:54:08 | INFO | train_inner | epoch 008:   4702 / 6736 loss=4.776, ppl=27.4, wps=21495.3, ups=0.08, wpb=262144, bsz=512, num_updates=52000, lr=0.0005547, gnorm=0.35, clip=0, loss_scale=8, train_wall=1219, gb_free=10.7, wall=0
2024-03-28 06:14:20 | INFO | train_inner | epoch 008:   4802 / 6736 loss=4.777, ppl=27.42, wps=21621.9, ups=0.08, wpb=262144, bsz=512, num_updates=52100, lr=0.000554168, gnorm=0.369, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-28 06:34:27 | INFO | train_inner | epoch 008:   4902 / 6736 loss=4.777, ppl=27.41, wps=21730.4, ups=0.08, wpb=262144, bsz=512, num_updates=52200, lr=0.000553637, gnorm=0.354, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-28 06:54:41 | INFO | train_inner | epoch 008:   5002 / 6736 loss=4.781, ppl=27.49, wps=21581.4, ups=0.08, wpb=262144, bsz=512, num_updates=52300, lr=0.000553107, gnorm=0.343, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-28 07:15:00 | INFO | train_inner | epoch 008:   5102 / 6736 loss=4.779, ppl=27.46, wps=21507.5, ups=0.08, wpb=262144, bsz=512, num_updates=52400, lr=0.000552579, gnorm=0.348, clip=0, loss_scale=8, train_wall=1219, gb_free=10.7, wall=0
2024-03-28 07:35:13 | INFO | train_inner | epoch 008:   5202 / 6736 loss=4.775, ppl=27.38, wps=21615.3, ups=0.08, wpb=262144, bsz=512, num_updates=52500, lr=0.000552052, gnorm=0.347, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-28 07:55:27 | INFO | train_inner | epoch 008:   5302 / 6736 loss=4.78, ppl=27.47, wps=21585.5, ups=0.08, wpb=262144, bsz=512, num_updates=52600, lr=0.000551527, gnorm=0.35, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-28 08:15:30 | INFO | train_inner | epoch 008:   5402 / 6736 loss=4.779, ppl=27.46, wps=21795.8, ups=0.08, wpb=262144, bsz=512, num_updates=52700, lr=0.000551004, gnorm=0.373, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-28 08:35:27 | INFO | train_inner | epoch 008:   5502 / 6736 loss=4.777, ppl=27.42, wps=21904.6, ups=0.08, wpb=262144, bsz=512, num_updates=52800, lr=0.000550482, gnorm=0.356, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-28 08:55:18 | INFO | train_inner | epoch 008:   5602 / 6736 loss=4.774, ppl=27.36, wps=22001.4, ups=0.08, wpb=262144, bsz=512, num_updates=52900, lr=0.000549961, gnorm=0.356, clip=0, loss_scale=8, train_wall=1191, gb_free=10.7, wall=0
2024-03-28 09:15:27 | INFO | train_inner | epoch 008:   5702 / 6736 loss=4.776, ppl=27.4, wps=21691.3, ups=0.08, wpb=262144, bsz=512, num_updates=53000, lr=0.000549442, gnorm=0.345, clip=0, loss_scale=16, train_wall=1208, gb_free=10.7, wall=0
2024-03-28 09:16:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-28 09:36:06 | INFO | train_inner | epoch 008:   5803 / 6736 loss=4.778, ppl=27.43, wps=21159.3, ups=0.08, wpb=262144, bsz=512, num_updates=53100, lr=0.000548925, gnorm=0.351, clip=0, loss_scale=8, train_wall=1239, gb_free=10.7, wall=0
2024-03-28 09:56:35 | INFO | train_inner | epoch 008:   5903 / 6736 loss=4.779, ppl=27.45, wps=21319.9, ups=0.08, wpb=262144, bsz=512, num_updates=53200, lr=0.000548408, gnorm=0.357, clip=0, loss_scale=8, train_wall=1229, gb_free=10.7, wall=0
2024-03-28 10:16:57 | INFO | train_inner | epoch 008:   6003 / 6736 loss=4.778, ppl=27.44, wps=21456.3, ups=0.08, wpb=262144, bsz=512, num_updates=53300, lr=0.000547894, gnorm=0.358, clip=0, loss_scale=8, train_wall=1222, gb_free=10.7, wall=0
2024-03-28 10:37:25 | INFO | train_inner | epoch 008:   6103 / 6736 loss=4.779, ppl=27.45, wps=21326.4, ups=0.08, wpb=261980, bsz=511.7, num_updates=53400, lr=0.000547381, gnorm=0.361, clip=0, loss_scale=8, train_wall=1228, gb_free=10.7, wall=0
2024-03-28 10:57:47 | INFO | train_inner | epoch 008:   6203 / 6736 loss=4.78, ppl=27.47, wps=21464.4, ups=0.08, wpb=262144, bsz=512, num_updates=53500, lr=0.000546869, gnorm=0.367, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-28 11:18:07 | INFO | train_inner | epoch 008:   6303 / 6736 loss=4.777, ppl=27.43, wps=21476.6, ups=0.08, wpb=262144, bsz=512, num_updates=53600, lr=0.000546358, gnorm=0.362, clip=0, loss_scale=8, train_wall=1220, gb_free=10.7, wall=0
2024-03-28 11:38:11 | INFO | train_inner | epoch 008:   6403 / 6736 loss=4.776, ppl=27.39, wps=21780, ups=0.08, wpb=262144, bsz=512, num_updates=53700, lr=0.000545849, gnorm=0.356, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-28 11:58:02 | INFO | train_inner | epoch 008:   6503 / 6736 loss=4.778, ppl=27.44, wps=22018.3, ups=0.08, wpb=262144, bsz=512, num_updates=53800, lr=0.000545342, gnorm=0.352, clip=0, loss_scale=8, train_wall=1190, gb_free=10.7, wall=0
2024-03-28 12:17:53 | INFO | train_inner | epoch 008:   6603 / 6736 loss=4.777, ppl=27.42, wps=21993.8, ups=0.08, wpb=262144, bsz=512, num_updates=53900, lr=0.000544836, gnorm=0.353, clip=0, loss_scale=8, train_wall=1192, gb_free=10.7, wall=0
2024-03-28 12:37:57 | INFO | train_inner | epoch 008:   6703 / 6736 loss=4.776, ppl=27.4, wps=21780.8, ups=0.08, wpb=262144, bsz=512, num_updates=54000, lr=0.000544331, gnorm=0.349, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-28 12:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 54033 updates
2024-03-28 12:44:35 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint8.pt
2024-03-28 12:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint8.pt
2024-03-28 12:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint8.pt (epoch 8 @ 54033 updates, score None) (writing took 72.73651735531166 seconds)
2024-03-28 12:45:47 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-03-28 12:45:47 | INFO | train | epoch 008 | loss 4.782 | ppl 27.51 | wps 21573.3 | ups 0.08 | wpb 262113 | bsz 511.9 | num_updates 54033 | lr 0.000544165 | gnorm 0.35 | clip 0 | loss_scale 8 | train_wall 81684 | gb_free 10.7 | wall 0
2024-03-28 12:45:47 | INFO | fairseq.trainer | loading train data for epoch 9
2024-03-28 12:45:49 | INFO | fairseq.data.data_utils | loaded 52,805,000 examples from: ./data/data-bin/8/train
2024-03-28 12:45:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6788
2024-03-28 12:45:50 | INFO | fairseq.trainer | begin training epoch 9
2024-03-28 12:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-28 12:59:17 | INFO | train_inner | epoch 009:     67 / 6788 loss=4.774, ppl=27.36, wps=20376, ups=0.08, wpb=260833, bsz=509.4, num_updates=54100, lr=0.000543828, gnorm=0.357, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-28 13:19:22 | INFO | train_inner | epoch 009:    167 / 6788 loss=4.781, ppl=27.49, wps=21763.5, ups=0.08, wpb=262144, bsz=512, num_updates=54200, lr=0.000543326, gnorm=0.353, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-28 13:39:23 | INFO | train_inner | epoch 009:    267 / 6788 loss=4.786, ppl=27.58, wps=21821.8, ups=0.08, wpb=262144, bsz=512, num_updates=54300, lr=0.000542825, gnorm=0.348, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-28 13:59:31 | INFO | train_inner | epoch 009:    367 / 6788 loss=4.779, ppl=27.45, wps=21706.9, ups=0.08, wpb=262144, bsz=512, num_updates=54400, lr=0.000542326, gnorm=0.358, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-28 14:19:27 | INFO | train_inner | epoch 009:    467 / 6788 loss=4.78, ppl=27.47, wps=21907.4, ups=0.08, wpb=262144, bsz=512, num_updates=54500, lr=0.000541828, gnorm=0.361, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-28 14:39:28 | INFO | train_inner | epoch 009:    567 / 6788 loss=4.779, ppl=27.46, wps=21824.8, ups=0.08, wpb=262144, bsz=512, num_updates=54600, lr=0.000541332, gnorm=0.342, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-28 14:59:26 | INFO | train_inner | epoch 009:    667 / 6788 loss=4.778, ppl=27.44, wps=21885.3, ups=0.08, wpb=262144, bsz=512, num_updates=54700, lr=0.000540837, gnorm=0.349, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-28 15:19:36 | INFO | train_inner | epoch 009:    767 / 6788 loss=4.778, ppl=27.43, wps=21669.7, ups=0.08, wpb=262144, bsz=512, num_updates=54800, lr=0.000540343, gnorm=0.346, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-28 15:39:15 | INFO | train_inner | epoch 009:    867 / 6788 loss=4.779, ppl=27.45, wps=22230.4, ups=0.08, wpb=262144, bsz=512, num_updates=54900, lr=0.000539851, gnorm=0.357, clip=0, loss_scale=8, train_wall=1179, gb_free=10.7, wall=0
2024-03-28 15:58:58 | INFO | train_inner | epoch 009:    967 / 6788 loss=4.775, ppl=27.38, wps=22160.9, ups=0.08, wpb=262144, bsz=512, num_updates=55000, lr=0.00053936, gnorm=0.357, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-28 15:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 55000 updates
2024-03-28 15:58:58 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_55000.pt
2024-03-28 15:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_55000.pt
2024-03-28 15:59:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_55000.pt (epoch 9 @ 55000 updates, score None) (writing took 61.282295495737344 seconds)
2024-03-28 16:19:58 | INFO | train_inner | epoch 009:   1067 / 6788 loss=4.779, ppl=27.45, wps=20805.2, ups=0.08, wpb=262144, bsz=512, num_updates=55100, lr=0.00053887, gnorm=0.352, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-28 16:40:01 | INFO | train_inner | epoch 009:   1167 / 6788 loss=4.776, ppl=27.39, wps=21731.8, ups=0.08, wpb=261500, bsz=510.8, num_updates=55200, lr=0.000538382, gnorm=0.359, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-28 17:00:06 | INFO | train_inner | epoch 009:   1267 / 6788 loss=4.778, ppl=27.43, wps=21762.2, ups=0.08, wpb=262144, bsz=512, num_updates=55300, lr=0.000537895, gnorm=0.357, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-28 17:20:25 | INFO | train_inner | epoch 009:   1367 / 6788 loss=4.775, ppl=27.38, wps=21502.2, ups=0.08, wpb=262144, bsz=512, num_updates=55400, lr=0.000537409, gnorm=0.359, clip=0, loss_scale=8, train_wall=1219, gb_free=10.7, wall=0
2024-03-28 17:40:46 | INFO | train_inner | epoch 009:   1467 / 6788 loss=4.777, ppl=27.42, wps=21466.8, ups=0.08, wpb=262144, bsz=512, num_updates=55500, lr=0.000536925, gnorm=0.354, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-28 18:01:31 | INFO | train_inner | epoch 009:   1567 / 6788 loss=4.775, ppl=27.38, wps=21052.8, ups=0.08, wpb=262144, bsz=512, num_updates=55600, lr=0.000536442, gnorm=0.351, clip=0, loss_scale=8, train_wall=1245, gb_free=10.7, wall=0
2024-03-28 18:21:39 | INFO | train_inner | epoch 009:   1667 / 6788 loss=4.773, ppl=27.35, wps=21705.6, ups=0.08, wpb=262144, bsz=512, num_updates=55700, lr=0.00053596, gnorm=0.35, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-28 18:41:56 | INFO | train_inner | epoch 009:   1767 / 6788 loss=4.776, ppl=27.4, wps=21543.7, ups=0.08, wpb=262144, bsz=512, num_updates=55800, lr=0.00053548, gnorm=0.364, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-28 19:01:58 | INFO | train_inner | epoch 009:   1867 / 6788 loss=4.778, ppl=27.44, wps=21799.5, ups=0.08, wpb=262062, bsz=511.8, num_updates=55900, lr=0.000535, gnorm=0.357, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-28 19:21:52 | INFO | train_inner | epoch 009:   1967 / 6788 loss=4.776, ppl=27.4, wps=21948.4, ups=0.08, wpb=262144, bsz=512, num_updates=56000, lr=0.000534522, gnorm=0.358, clip=0, loss_scale=8, train_wall=1194, gb_free=10.7, wall=0
2024-03-28 19:41:49 | INFO | train_inner | epoch 009:   2067 / 6788 loss=4.779, ppl=27.45, wps=21900.4, ups=0.08, wpb=262144, bsz=512, num_updates=56100, lr=0.000534046, gnorm=0.353, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-28 20:01:47 | INFO | train_inner | epoch 009:   2167 / 6788 loss=4.778, ppl=27.43, wps=21879.5, ups=0.08, wpb=262144, bsz=512, num_updates=56200, lr=0.000533571, gnorm=0.357, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-28 20:21:50 | INFO | train_inner | epoch 009:   2267 / 6788 loss=4.775, ppl=27.37, wps=21790.9, ups=0.08, wpb=262144, bsz=512, num_updates=56300, lr=0.000533096, gnorm=0.362, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-28 20:41:45 | INFO | train_inner | epoch 009:   2367 / 6788 loss=4.776, ppl=27.39, wps=21939, ups=0.08, wpb=262144, bsz=512, num_updates=56400, lr=0.000532624, gnorm=0.357, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-28 21:01:42 | INFO | train_inner | epoch 009:   2467 / 6788 loss=4.773, ppl=27.34, wps=21900.1, ups=0.08, wpb=262144, bsz=512, num_updates=56500, lr=0.000532152, gnorm=0.354, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-28 21:21:42 | INFO | train_inner | epoch 009:   2567 / 6788 loss=4.774, ppl=27.35, wps=21856, ups=0.08, wpb=262144, bsz=512, num_updates=56600, lr=0.000531682, gnorm=0.362, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-28 21:42:06 | INFO | train_inner | epoch 009:   2667 / 6788 loss=4.772, ppl=27.33, wps=21410.6, ups=0.08, wpb=262144, bsz=512, num_updates=56700, lr=0.000531213, gnorm=0.347, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-28 22:02:42 | INFO | train_inner | epoch 009:   2767 / 6788 loss=4.775, ppl=27.38, wps=21217.9, ups=0.08, wpb=262144, bsz=512, num_updates=56800, lr=0.000530745, gnorm=0.354, clip=0, loss_scale=8, train_wall=1235, gb_free=10.7, wall=0
2024-03-28 22:22:38 | INFO | train_inner | epoch 009:   2867 / 6788 loss=4.773, ppl=27.34, wps=21914.7, ups=0.08, wpb=262144, bsz=512, num_updates=56900, lr=0.000530278, gnorm=0.347, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-28 22:42:22 | INFO | train_inner | epoch 009:   2967 / 6788 loss=4.771, ppl=27.3, wps=22128.9, ups=0.08, wpb=262144, bsz=512, num_updates=57000, lr=0.000529813, gnorm=0.347, clip=0, loss_scale=8, train_wall=1184, gb_free=10.7, wall=0
2024-03-28 23:02:15 | INFO | train_inner | epoch 009:   3067 / 6788 loss=4.773, ppl=27.34, wps=21990.8, ups=0.08, wpb=262144, bsz=512, num_updates=57100, lr=0.000529349, gnorm=0.348, clip=0, loss_scale=16, train_wall=1192, gb_free=10.7, wall=0
2024-03-28 23:05:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-28 23:22:29 | INFO | train_inner | epoch 009:   3168 / 6788 loss=4.772, ppl=27.32, wps=21590.3, ups=0.08, wpb=262144, bsz=512, num_updates=57200, lr=0.000528886, gnorm=0.36, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-28 23:42:33 | INFO | train_inner | epoch 009:   3268 / 6788 loss=4.771, ppl=27.31, wps=21758.6, ups=0.08, wpb=262144, bsz=512, num_updates=57300, lr=0.000528424, gnorm=0.357, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-29 00:02:29 | INFO | train_inner | epoch 009:   3368 / 6788 loss=4.772, ppl=27.32, wps=21925.9, ups=0.08, wpb=262144, bsz=512, num_updates=57400, lr=0.000527964, gnorm=0.367, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 00:22:17 | INFO | train_inner | epoch 009:   3468 / 6788 loss=4.775, ppl=27.37, wps=22065.8, ups=0.08, wpb=262144, bsz=512, num_updates=57500, lr=0.000527504, gnorm=0.352, clip=0, loss_scale=8, train_wall=1188, gb_free=10.7, wall=0
2024-03-29 00:42:05 | INFO | train_inner | epoch 009:   3568 / 6788 loss=4.772, ppl=27.32, wps=22072.6, ups=0.08, wpb=262144, bsz=512, num_updates=57600, lr=0.000527046, gnorm=0.357, clip=0, loss_scale=8, train_wall=1187, gb_free=10.7, wall=0
2024-03-29 01:02:02 | INFO | train_inner | epoch 009:   3668 / 6788 loss=4.776, ppl=27.4, wps=21890.5, ups=0.08, wpb=262144, bsz=512, num_updates=57700, lr=0.000526589, gnorm=0.357, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-29 01:22:01 | INFO | train_inner | epoch 009:   3768 / 6788 loss=4.776, ppl=27.39, wps=21868, ups=0.08, wpb=262144, bsz=512, num_updates=57800, lr=0.000526134, gnorm=0.356, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-29 01:41:50 | INFO | train_inner | epoch 009:   3868 / 6788 loss=4.77, ppl=27.29, wps=22044.6, ups=0.08, wpb=262144, bsz=512, num_updates=57900, lr=0.000525679, gnorm=0.367, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-29 02:01:21 | INFO | train_inner | epoch 009:   3968 / 6788 loss=4.772, ppl=27.32, wps=22380, ups=0.09, wpb=262144, bsz=512, num_updates=58000, lr=0.000525226, gnorm=0.354, clip=0, loss_scale=8, train_wall=1171, gb_free=10.7, wall=0
2024-03-29 02:20:49 | INFO | train_inner | epoch 009:   4068 / 6788 loss=4.771, ppl=27.31, wps=22447.1, ups=0.09, wpb=262144, bsz=512, num_updates=58100, lr=0.000524774, gnorm=0.359, clip=0, loss_scale=8, train_wall=1168, gb_free=10.7, wall=0
2024-03-29 02:40:36 | INFO | train_inner | epoch 009:   4168 / 6788 loss=4.776, ppl=27.39, wps=22083.3, ups=0.08, wpb=262144, bsz=512, num_updates=58200, lr=0.000524323, gnorm=0.363, clip=0, loss_scale=8, train_wall=1187, gb_free=10.7, wall=0
2024-03-29 03:00:32 | INFO | train_inner | epoch 009:   4268 / 6788 loss=4.773, ppl=27.33, wps=21917.2, ups=0.08, wpb=262144, bsz=512, num_updates=58300, lr=0.000523873, gnorm=0.356, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-29 03:20:31 | INFO | train_inner | epoch 009:   4368 / 6788 loss=4.771, ppl=27.3, wps=21876.7, ups=0.08, wpb=262144, bsz=512, num_updates=58400, lr=0.000523424, gnorm=0.353, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-29 03:40:26 | INFO | train_inner | epoch 009:   4468 / 6788 loss=4.77, ppl=27.29, wps=21936.5, ups=0.08, wpb=262144, bsz=512, num_updates=58500, lr=0.000522976, gnorm=0.363, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 04:00:22 | INFO | train_inner | epoch 009:   4568 / 6788 loss=4.772, ppl=27.33, wps=21921.1, ups=0.08, wpb=262144, bsz=512, num_updates=58600, lr=0.00052253, gnorm=0.361, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-29 04:20:09 | INFO | train_inner | epoch 009:   4668 / 6788 loss=4.772, ppl=27.32, wps=22076.6, ups=0.08, wpb=262144, bsz=512, num_updates=58700, lr=0.000522085, gnorm=0.356, clip=0, loss_scale=8, train_wall=1187, gb_free=10.7, wall=0
2024-03-29 04:40:04 | INFO | train_inner | epoch 009:   4768 / 6788 loss=4.77, ppl=27.28, wps=21939.1, ups=0.08, wpb=262144, bsz=512, num_updates=58800, lr=0.000521641, gnorm=0.351, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 05:00:05 | INFO | train_inner | epoch 009:   4868 / 6788 loss=4.771, ppl=27.3, wps=21821.2, ups=0.08, wpb=262144, bsz=512, num_updates=58900, lr=0.000521198, gnorm=0.363, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-29 05:19:48 | INFO | train_inner | epoch 009:   4968 / 6788 loss=4.772, ppl=27.33, wps=22166.1, ups=0.08, wpb=262144, bsz=512, num_updates=59000, lr=0.000520756, gnorm=0.358, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-29 05:39:26 | INFO | train_inner | epoch 009:   5068 / 6788 loss=4.77, ppl=27.29, wps=22245.5, ups=0.08, wpb=262144, bsz=512, num_updates=59100, lr=0.000520315, gnorm=0.358, clip=0, loss_scale=8, train_wall=1178, gb_free=10.7, wall=0
2024-03-29 05:59:12 | INFO | train_inner | epoch 009:   5168 / 6788 loss=4.771, ppl=27.3, wps=22105.6, ups=0.08, wpb=262144, bsz=512, num_updates=59200, lr=0.000519875, gnorm=0.37, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-29 06:19:01 | INFO | train_inner | epoch 009:   5268 / 6788 loss=4.774, ppl=27.36, wps=22048.2, ups=0.08, wpb=262144, bsz=512, num_updates=59300, lr=0.000519437, gnorm=0.355, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-29 06:39:00 | INFO | train_inner | epoch 009:   5368 / 6788 loss=4.767, ppl=27.23, wps=21866.8, ups=0.08, wpb=262144, bsz=512, num_updates=59400, lr=0.000518999, gnorm=0.361, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-29 06:58:57 | INFO | train_inner | epoch 009:   5468 / 6788 loss=4.772, ppl=27.33, wps=21893.9, ups=0.08, wpb=262144, bsz=512, num_updates=59500, lr=0.000518563, gnorm=0.358, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-29 07:18:44 | INFO | train_inner | epoch 009:   5568 / 6788 loss=4.768, ppl=27.25, wps=22086.6, ups=0.08, wpb=262144, bsz=512, num_updates=59600, lr=0.000518128, gnorm=0.357, clip=0, loss_scale=8, train_wall=1187, gb_free=10.7, wall=0
2024-03-29 07:38:35 | INFO | train_inner | epoch 009:   5668 / 6788 loss=4.767, ppl=27.23, wps=22017.2, ups=0.08, wpb=262144, bsz=512, num_updates=59700, lr=0.000517694, gnorm=0.358, clip=0, loss_scale=8, train_wall=1190, gb_free=10.7, wall=0
2024-03-29 07:58:30 | INFO | train_inner | epoch 009:   5768 / 6788 loss=4.77, ppl=27.29, wps=21925.7, ups=0.08, wpb=262144, bsz=512, num_updates=59800, lr=0.000517261, gnorm=0.361, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 08:18:22 | INFO | train_inner | epoch 009:   5868 / 6788 loss=4.767, ppl=27.23, wps=22003.3, ups=0.08, wpb=262144, bsz=512, num_updates=59900, lr=0.000516829, gnorm=0.358, clip=0, loss_scale=8, train_wall=1191, gb_free=10.7, wall=0
2024-03-29 08:38:05 | INFO | train_inner | epoch 009:   5968 / 6788 loss=4.772, ppl=27.32, wps=22159.5, ups=0.08, wpb=262144, bsz=512, num_updates=60000, lr=0.000516398, gnorm=0.366, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-29 08:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 60000 updates
2024-03-29 08:38:05 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_60000.pt
2024-03-29 08:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_60000.pt
2024-03-29 08:38:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_9_60000.pt (epoch 9 @ 60000 updates, score None) (writing took 43.90595582826063 seconds)
2024-03-29 08:58:25 | INFO | train_inner | epoch 009:   6068 / 6788 loss=4.767, ppl=27.24, wps=21481.1, ups=0.08, wpb=262144, bsz=512, num_updates=60100, lr=0.000515968, gnorm=0.353, clip=0, loss_scale=8, train_wall=1176, gb_free=10.7, wall=0
2024-03-29 09:18:03 | INFO | train_inner | epoch 009:   6168 / 6788 loss=4.773, ppl=27.33, wps=22262.4, ups=0.08, wpb=262144, bsz=512, num_updates=60200, lr=0.000515539, gnorm=0.364, clip=0, loss_scale=8, train_wall=1177, gb_free=10.7, wall=0
2024-03-29 09:37:46 | INFO | train_inner | epoch 009:   6268 / 6788 loss=4.767, ppl=27.22, wps=22152.2, ups=0.08, wpb=262144, bsz=512, num_updates=60300, lr=0.000515112, gnorm=0.356, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-29 09:57:43 | INFO | train_inner | epoch 009:   6368 / 6788 loss=4.771, ppl=27.31, wps=21906.4, ups=0.08, wpb=262144, bsz=512, num_updates=60400, lr=0.000514685, gnorm=0.358, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-29 10:17:39 | INFO | train_inner | epoch 009:   6468 / 6788 loss=4.771, ppl=27.31, wps=21916.4, ups=0.08, wpb=262144, bsz=512, num_updates=60500, lr=0.000514259, gnorm=0.357, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-29 10:37:42 | INFO | train_inner | epoch 009:   6568 / 6788 loss=4.772, ppl=27.32, wps=21783.1, ups=0.08, wpb=262144, bsz=512, num_updates=60600, lr=0.000513835, gnorm=0.369, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-29 10:57:43 | INFO | train_inner | epoch 009:   6668 / 6788 loss=4.77, ppl=27.28, wps=21826.8, ups=0.08, wpb=262144, bsz=512, num_updates=60700, lr=0.000513412, gnorm=0.354, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-29 11:17:40 | INFO | train_inner | epoch 009:   6768 / 6788 loss=4.775, ppl=27.38, wps=21913, ups=0.08, wpb=262144, bsz=512, num_updates=60800, lr=0.000512989, gnorm=0.374, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-29 11:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 60820 updates
2024-03-29 11:21:40 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint9.pt
2024-03-29 11:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint9.pt
2024-03-29 11:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint9.pt (epoch 9 @ 60820 updates, score None) (writing took 72.56134232506156 seconds)
2024-03-29 11:22:53 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-03-29 11:22:53 | INFO | train | epoch 009 | loss 4.774 | ppl 27.35 | wps 21848.7 | ups 0.08 | wpb 262124 | bsz 512 | num_updates 60820 | lr 0.000512905 | gnorm 0.357 | clip 0 | loss_scale 8 | train_wall 81232 | gb_free 10.7 | wall 0
2024-03-29 11:22:53 | INFO | fairseq.trainer | loading train data for epoch 10
2024-03-29 11:22:54 | INFO | fairseq.data.data_utils | loaded 52,653,000 examples from: ./data/data-bin/9/train
2024-03-29 11:22:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6772
2024-03-29 11:22:55 | INFO | fairseq.trainer | begin training epoch 10
2024-03-29 11:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-29 11:39:10 | INFO | train_inner | epoch 010:     80 / 6772 loss=4.769, ppl=27.27, wps=20262.8, ups=0.08, wpb=261489, bsz=510.7, num_updates=60900, lr=0.000512568, gnorm=0.358, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-29 11:59:10 | INFO | train_inner | epoch 010:    180 / 6772 loss=4.768, ppl=27.24, wps=21846.7, ups=0.08, wpb=262144, bsz=512, num_updates=61000, lr=0.000512148, gnorm=0.352, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-29 12:19:07 | INFO | train_inner | epoch 010:    280 / 6772 loss=4.77, ppl=27.28, wps=21858.8, ups=0.08, wpb=261693, bsz=511.1, num_updates=61100, lr=0.000511728, gnorm=0.357, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-29 12:38:57 | INFO | train_inner | epoch 010:    380 / 6772 loss=4.77, ppl=27.28, wps=22028.9, ups=0.08, wpb=262144, bsz=512, num_updates=61200, lr=0.00051131, gnorm=0.374, clip=0, loss_scale=8, train_wall=1190, gb_free=10.7, wall=0
2024-03-29 12:43:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-29 12:59:02 | INFO | train_inner | epoch 010:    481 / 6772 loss=4.768, ppl=27.25, wps=21752.6, ups=0.08, wpb=262144, bsz=512, num_updates=61300, lr=0.000510893, gnorm=0.371, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-29 13:19:12 | INFO | train_inner | epoch 010:    581 / 6772 loss=4.763, ppl=27.15, wps=21672.8, ups=0.08, wpb=262144, bsz=512, num_updates=61400, lr=0.000510477, gnorm=0.365, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-29 13:39:24 | INFO | train_inner | epoch 010:    681 / 6772 loss=4.769, ppl=27.27, wps=21618.6, ups=0.08, wpb=262144, bsz=512, num_updates=61500, lr=0.000510061, gnorm=0.366, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-29 13:59:36 | INFO | train_inner | epoch 010:    781 / 6772 loss=4.771, ppl=27.3, wps=21641.2, ups=0.08, wpb=262144, bsz=512, num_updates=61600, lr=0.000509647, gnorm=0.357, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-29 14:19:39 | INFO | train_inner | epoch 010:    881 / 6772 loss=4.768, ppl=27.24, wps=21781.4, ups=0.08, wpb=262144, bsz=512, num_updates=61700, lr=0.000509234, gnorm=0.358, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-29 14:39:54 | INFO | train_inner | epoch 010:    981 / 6772 loss=4.763, ppl=27.15, wps=21577.7, ups=0.08, wpb=262144, bsz=512, num_updates=61800, lr=0.000508822, gnorm=0.362, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-29 14:59:58 | INFO | train_inner | epoch 010:   1081 / 6772 loss=4.767, ppl=27.23, wps=21780.4, ups=0.08, wpb=262144, bsz=512, num_updates=61900, lr=0.000508411, gnorm=0.362, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-03-29 15:20:06 | INFO | train_inner | epoch 010:   1181 / 6772 loss=4.766, ppl=27.21, wps=21701.2, ups=0.08, wpb=262144, bsz=512, num_updates=62000, lr=0.000508001, gnorm=0.357, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-29 15:40:01 | INFO | train_inner | epoch 010:   1281 / 6772 loss=4.767, ppl=27.23, wps=21929.7, ups=0.08, wpb=262144, bsz=512, num_updates=62100, lr=0.000507591, gnorm=0.351, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 15:59:56 | INFO | train_inner | epoch 010:   1381 / 6772 loss=4.77, ppl=27.28, wps=21930.1, ups=0.08, wpb=262144, bsz=512, num_updates=62200, lr=0.000507183, gnorm=0.363, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-29 16:19:44 | INFO | train_inner | epoch 010:   1481 / 6772 loss=4.766, ppl=27.22, wps=22067.9, ups=0.08, wpb=262144, bsz=512, num_updates=62300, lr=0.000506776, gnorm=0.369, clip=0, loss_scale=8, train_wall=1188, gb_free=10.7, wall=0
2024-03-29 16:39:47 | INFO | train_inner | epoch 010:   1581 / 6772 loss=4.767, ppl=27.23, wps=21799.5, ups=0.08, wpb=262144, bsz=512, num_updates=62400, lr=0.00050637, gnorm=0.37, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-29 16:59:54 | INFO | train_inner | epoch 010:   1681 / 6772 loss=4.766, ppl=27.21, wps=21707.6, ups=0.08, wpb=262144, bsz=512, num_updates=62500, lr=0.000505964, gnorm=0.369, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-29 17:20:09 | INFO | train_inner | epoch 010:   1781 / 6772 loss=4.77, ppl=27.28, wps=21586.5, ups=0.08, wpb=262144, bsz=512, num_updates=62600, lr=0.00050556, gnorm=0.351, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-29 17:40:20 | INFO | train_inner | epoch 010:   1881 / 6772 loss=4.765, ppl=27.18, wps=21646.4, ups=0.08, wpb=262144, bsz=512, num_updates=62700, lr=0.000505157, gnorm=0.355, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-29 18:00:28 | INFO | train_inner | epoch 010:   1981 / 6772 loss=4.765, ppl=27.19, wps=21702.9, ups=0.08, wpb=262144, bsz=512, num_updates=62800, lr=0.000504754, gnorm=0.354, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-29 18:20:37 | INFO | train_inner | epoch 010:   2081 / 6772 loss=4.768, ppl=27.25, wps=21672.6, ups=0.08, wpb=262144, bsz=512, num_updates=62900, lr=0.000504353, gnorm=0.353, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-29 18:40:49 | INFO | train_inner | epoch 010:   2181 / 6772 loss=4.768, ppl=27.25, wps=21630.4, ups=0.08, wpb=262144, bsz=512, num_updates=63000, lr=0.000503953, gnorm=0.36, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-29 19:00:50 | INFO | train_inner | epoch 010:   2281 / 6772 loss=4.765, ppl=27.2, wps=21782.8, ups=0.08, wpb=261494, bsz=510.7, num_updates=63100, lr=0.000503553, gnorm=0.362, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-29 19:20:39 | INFO | train_inner | epoch 010:   2381 / 6772 loss=4.762, ppl=27.13, wps=22035.7, ups=0.08, wpb=262144, bsz=512, num_updates=63200, lr=0.000503155, gnorm=0.377, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-29 19:40:33 | INFO | train_inner | epoch 010:   2481 / 6772 loss=4.765, ppl=27.18, wps=21970.6, ups=0.08, wpb=262144, bsz=512, num_updates=63300, lr=0.000502757, gnorm=0.358, clip=0, loss_scale=8, train_wall=1193, gb_free=10.7, wall=0
2024-03-29 20:00:46 | INFO | train_inner | epoch 010:   2581 / 6772 loss=4.76, ppl=27.09, wps=21608.5, ups=0.08, wpb=262144, bsz=512, num_updates=63400, lr=0.00050236, gnorm=0.36, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-29 20:20:53 | INFO | train_inner | epoch 010:   2681 / 6772 loss=4.766, ppl=27.21, wps=21713, ups=0.08, wpb=262144, bsz=512, num_updates=63500, lr=0.000501965, gnorm=0.367, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-29 20:40:58 | INFO | train_inner | epoch 010:   2781 / 6772 loss=4.764, ppl=27.16, wps=21761.1, ups=0.08, wpb=262142, bsz=512, num_updates=63600, lr=0.00050157, gnorm=0.354, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-29 21:01:09 | INFO | train_inner | epoch 010:   2881 / 6772 loss=4.763, ppl=27.14, wps=21643.2, ups=0.08, wpb=262144, bsz=512, num_updates=63700, lr=0.000501176, gnorm=0.362, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-29 21:21:24 | INFO | train_inner | epoch 010:   2981 / 6772 loss=4.762, ppl=27.13, wps=21574.2, ups=0.08, wpb=262144, bsz=512, num_updates=63800, lr=0.000500783, gnorm=0.361, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-29 21:41:32 | INFO | train_inner | epoch 010:   3081 / 6772 loss=4.763, ppl=27.16, wps=21701.8, ups=0.08, wpb=262144, bsz=512, num_updates=63900, lr=0.000500391, gnorm=0.361, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-29 22:01:33 | INFO | train_inner | epoch 010:   3181 / 6772 loss=4.765, ppl=27.19, wps=21824.7, ups=0.08, wpb=262144, bsz=512, num_updates=64000, lr=0.0005, gnorm=0.373, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-29 22:21:38 | INFO | train_inner | epoch 010:   3281 / 6772 loss=4.767, ppl=27.23, wps=21747, ups=0.08, wpb=262144, bsz=512, num_updates=64100, lr=0.00049961, gnorm=0.36, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-29 22:41:32 | INFO | train_inner | epoch 010:   3381 / 6772 loss=4.763, ppl=27.15, wps=21955.2, ups=0.08, wpb=262144, bsz=512, num_updates=64200, lr=0.000499221, gnorm=0.361, clip=0, loss_scale=8, train_wall=1194, gb_free=10.7, wall=0
2024-03-29 23:01:23 | INFO | train_inner | epoch 010:   3481 / 6772 loss=4.767, ppl=27.22, wps=22011.2, ups=0.08, wpb=262144, bsz=512, num_updates=64300, lr=0.000498832, gnorm=0.35, clip=0, loss_scale=8, train_wall=1191, gb_free=10.7, wall=0
2024-03-29 23:21:16 | INFO | train_inner | epoch 010:   3581 / 6772 loss=4.767, ppl=27.22, wps=21976.5, ups=0.08, wpb=262144, bsz=512, num_updates=64400, lr=0.000498445, gnorm=0.37, clip=0, loss_scale=8, train_wall=1193, gb_free=10.7, wall=0
2024-03-29 23:41:24 | INFO | train_inner | epoch 010:   3681 / 6772 loss=4.763, ppl=27.15, wps=21707.3, ups=0.08, wpb=262144, bsz=512, num_updates=64500, lr=0.000498058, gnorm=0.364, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-03-30 00:01:30 | INFO | train_inner | epoch 010:   3781 / 6772 loss=4.761, ppl=27.11, wps=21735.8, ups=0.08, wpb=262144, bsz=512, num_updates=64600, lr=0.000497673, gnorm=0.371, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-30 00:21:35 | INFO | train_inner | epoch 010:   3881 / 6772 loss=4.766, ppl=27.2, wps=21757.8, ups=0.08, wpb=262144, bsz=512, num_updates=64700, lr=0.000497288, gnorm=0.368, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-30 00:41:50 | INFO | train_inner | epoch 010:   3981 / 6772 loss=4.763, ppl=27.15, wps=21574.4, ups=0.08, wpb=262144, bsz=512, num_updates=64800, lr=0.000496904, gnorm=0.377, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-30 01:01:54 | INFO | train_inner | epoch 010:   4081 / 6772 loss=4.765, ppl=27.19, wps=21776.4, ups=0.08, wpb=262144, bsz=512, num_updates=64900, lr=0.000496521, gnorm=0.359, clip=0, loss_scale=8, train_wall=1204, gb_free=10.7, wall=0
2024-03-30 01:22:11 | INFO | train_inner | epoch 010:   4181 / 6772 loss=4.761, ppl=27.12, wps=21542.2, ups=0.08, wpb=262144, bsz=512, num_updates=65000, lr=0.000496139, gnorm=0.352, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-30 01:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 65000 updates
2024-03-30 01:22:11 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_10_65000.pt
2024-03-30 01:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_10_65000.pt
2024-03-30 01:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_10_65000.pt (epoch 10 @ 65000 updates, score None) (writing took 44.32412360608578 seconds)
2024-03-30 01:43:04 | INFO | train_inner | epoch 010:   4281 / 6772 loss=4.76, ppl=27.1, wps=20910.8, ups=0.08, wpb=262144, bsz=512, num_updates=65100, lr=0.000495758, gnorm=0.373, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-30 02:03:00 | INFO | train_inner | epoch 010:   4381 / 6772 loss=4.759, ppl=27.07, wps=21914, ups=0.08, wpb=262144, bsz=512, num_updates=65200, lr=0.000495377, gnorm=0.358, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-30 02:22:47 | INFO | train_inner | epoch 010:   4481 / 6772 loss=4.762, ppl=27.13, wps=22090.4, ups=0.08, wpb=262144, bsz=512, num_updates=65300, lr=0.000494998, gnorm=0.37, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-30 02:28:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-30 02:42:48 | INFO | train_inner | epoch 010:   4582 / 6772 loss=4.763, ppl=27.15, wps=21824.4, ups=0.08, wpb=262144, bsz=512, num_updates=65400, lr=0.000494619, gnorm=0.368, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-30 03:02:50 | INFO | train_inner | epoch 010:   4682 / 6772 loss=4.766, ppl=27.22, wps=21811.6, ups=0.08, wpb=262144, bsz=512, num_updates=65500, lr=0.000494242, gnorm=0.376, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-30 03:23:00 | INFO | train_inner | epoch 010:   4782 / 6772 loss=4.759, ppl=27.08, wps=21672.7, ups=0.08, wpb=262144, bsz=512, num_updates=65600, lr=0.000493865, gnorm=0.37, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-30 03:43:08 | INFO | train_inner | epoch 010:   4882 / 6772 loss=4.766, ppl=27.2, wps=21690.3, ups=0.08, wpb=262144, bsz=512, num_updates=65700, lr=0.000493489, gnorm=0.356, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-30 04:03:07 | INFO | train_inner | epoch 010:   4982 / 6772 loss=4.766, ppl=27.2, wps=21865, ups=0.08, wpb=262144, bsz=512, num_updates=65800, lr=0.000493114, gnorm=0.365, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-30 04:23:09 | INFO | train_inner | epoch 010:   5082 / 6772 loss=4.765, ppl=27.19, wps=21817.2, ups=0.08, wpb=262144, bsz=512, num_updates=65900, lr=0.000492739, gnorm=0.362, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-30 04:43:06 | INFO | train_inner | epoch 010:   5182 / 6772 loss=4.766, ppl=27.22, wps=21903.6, ups=0.08, wpb=262144, bsz=512, num_updates=66000, lr=0.000492366, gnorm=0.365, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-30 05:03:00 | INFO | train_inner | epoch 010:   5282 / 6772 loss=4.759, ppl=27.07, wps=21938.5, ups=0.08, wpb=262144, bsz=512, num_updates=66100, lr=0.000491993, gnorm=0.365, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-30 05:22:54 | INFO | train_inner | epoch 010:   5382 / 6772 loss=4.765, ppl=27.19, wps=21959.5, ups=0.08, wpb=262144, bsz=512, num_updates=66200, lr=0.000491622, gnorm=0.371, clip=0, loss_scale=8, train_wall=1194, gb_free=10.7, wall=0
2024-03-30 05:42:37 | INFO | train_inner | epoch 010:   5482 / 6772 loss=4.763, ppl=27.14, wps=22171.3, ups=0.08, wpb=262144, bsz=512, num_updates=66300, lr=0.000491251, gnorm=0.367, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-30 06:02:20 | INFO | train_inner | epoch 010:   5582 / 6772 loss=4.762, ppl=27.14, wps=22159.3, ups=0.08, wpb=262144, bsz=512, num_updates=66400, lr=0.000490881, gnorm=0.357, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-30 06:22:06 | INFO | train_inner | epoch 010:   5682 / 6772 loss=4.759, ppl=27.09, wps=22094.1, ups=0.08, wpb=262144, bsz=512, num_updates=66500, lr=0.000490511, gnorm=0.365, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-30 06:42:11 | INFO | train_inner | epoch 010:   5782 / 6772 loss=4.761, ppl=27.11, wps=21754.6, ups=0.08, wpb=262144, bsz=512, num_updates=66600, lr=0.000490143, gnorm=0.369, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-30 07:02:10 | INFO | train_inner | epoch 010:   5882 / 6772 loss=4.76, ppl=27.1, wps=21862.5, ups=0.08, wpb=262144, bsz=512, num_updates=66700, lr=0.000489776, gnorm=0.361, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-30 07:22:10 | INFO | train_inner | epoch 010:   5982 / 6772 loss=4.763, ppl=27.16, wps=21847.9, ups=0.08, wpb=262144, bsz=512, num_updates=66800, lr=0.000489409, gnorm=0.356, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-30 07:42:09 | INFO | train_inner | epoch 010:   6082 / 6772 loss=4.758, ppl=27.05, wps=21862.6, ups=0.08, wpb=262144, bsz=512, num_updates=66900, lr=0.000489043, gnorm=0.364, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-30 08:02:06 | INFO | train_inner | epoch 010:   6182 / 6772 loss=4.762, ppl=27.14, wps=21909, ups=0.08, wpb=262144, bsz=512, num_updates=67000, lr=0.000488678, gnorm=0.372, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-30 08:22:02 | INFO | train_inner | epoch 010:   6282 / 6772 loss=4.762, ppl=27.14, wps=21911.3, ups=0.08, wpb=262144, bsz=512, num_updates=67100, lr=0.000488314, gnorm=0.357, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-30 08:41:56 | INFO | train_inner | epoch 010:   6382 / 6772 loss=4.757, ppl=27.05, wps=21958.7, ups=0.08, wpb=262144, bsz=512, num_updates=67200, lr=0.00048795, gnorm=0.361, clip=0, loss_scale=8, train_wall=1194, gb_free=10.7, wall=0
2024-03-30 09:01:39 | INFO | train_inner | epoch 010:   6482 / 6772 loss=4.759, ppl=27.09, wps=22158.1, ups=0.08, wpb=262144, bsz=512, num_updates=67300, lr=0.000487587, gnorm=0.366, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-30 09:21:20 | INFO | train_inner | epoch 010:   6582 / 6772 loss=4.761, ppl=27.11, wps=22185.3, ups=0.08, wpb=262144, bsz=512, num_updates=67400, lr=0.000487226, gnorm=0.366, clip=0, loss_scale=8, train_wall=1181, gb_free=10.7, wall=0
2024-03-30 09:41:05 | INFO | train_inner | epoch 010:   6682 / 6772 loss=4.759, ppl=27.08, wps=22120.5, ups=0.08, wpb=262144, bsz=512, num_updates=67500, lr=0.000486864, gnorm=0.352, clip=0, loss_scale=8, train_wall=1185, gb_free=10.7, wall=0
2024-03-30 09:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 67590 updates
2024-03-30 09:59:05 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint10.pt
2024-03-30 09:59:21 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint10.pt
2024-03-30 10:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint10.pt (epoch 10 @ 67590 updates, score None) (writing took 71.0977051500231 seconds)
2024-03-30 10:00:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-03-30 10:00:16 | INFO | train | epoch 010 | loss 4.764 | ppl 27.17 | wps 21788.5 | ups 0.08 | wpb 262118 | bsz 511.9 | num_updates 67590 | lr 0.00048654 | gnorm 0.363 | clip 0 | loss_scale 8 | train_wall 81313 | gb_free 10.7 | wall 0
2024-03-30 10:00:16 | INFO | fairseq.trainer | loading train data for epoch 11
2024-03-30 10:00:18 | INFO | fairseq.data.data_utils | loaded 52,970,000 examples from: ./data/data-bin/10/train
2024-03-30 10:00:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6806
2024-03-30 10:00:19 | INFO | fairseq.trainer | begin training epoch 11
2024-03-30 10:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-30 10:02:21 | INFO | train_inner | epoch 011:     10 / 6806 loss=4.753, ppl=26.97, wps=20506.1, ups=0.08, wpb=261489, bsz=510.7, num_updates=67600, lr=0.000486504, gnorm=0.359, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-30 10:22:30 | INFO | train_inner | epoch 011:    110 / 6806 loss=4.764, ppl=27.17, wps=21677.8, ups=0.08, wpb=262144, bsz=512, num_updates=67700, lr=0.000486145, gnorm=0.371, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-30 10:42:35 | INFO | train_inner | epoch 011:    210 / 6806 loss=4.754, ppl=26.99, wps=21751.1, ups=0.08, wpb=262144, bsz=512, num_updates=67800, lr=0.000485786, gnorm=0.367, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-03-30 11:02:38 | INFO | train_inner | epoch 011:    310 / 6806 loss=4.764, ppl=27.16, wps=21796.9, ups=0.08, wpb=262144, bsz=512, num_updates=67900, lr=0.000485428, gnorm=0.365, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-30 11:22:46 | INFO | train_inner | epoch 011:    410 / 6806 loss=4.757, ppl=27.04, wps=21703.9, ups=0.08, wpb=262144, bsz=512, num_updates=68000, lr=0.000485071, gnorm=0.365, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-03-30 11:43:02 | INFO | train_inner | epoch 011:    510 / 6806 loss=4.763, ppl=27.16, wps=21553, ups=0.08, wpb=262144, bsz=512, num_updates=68100, lr=0.000484715, gnorm=0.364, clip=0, loss_scale=8, train_wall=1216, gb_free=10.7, wall=0
2024-03-30 12:03:11 | INFO | train_inner | epoch 011:    610 / 6806 loss=4.755, ppl=27.01, wps=21680.3, ups=0.08, wpb=262144, bsz=512, num_updates=68200, lr=0.000484359, gnorm=0.365, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-30 12:23:11 | INFO | train_inner | epoch 011:    710 / 6806 loss=4.759, ppl=27.07, wps=21838.4, ups=0.08, wpb=262144, bsz=512, num_updates=68300, lr=0.000484005, gnorm=0.365, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-30 12:43:00 | INFO | train_inner | epoch 011:    810 / 6806 loss=4.761, ppl=27.11, wps=22029.9, ups=0.08, wpb=261939, bsz=511.6, num_updates=68400, lr=0.000483651, gnorm=0.371, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-30 13:02:59 | INFO | train_inner | epoch 011:    910 / 6806 loss=4.758, ppl=27.07, wps=21863.7, ups=0.08, wpb=262144, bsz=512, num_updates=68500, lr=0.000483298, gnorm=0.377, clip=0, loss_scale=8, train_wall=1199, gb_free=10.7, wall=0
2024-03-30 13:23:29 | INFO | train_inner | epoch 011:   1010 / 6806 loss=4.756, ppl=27.02, wps=21319.9, ups=0.08, wpb=262144, bsz=512, num_updates=68600, lr=0.000482945, gnorm=0.361, clip=0, loss_scale=8, train_wall=1229, gb_free=10.7, wall=0
2024-03-30 13:43:58 | INFO | train_inner | epoch 011:   1110 / 6806 loss=4.764, ppl=27.18, wps=21321.8, ups=0.08, wpb=262144, bsz=512, num_updates=68700, lr=0.000482594, gnorm=0.362, clip=0, loss_scale=8, train_wall=1229, gb_free=10.7, wall=0
2024-03-30 14:04:34 | INFO | train_inner | epoch 011:   1210 / 6806 loss=4.76, ppl=27.09, wps=21223.4, ups=0.08, wpb=262144, bsz=512, num_updates=68800, lr=0.000482243, gnorm=0.364, clip=0, loss_scale=8, train_wall=1235, gb_free=10.7, wall=0
2024-03-30 14:25:03 | INFO | train_inner | epoch 011:   1310 / 6806 loss=4.759, ppl=27.08, wps=21327, ups=0.08, wpb=262144, bsz=512, num_updates=68900, lr=0.000481893, gnorm=0.374, clip=0, loss_scale=8, train_wall=1229, gb_free=10.7, wall=0
2024-03-30 14:45:34 | INFO | train_inner | epoch 011:   1410 / 6806 loss=4.759, ppl=27.08, wps=21297, ups=0.08, wpb=262144, bsz=512, num_updates=69000, lr=0.000481543, gnorm=0.369, clip=0, loss_scale=8, train_wall=1231, gb_free=10.7, wall=0
2024-03-30 15:06:08 | INFO | train_inner | epoch 011:   1510 / 6806 loss=4.757, ppl=27.05, wps=21243, ups=0.08, wpb=262144, bsz=512, num_updates=69100, lr=0.000481195, gnorm=0.364, clip=0, loss_scale=8, train_wall=1234, gb_free=10.7, wall=0
2024-03-30 15:26:29 | INFO | train_inner | epoch 011:   1610 / 6806 loss=4.754, ppl=26.98, wps=21459.1, ups=0.08, wpb=262144, bsz=512, num_updates=69200, lr=0.000480847, gnorm=0.365, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-30 15:46:54 | INFO | train_inner | epoch 011:   1710 / 6806 loss=4.761, ppl=27.12, wps=21401.9, ups=0.08, wpb=262144, bsz=512, num_updates=69300, lr=0.0004805, gnorm=0.375, clip=0, loss_scale=8, train_wall=1225, gb_free=10.7, wall=0
2024-03-30 16:07:22 | INFO | train_inner | epoch 011:   1810 / 6806 loss=4.759, ppl=27.08, wps=21352.4, ups=0.08, wpb=262144, bsz=512, num_updates=69400, lr=0.000480154, gnorm=0.354, clip=0, loss_scale=8, train_wall=1228, gb_free=10.7, wall=0
2024-03-30 16:13:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-30 16:28:00 | INFO | train_inner | epoch 011:   1911 / 6806 loss=4.757, ppl=27.04, wps=21175.1, ups=0.08, wpb=262144, bsz=512, num_updates=69500, lr=0.000479808, gnorm=0.386, clip=0, loss_scale=8, train_wall=1238, gb_free=10.7, wall=0
2024-03-30 16:48:23 | INFO | train_inner | epoch 011:   2011 / 6806 loss=4.75, ppl=26.92, wps=21432.2, ups=0.08, wpb=262144, bsz=512, num_updates=69600, lr=0.000479463, gnorm=0.365, clip=0, loss_scale=8, train_wall=1223, gb_free=10.7, wall=0
2024-03-30 17:08:47 | INFO | train_inner | epoch 011:   2111 / 6806 loss=4.752, ppl=26.94, wps=21415, ups=0.08, wpb=262144, bsz=512, num_updates=69700, lr=0.000479119, gnorm=0.357, clip=0, loss_scale=8, train_wall=1224, gb_free=10.7, wall=0
2024-03-30 17:28:59 | INFO | train_inner | epoch 011:   2211 / 6806 loss=4.761, ppl=27.11, wps=21627.3, ups=0.08, wpb=262144, bsz=512, num_updates=69800, lr=0.000478776, gnorm=0.369, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-30 17:49:09 | INFO | train_inner | epoch 011:   2311 / 6806 loss=4.757, ppl=27.04, wps=21663.3, ups=0.08, wpb=262144, bsz=512, num_updates=69900, lr=0.000478433, gnorm=0.369, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-30 18:09:10 | INFO | train_inner | epoch 011:   2411 / 6806 loss=4.755, ppl=27.01, wps=21837.8, ups=0.08, wpb=262144, bsz=512, num_updates=70000, lr=0.000478091, gnorm=0.374, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-30 18:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 70000 updates
2024-03-30 18:09:10 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_11_70000.pt
2024-03-30 18:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_11_70000.pt
2024-03-30 18:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_11_70000.pt (epoch 11 @ 70000 updates, score None) (writing took 44.255988395772874 seconds)
2024-03-30 18:30:07 | INFO | train_inner | epoch 011:   2511 / 6806 loss=4.757, ppl=27.05, wps=20857.6, ups=0.08, wpb=262144, bsz=512, num_updates=70100, lr=0.00047775, gnorm=0.367, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-30 18:50:18 | INFO | train_inner | epoch 011:   2611 / 6806 loss=4.754, ppl=26.98, wps=21631.2, ups=0.08, wpb=262144, bsz=512, num_updates=70200, lr=0.00047741, gnorm=0.369, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-30 19:10:25 | INFO | train_inner | epoch 011:   2711 / 6806 loss=4.758, ppl=27.05, wps=21727.1, ups=0.08, wpb=262144, bsz=512, num_updates=70300, lr=0.00047707, gnorm=0.366, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-30 19:30:42 | INFO | train_inner | epoch 011:   2811 / 6806 loss=4.752, ppl=26.95, wps=21530.8, ups=0.08, wpb=262144, bsz=512, num_updates=70400, lr=0.000476731, gnorm=0.369, clip=0, loss_scale=8, train_wall=1217, gb_free=10.7, wall=0
2024-03-30 19:50:52 | INFO | train_inner | epoch 011:   2911 / 6806 loss=4.758, ppl=27.06, wps=21668.2, ups=0.08, wpb=262144, bsz=512, num_updates=70500, lr=0.000476393, gnorm=0.378, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-30 20:11:02 | INFO | train_inner | epoch 011:   3011 / 6806 loss=4.756, ppl=27.02, wps=21663.1, ups=0.08, wpb=262144, bsz=512, num_updates=70600, lr=0.000476056, gnorm=0.375, clip=0, loss_scale=8, train_wall=1210, gb_free=10.7, wall=0
2024-03-30 20:31:03 | INFO | train_inner | epoch 011:   3111 / 6806 loss=4.757, ppl=27.04, wps=21840.8, ups=0.08, wpb=262144, bsz=512, num_updates=70700, lr=0.000475719, gnorm=0.369, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-30 20:51:05 | INFO | train_inner | epoch 011:   3211 / 6806 loss=4.754, ppl=26.99, wps=21796.7, ups=0.08, wpb=262144, bsz=512, num_updates=70800, lr=0.000475383, gnorm=0.365, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-30 21:11:12 | INFO | train_inner | epoch 011:   3311 / 6806 loss=4.755, ppl=27, wps=21731.6, ups=0.08, wpb=262144, bsz=512, num_updates=70900, lr=0.000475047, gnorm=0.371, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-30 21:31:07 | INFO | train_inner | epoch 011:   3411 / 6806 loss=4.752, ppl=26.94, wps=21921.7, ups=0.08, wpb=262144, bsz=512, num_updates=71000, lr=0.000474713, gnorm=0.36, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-30 21:51:03 | INFO | train_inner | epoch 011:   3511 / 6806 loss=4.756, ppl=27.01, wps=21924.7, ups=0.08, wpb=262144, bsz=512, num_updates=71100, lr=0.000474379, gnorm=0.371, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-30 22:10:59 | INFO | train_inner | epoch 011:   3611 / 6806 loss=4.759, ppl=27.09, wps=21913.3, ups=0.08, wpb=262144, bsz=512, num_updates=71200, lr=0.000474045, gnorm=0.359, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-30 22:30:57 | INFO | train_inner | epoch 011:   3711 / 6806 loss=4.754, ppl=26.98, wps=21885.1, ups=0.08, wpb=262144, bsz=512, num_updates=71300, lr=0.000473713, gnorm=0.383, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-30 22:50:52 | INFO | train_inner | epoch 011:   3811 / 6806 loss=4.757, ppl=27.03, wps=21938.3, ups=0.08, wpb=262144, bsz=512, num_updates=71400, lr=0.000473381, gnorm=0.38, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-30 23:10:46 | INFO | train_inner | epoch 011:   3911 / 6806 loss=4.751, ppl=26.94, wps=21962.6, ups=0.08, wpb=262144, bsz=512, num_updates=71500, lr=0.00047305, gnorm=0.367, clip=0, loss_scale=8, train_wall=1193, gb_free=10.7, wall=0
2024-03-30 23:30:36 | INFO | train_inner | epoch 011:   4011 / 6806 loss=4.75, ppl=26.91, wps=22025.7, ups=0.08, wpb=262144, bsz=512, num_updates=71600, lr=0.000472719, gnorm=0.377, clip=0, loss_scale=8, train_wall=1190, gb_free=10.7, wall=0
2024-03-30 23:50:25 | INFO | train_inner | epoch 011:   4111 / 6806 loss=4.754, ppl=26.98, wps=22038.3, ups=0.08, wpb=262144, bsz=512, num_updates=71700, lr=0.00047239, gnorm=0.353, clip=0, loss_scale=8, train_wall=1189, gb_free=10.7, wall=0
2024-03-31 00:10:23 | INFO | train_inner | epoch 011:   4211 / 6806 loss=4.754, ppl=26.98, wps=21883.5, ups=0.08, wpb=262144, bsz=512, num_updates=71800, lr=0.000472061, gnorm=0.383, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-31 00:30:18 | INFO | train_inner | epoch 011:   4311 / 6806 loss=4.751, ppl=26.93, wps=21938.9, ups=0.08, wpb=262144, bsz=512, num_updates=71900, lr=0.000471732, gnorm=0.382, clip=0, loss_scale=8, train_wall=1195, gb_free=10.7, wall=0
2024-03-31 00:50:15 | INFO | train_inner | epoch 011:   4411 / 6806 loss=4.751, ppl=26.94, wps=21896.4, ups=0.08, wpb=262144, bsz=512, num_updates=72000, lr=0.000471405, gnorm=0.364, clip=0, loss_scale=8, train_wall=1197, gb_free=10.7, wall=0
2024-03-31 01:10:12 | INFO | train_inner | epoch 011:   4511 / 6806 loss=4.754, ppl=26.98, wps=21908.9, ups=0.08, wpb=262144, bsz=512, num_updates=72100, lr=0.000471077, gnorm=0.357, clip=0, loss_scale=8, train_wall=1196, gb_free=10.7, wall=0
2024-03-31 01:30:23 | INFO | train_inner | epoch 011:   4611 / 6806 loss=4.755, ppl=27, wps=21645.5, ups=0.08, wpb=262144, bsz=512, num_updates=72200, lr=0.000470751, gnorm=0.359, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-03-31 01:50:36 | INFO | train_inner | epoch 011:   4711 / 6806 loss=4.749, ppl=26.89, wps=21604, ups=0.08, wpb=262144, bsz=512, num_updates=72300, lr=0.000470425, gnorm=0.38, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-31 03:10:50 | INFO | train_inner | epoch 011:   4811 / 6806 loss=4.753, ppl=26.96, wps=21606.6, ups=0.08, wpb=262144, bsz=512, num_updates=72400, lr=0.0004701, gnorm=0.367, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-31 03:31:02 | INFO | train_inner | epoch 011:   4911 / 6806 loss=4.751, ppl=26.93, wps=21615.8, ups=0.08, wpb=262144, bsz=512, num_updates=72500, lr=0.000469776, gnorm=0.366, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-03-31 03:51:17 | INFO | train_inner | epoch 011:   5011 / 6806 loss=4.753, ppl=26.97, wps=21580.1, ups=0.08, wpb=262144, bsz=512, num_updates=72600, lr=0.000469453, gnorm=0.382, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-03-31 04:11:37 | INFO | train_inner | epoch 011:   5111 / 6806 loss=4.752, ppl=26.95, wps=21484.9, ups=0.08, wpb=262144, bsz=512, num_updates=72700, lr=0.00046913, gnorm=0.382, clip=0, loss_scale=8, train_wall=1220, gb_free=10.7, wall=0
2024-03-31 04:31:58 | INFO | train_inner | epoch 011:   5211 / 6806 loss=4.754, ppl=26.98, wps=21473.9, ups=0.08, wpb=262144, bsz=512, num_updates=72800, lr=0.000468807, gnorm=0.362, clip=0, loss_scale=8, train_wall=1221, gb_free=10.7, wall=0
2024-03-31 04:52:13 | INFO | train_inner | epoch 011:   5311 / 6806 loss=4.752, ppl=26.95, wps=21581.4, ups=0.08, wpb=262144, bsz=512, num_updates=72900, lr=0.000468486, gnorm=0.37, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-03-31 05:12:25 | INFO | train_inner | epoch 011:   5411 / 6806 loss=4.754, ppl=26.99, wps=21623.1, ups=0.08, wpb=262144, bsz=512, num_updates=73000, lr=0.000468165, gnorm=0.365, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-03-31 05:32:43 | INFO | train_inner | epoch 011:   5511 / 6806 loss=4.748, ppl=26.88, wps=21523.4, ups=0.08, wpb=262144, bsz=512, num_updates=73100, lr=0.000467844, gnorm=0.37, clip=0, loss_scale=8, train_wall=1218, gb_free=10.7, wall=0
2024-03-31 05:52:41 | INFO | train_inner | epoch 011:   5611 / 6806 loss=4.75, ppl=26.91, wps=21887.1, ups=0.08, wpb=262144, bsz=512, num_updates=73200, lr=0.000467525, gnorm=0.366, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-31 06:12:39 | INFO | train_inner | epoch 011:   5711 / 6806 loss=4.757, ppl=27.03, wps=21879, ups=0.08, wpb=262144, bsz=512, num_updates=73300, lr=0.000467206, gnorm=0.378, clip=0, loss_scale=8, train_wall=1198, gb_free=10.7, wall=0
2024-03-31 06:32:45 | INFO | train_inner | epoch 011:   5811 / 6806 loss=4.754, ppl=26.98, wps=21740.3, ups=0.08, wpb=262144, bsz=512, num_updates=73400, lr=0.000466887, gnorm=0.378, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-03-31 06:52:47 | INFO | train_inner | epoch 011:   5911 / 6806 loss=4.75, ppl=26.9, wps=21801.7, ups=0.08, wpb=262144, bsz=512, num_updates=73500, lr=0.000466569, gnorm=0.374, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-31 06:59:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-03-31 07:13:05 | INFO | train_inner | epoch 011:   6012 / 6806 loss=4.751, ppl=26.92, wps=21520, ups=0.08, wpb=262144, bsz=512, num_updates=73600, lr=0.000466252, gnorm=0.364, clip=0, loss_scale=8, train_wall=1218, gb_free=10.7, wall=0
2024-03-31 07:33:07 | INFO | train_inner | epoch 011:   6112 / 6806 loss=4.757, ppl=27.03, wps=21814.9, ups=0.08, wpb=262144, bsz=512, num_updates=73700, lr=0.000465936, gnorm=0.377, clip=0, loss_scale=8, train_wall=1201, gb_free=10.7, wall=0
2024-03-31 07:53:09 | INFO | train_inner | epoch 011:   6212 / 6806 loss=4.756, ppl=27.03, wps=21798.3, ups=0.08, wpb=262144, bsz=512, num_updates=73800, lr=0.00046562, gnorm=0.374, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-03-31 08:13:09 | INFO | train_inner | epoch 011:   6312 / 6806 loss=4.751, ppl=26.93, wps=21844.8, ups=0.08, wpb=262144, bsz=512, num_updates=73900, lr=0.000465305, gnorm=0.378, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-31 08:33:10 | INFO | train_inner | epoch 011:   6412 / 6806 loss=4.754, ppl=26.98, wps=21779.4, ups=0.08, wpb=261499, bsz=510.7, num_updates=74000, lr=0.000464991, gnorm=0.377, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-03-31 08:52:47 | INFO | train_inner | epoch 011:   6512 / 6806 loss=4.748, ppl=26.87, wps=22276.8, ups=0.08, wpb=262144, bsz=512, num_updates=74100, lr=0.000464677, gnorm=0.368, clip=0, loss_scale=8, train_wall=1177, gb_free=10.7, wall=0
2024-03-31 09:12:20 | INFO | train_inner | epoch 011:   6612 / 6806 loss=4.748, ppl=26.87, wps=22343, ups=0.09, wpb=262144, bsz=512, num_updates=74200, lr=0.000464363, gnorm=0.371, clip=0, loss_scale=8, train_wall=1173, gb_free=10.7, wall=0
2024-03-31 09:31:56 | INFO | train_inner | epoch 011:   6712 / 6806 loss=4.754, ppl=26.97, wps=22297.1, ups=0.09, wpb=262144, bsz=512, num_updates=74300, lr=0.000464051, gnorm=0.364, clip=0, loss_scale=8, train_wall=1175, gb_free=10.7, wall=0
2024-03-31 09:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 74394 updates
2024-03-31 09:50:22 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint11.pt
2024-03-31 09:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint11.pt
2024-03-31 09:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint11.pt (epoch 11 @ 74394 updates, score None) (writing took 72.95965316984802 seconds)
2024-03-31 09:51:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-03-31 09:51:35 | INFO | train | epoch 011 | loss 4.755 | ppl 27 | wps 21674.6 | ups 0.08 | wpb 262103 | bsz 511.9 | num_updates 74394 | lr 0.000463758 | gnorm 0.369 | clip 0 | loss_scale 8 | train_wall 82145 | gb_free 10.7 | wall 0
2024-03-31 09:51:35 | INFO | fairseq.trainer | loading train data for epoch 12
2024-03-31 09:51:36 | INFO | fairseq.data.data_utils | loaded 52,748,000 examples from: ./data/data-bin/11/train
2024-03-31 09:51:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6774
2024-03-31 09:51:37 | INFO | fairseq.trainer | begin training epoch 12
2024-03-31 09:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2024-03-31 09:52:47 | INFO | train_inner | epoch 012:      6 / 6774 loss=4.751, ppl=26.94, wps=20795.7, ups=0.08, wpb=260178, bsz=508.2, num_updates=74400, lr=0.000463739, gnorm=0.373, clip=0, loss_scale=8, train_wall=1176, gb_free=10.7, wall=0
2024-03-31 10:12:25 | INFO | train_inner | epoch 012:    106 / 6774 loss=4.756, ppl=27.02, wps=22243.9, ups=0.08, wpb=261939, bsz=511.6, num_updates=74500, lr=0.000463428, gnorm=0.363, clip=0, loss_scale=8, train_wall=1177, gb_free=10.7, wall=0
2024-03-31 10:32:07 | INFO | train_inner | epoch 012:    206 / 6774 loss=4.758, ppl=27.05, wps=22166.7, ups=0.08, wpb=262144, bsz=512, num_updates=74600, lr=0.000463117, gnorm=0.365, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-31 10:51:52 | INFO | train_inner | epoch 012:    306 / 6774 loss=4.754, ppl=26.99, wps=22132.4, ups=0.08, wpb=262144, bsz=512, num_updates=74700, lr=0.000462807, gnorm=0.363, clip=0, loss_scale=8, train_wall=1184, gb_free=10.7, wall=0
2024-03-31 11:11:34 | INFO | train_inner | epoch 012:    406 / 6774 loss=4.754, ppl=26.99, wps=22167.4, ups=0.08, wpb=262144, bsz=512, num_updates=74800, lr=0.000462497, gnorm=0.366, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-31 11:31:15 | INFO | train_inner | epoch 012:    506 / 6774 loss=4.749, ppl=26.9, wps=22191.5, ups=0.08, wpb=262144, bsz=512, num_updates=74900, lr=0.000462188, gnorm=0.366, clip=0, loss_scale=8, train_wall=1181, gb_free=10.7, wall=0
2024-03-31 11:51:02 | INFO | train_inner | epoch 012:    606 / 6774 loss=4.752, ppl=26.95, wps=22099.6, ups=0.08, wpb=262144, bsz=512, num_updates=75000, lr=0.00046188, gnorm=0.373, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-31 11:51:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 75000 updates
2024-03-31 11:51:02 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_75000.pt
2024-03-31 11:51:17 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_75000.pt
2024-03-31 11:51:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_75000.pt (epoch 12 @ 75000 updates, score None) (writing took 44.15025555016473 seconds)
2024-03-31 12:11:29 | INFO | train_inner | epoch 012:    706 / 6774 loss=4.751, ppl=26.93, wps=21354.5, ups=0.08, wpb=262144, bsz=512, num_updates=75100, lr=0.000461573, gnorm=0.379, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-31 12:31:15 | INFO | train_inner | epoch 012:    806 / 6774 loss=4.754, ppl=26.99, wps=22104.9, ups=0.08, wpb=262144, bsz=512, num_updates=75200, lr=0.000461266, gnorm=0.378, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-31 12:51:01 | INFO | train_inner | epoch 012:    906 / 6774 loss=4.752, ppl=26.95, wps=22098.5, ups=0.08, wpb=262144, bsz=512, num_updates=75300, lr=0.000460959, gnorm=0.363, clip=0, loss_scale=8, train_wall=1186, gb_free=10.7, wall=0
2024-03-31 13:10:43 | INFO | train_inner | epoch 012:   1006 / 6774 loss=4.755, ppl=27.01, wps=22180.6, ups=0.08, wpb=262144, bsz=512, num_updates=75400, lr=0.000460653, gnorm=0.372, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-31 13:31:08 | INFO | train_inner | epoch 012:   1106 / 6774 loss=4.754, ppl=26.99, wps=21403.3, ups=0.08, wpb=262144, bsz=512, num_updates=75500, lr=0.000460348, gnorm=0.371, clip=0, loss_scale=8, train_wall=1225, gb_free=10.7, wall=0
2024-03-31 13:51:24 | INFO | train_inner | epoch 012:   1206 / 6774 loss=4.75, ppl=26.92, wps=21561.2, ups=0.08, wpb=262144, bsz=512, num_updates=75600, lr=0.000460044, gnorm=0.372, clip=0, loss_scale=8, train_wall=1216, gb_free=10.7, wall=0
2024-03-31 14:11:33 | INFO | train_inner | epoch 012:   1306 / 6774 loss=4.754, ppl=26.99, wps=21683.3, ups=0.08, wpb=262144, bsz=512, num_updates=75700, lr=0.00045974, gnorm=0.382, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-03-31 14:31:18 | INFO | train_inner | epoch 012:   1406 / 6774 loss=4.751, ppl=26.93, wps=22126.3, ups=0.08, wpb=262144, bsz=512, num_updates=75800, lr=0.000459436, gnorm=0.37, clip=0, loss_scale=8, train_wall=1185, gb_free=10.7, wall=0
2024-03-31 14:50:59 | INFO | train_inner | epoch 012:   1506 / 6774 loss=4.753, ppl=26.97, wps=22196.6, ups=0.08, wpb=262144, bsz=512, num_updates=75900, lr=0.000459134, gnorm=0.372, clip=0, loss_scale=8, train_wall=1181, gb_free=10.7, wall=0
2024-03-31 15:10:42 | INFO | train_inner | epoch 012:   1606 / 6774 loss=4.753, ppl=26.96, wps=22159.8, ups=0.08, wpb=262144, bsz=512, num_updates=76000, lr=0.000458831, gnorm=0.37, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-31 15:30:21 | INFO | train_inner | epoch 012:   1706 / 6774 loss=4.752, ppl=26.94, wps=22227, ups=0.08, wpb=262144, bsz=512, num_updates=76100, lr=0.00045853, gnorm=0.363, clip=0, loss_scale=8, train_wall=1179, gb_free=10.7, wall=0
2024-03-31 15:50:02 | INFO | train_inner | epoch 012:   1806 / 6774 loss=4.754, ppl=26.99, wps=22200, ups=0.08, wpb=262144, bsz=512, num_updates=76200, lr=0.000458229, gnorm=0.365, clip=0, loss_scale=8, train_wall=1181, gb_free=10.7, wall=0
2024-03-31 16:09:45 | INFO | train_inner | epoch 012:   1906 / 6774 loss=4.755, ppl=27.01, wps=22159.9, ups=0.08, wpb=262144, bsz=512, num_updates=76300, lr=0.000457929, gnorm=0.376, clip=0, loss_scale=8, train_wall=1183, gb_free=10.7, wall=0
2024-03-31 16:29:24 | INFO | train_inner | epoch 012:   2006 / 6774 loss=4.757, ppl=27.04, wps=22228.6, ups=0.08, wpb=262144, bsz=512, num_updates=76400, lr=0.000457629, gnorm=0.372, clip=0, loss_scale=8, train_wall=1179, gb_free=10.7, wall=0
2024-03-31 16:49:03 | INFO | train_inner | epoch 012:   2106 / 6774 loss=4.757, ppl=27.04, wps=22240.9, ups=0.08, wpb=262144, bsz=512, num_updates=76500, lr=0.00045733, gnorm=0.38, clip=0, loss_scale=8, train_wall=1178, gb_free=10.7, wall=0
2024-03-31 17:08:42 | INFO | train_inner | epoch 012:   2206 / 6774 loss=4.752, ppl=26.94, wps=22221.4, ups=0.08, wpb=262144, bsz=512, num_updates=76600, lr=0.000457031, gnorm=0.373, clip=0, loss_scale=8, train_wall=1179, gb_free=10.7, wall=0
2024-03-31 17:28:24 | INFO | train_inner | epoch 012:   2306 / 6774 loss=4.75, ppl=26.92, wps=22195, ups=0.08, wpb=262144, bsz=512, num_updates=76700, lr=0.000456733, gnorm=0.37, clip=0, loss_scale=8, train_wall=1181, gb_free=10.7, wall=0
2024-03-31 17:48:08 | INFO | train_inner | epoch 012:   2406 / 6774 loss=4.749, ppl=26.89, wps=22135.7, ups=0.08, wpb=262144, bsz=512, num_updates=76800, lr=0.000456435, gnorm=0.365, clip=0, loss_scale=8, train_wall=1184, gb_free=10.7, wall=0
2024-03-31 18:07:45 | INFO | train_inner | epoch 012:   2506 / 6774 loss=4.749, ppl=26.89, wps=22271.8, ups=0.08, wpb=262144, bsz=512, num_updates=76900, lr=0.000456139, gnorm=0.384, clip=0, loss_scale=8, train_wall=1177, gb_free=10.7, wall=0
2024-03-31 18:27:25 | INFO | train_inner | epoch 012:   2606 / 6774 loss=4.751, ppl=26.94, wps=22213.7, ups=0.08, wpb=262144, bsz=512, num_updates=77000, lr=0.000455842, gnorm=0.376, clip=0, loss_scale=8, train_wall=1180, gb_free=10.7, wall=0
2024-03-31 18:46:59 | INFO | train_inner | epoch 012:   2706 / 6774 loss=4.754, ppl=26.97, wps=22324.2, ups=0.09, wpb=262144, bsz=512, num_updates=77100, lr=0.000455547, gnorm=0.367, clip=0, loss_scale=8, train_wall=1174, gb_free=10.7, wall=0
2024-03-31 19:06:35 | INFO | train_inner | epoch 012:   2806 / 6774 loss=4.756, ppl=27.02, wps=22290.5, ups=0.09, wpb=262144, bsz=512, num_updates=77200, lr=0.000455251, gnorm=0.374, clip=0, loss_scale=8, train_wall=1176, gb_free=10.7, wall=0
2024-03-31 19:26:15 | INFO | train_inner | epoch 012:   2906 / 6774 loss=4.752, ppl=26.94, wps=22219.8, ups=0.08, wpb=262144, bsz=512, num_updates=77300, lr=0.000454957, gnorm=0.384, clip=0, loss_scale=8, train_wall=1180, gb_free=10.7, wall=0
2024-03-31 19:45:57 | INFO | train_inner | epoch 012:   3006 / 6774 loss=4.752, ppl=26.95, wps=22174.1, ups=0.08, wpb=262144, bsz=512, num_updates=77400, lr=0.000454663, gnorm=0.374, clip=0, loss_scale=8, train_wall=1182, gb_free=10.7, wall=0
2024-03-31 20:06:36 | INFO | train_inner | epoch 012:   3106 / 6774 loss=4.746, ppl=26.84, wps=21168.1, ups=0.08, wpb=262144, bsz=512, num_updates=77500, lr=0.000454369, gnorm=0.374, clip=0, loss_scale=8, train_wall=1238, gb_free=10.7, wall=0
2024-03-31 20:27:04 | INFO | train_inner | epoch 012:   3206 / 6774 loss=4.755, ppl=27.01, wps=21347.7, ups=0.08, wpb=262144, bsz=512, num_updates=77600, lr=0.000454077, gnorm=0.389, clip=0, loss_scale=8, train_wall=1228, gb_free=10.7, wall=0
2024-03-31 20:27:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-03-31 20:47:39 | INFO | train_inner | epoch 012:   3307 / 6774 loss=4.747, ppl=26.85, wps=21217.5, ups=0.08, wpb=262144, bsz=512, num_updates=77700, lr=0.000453784, gnorm=0.386, clip=0, loss_scale=4, train_wall=1235, gb_free=10.7, wall=0
2024-03-31 21:07:46 | INFO | train_inner | epoch 012:   3407 / 6774 loss=4.748, ppl=26.88, wps=21714.5, ups=0.08, wpb=262144, bsz=512, num_updates=77800, lr=0.000453493, gnorm=0.384, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=0
2024-03-31 21:27:35 | INFO | train_inner | epoch 012:   3507 / 6774 loss=4.75, ppl=26.9, wps=22047.5, ups=0.08, wpb=262144, bsz=512, num_updates=77900, lr=0.000453201, gnorm=0.378, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=0
2024-03-31 21:47:56 | INFO | train_inner | epoch 012:   3607 / 6774 loss=4.753, ppl=26.97, wps=21479.6, ups=0.08, wpb=262144, bsz=512, num_updates=78000, lr=0.000452911, gnorm=0.375, clip=0, loss_scale=4, train_wall=1220, gb_free=10.7, wall=0
2024-03-31 22:07:49 | INFO | train_inner | epoch 012:   3707 / 6774 loss=4.747, ppl=26.86, wps=21962.5, ups=0.08, wpb=262144, bsz=512, num_updates=78100, lr=0.000452621, gnorm=0.369, clip=0, loss_scale=4, train_wall=1193, gb_free=10.7, wall=0
2024-03-31 22:28:06 | INFO | train_inner | epoch 012:   3807 / 6774 loss=4.75, ppl=26.91, wps=21543.4, ups=0.08, wpb=262144, bsz=512, num_updates=78200, lr=0.000452331, gnorm=0.368, clip=0, loss_scale=4, train_wall=1217, gb_free=10.7, wall=0
2024-03-31 22:48:15 | INFO | train_inner | epoch 012:   3907 / 6774 loss=4.754, ppl=26.99, wps=21677.9, ups=0.08, wpb=262144, bsz=512, num_updates=78300, lr=0.000452042, gnorm=0.377, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=0
2024-03-31 23:08:19 | INFO | train_inner | epoch 012:   4007 / 6774 loss=4.75, ppl=26.9, wps=21773.8, ups=0.08, wpb=262144, bsz=512, num_updates=78400, lr=0.000451754, gnorm=0.376, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=0
2024-03-31 23:28:27 | INFO | train_inner | epoch 012:   4107 / 6774 loss=4.746, ppl=26.84, wps=21711.9, ups=0.08, wpb=262144, bsz=512, num_updates=78500, lr=0.000451466, gnorm=0.38, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=0
2024-03-31 23:48:29 | INFO | train_inner | epoch 012:   4207 / 6774 loss=4.747, ppl=26.85, wps=21810.9, ups=0.08, wpb=262144, bsz=512, num_updates=78600, lr=0.000451179, gnorm=0.373, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 00:08:34 | INFO | train_inner | epoch 012:   4307 / 6774 loss=4.753, ppl=26.96, wps=21756.7, ups=0.08, wpb=262144, bsz=512, num_updates=78700, lr=0.000450892, gnorm=0.368, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=0
2024-04-01 00:28:35 | INFO | train_inner | epoch 012:   4407 / 6774 loss=4.748, ppl=26.88, wps=21819.8, ups=0.08, wpb=262144, bsz=512, num_updates=78800, lr=0.000450606, gnorm=0.379, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=0
2024-04-01 00:48:30 | INFO | train_inner | epoch 012:   4507 / 6774 loss=4.747, ppl=26.86, wps=21938.5, ups=0.08, wpb=262144, bsz=512, num_updates=78900, lr=0.00045032, gnorm=0.377, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=0
2024-04-01 01:08:27 | INFO | train_inner | epoch 012:   4607 / 6774 loss=4.744, ppl=26.8, wps=21890.2, ups=0.08, wpb=262144, bsz=512, num_updates=79000, lr=0.000450035, gnorm=0.369, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=0
2024-04-01 01:28:25 | INFO | train_inner | epoch 012:   4707 / 6774 loss=4.75, ppl=26.91, wps=21893.5, ups=0.08, wpb=262144, bsz=512, num_updates=79100, lr=0.000449751, gnorm=0.367, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=0
2024-04-01 01:48:25 | INFO | train_inner | epoch 012:   4807 / 6774 loss=4.75, ppl=26.92, wps=21839.2, ups=0.08, wpb=262144, bsz=512, num_updates=79200, lr=0.000449467, gnorm=0.381, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 02:08:28 | INFO | train_inner | epoch 012:   4907 / 6774 loss=4.747, ppl=26.86, wps=21786.6, ups=0.08, wpb=262144, bsz=512, num_updates=79300, lr=0.000449183, gnorm=0.375, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=0
2024-04-01 02:28:34 | INFO | train_inner | epoch 012:   5007 / 6774 loss=4.748, ppl=26.87, wps=21733.4, ups=0.08, wpb=262144, bsz=512, num_updates=79400, lr=0.0004489, gnorm=0.371, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 02:48:35 | INFO | train_inner | epoch 012:   5107 / 6774 loss=4.75, ppl=26.91, wps=21842.2, ups=0.08, wpb=262144, bsz=512, num_updates=79500, lr=0.000448618, gnorm=0.377, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 03:08:33 | INFO | train_inner | epoch 012:   5207 / 6774 loss=4.747, ppl=26.85, wps=21878.4, ups=0.08, wpb=262144, bsz=512, num_updates=79600, lr=0.000448336, gnorm=0.383, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=0
2024-04-01 03:28:32 | INFO | train_inner | epoch 012:   5307 / 6774 loss=4.744, ppl=26.79, wps=21856.5, ups=0.08, wpb=262144, bsz=512, num_updates=79700, lr=0.000448054, gnorm=0.377, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=0
2024-04-01 03:48:32 | INFO | train_inner | epoch 012:   5407 / 6774 loss=4.748, ppl=26.87, wps=21842, ups=0.08, wpb=262144, bsz=512, num_updates=79800, lr=0.000447774, gnorm=0.378, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 04:08:34 | INFO | train_inner | epoch 012:   5507 / 6774 loss=4.749, ppl=26.89, wps=21818.8, ups=0.08, wpb=262139, bsz=512, num_updates=79900, lr=0.000447493, gnorm=0.363, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=0
2024-04-01 04:28:36 | INFO | train_inner | epoch 012:   5607 / 6774 loss=4.751, ppl=26.92, wps=21809.2, ups=0.08, wpb=262144, bsz=512, num_updates=80000, lr=0.000447214, gnorm=0.361, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 04:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 80000 updates
2024-04-01 04:28:36 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_80000.pt
2024-04-01 04:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_80000.pt
2024-04-01 04:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_12_80000.pt (epoch 12 @ 80000 updates, score None) (writing took 44.03946948284283 seconds)
2024-04-01 04:49:27 | INFO | train_inner | epoch 012:   5707 / 6774 loss=4.744, ppl=26.81, wps=20952.1, ups=0.08, wpb=262144, bsz=512, num_updates=80100, lr=0.000446934, gnorm=0.365, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=0
2024-04-01 05:09:28 | INFO | train_inner | epoch 012:   5807 / 6774 loss=4.746, ppl=26.84, wps=21834.8, ups=0.08, wpb=262144, bsz=512, num_updates=80200, lr=0.000446656, gnorm=0.38, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 05:29:31 | INFO | train_inner | epoch 012:   5907 / 6774 loss=4.753, ppl=26.96, wps=21787, ups=0.08, wpb=262144, bsz=512, num_updates=80300, lr=0.000446377, gnorm=0.384, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=0
2024-04-01 05:49:28 | INFO | train_inner | epoch 012:   6007 / 6774 loss=4.751, ppl=26.92, wps=21904.7, ups=0.08, wpb=262144, bsz=512, num_updates=80400, lr=0.0004461, gnorm=0.377, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=0
2024-04-01 06:09:28 | INFO | train_inner | epoch 012:   6107 / 6774 loss=4.746, ppl=26.84, wps=21840, ups=0.08, wpb=262144, bsz=512, num_updates=80500, lr=0.000445823, gnorm=0.363, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 06:29:29 | INFO | train_inner | epoch 012:   6207 / 6774 loss=4.753, ppl=26.96, wps=21817.8, ups=0.08, wpb=262144, bsz=512, num_updates=80600, lr=0.000445546, gnorm=0.383, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=0
2024-04-01 06:49:31 | INFO | train_inner | epoch 012:   6307 / 6774 loss=4.747, ppl=26.85, wps=21812.8, ups=0.08, wpb=262144, bsz=512, num_updates=80700, lr=0.00044527, gnorm=0.369, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 07:09:29 | INFO | train_inner | epoch 012:   6407 / 6774 loss=4.753, ppl=26.96, wps=21876.4, ups=0.08, wpb=262144, bsz=512, num_updates=80800, lr=0.000444994, gnorm=0.365, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=0
2024-04-01 07:29:29 | INFO | train_inner | epoch 012:   6507 / 6774 loss=4.746, ppl=26.83, wps=21798.5, ups=0.08, wpb=261504, bsz=510.8, num_updates=80900, lr=0.000444719, gnorm=0.375, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=0
2024-04-01 07:49:29 | INFO | train_inner | epoch 012:   6607 / 6774 loss=4.749, ppl=26.9, wps=21845.3, ups=0.08, wpb=262144, bsz=512, num_updates=81000, lr=0.000444444, gnorm=0.388, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 08:09:29 | INFO | train_inner | epoch 012:   6707 / 6774 loss=4.748, ppl=26.86, wps=21845.6, ups=0.08, wpb=262144, bsz=512, num_updates=81100, lr=0.00044417, gnorm=0.369, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 08:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 81167 updates
2024-04-01 08:22:59 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint12.pt
2024-04-01 08:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint12.pt
2024-04-01 08:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint12.pt (epoch 12 @ 81167 updates, score None) (writing took 44.3515335698612 seconds)
2024-04-01 08:23:43 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-04-01 08:23:43 | INFO | train | epoch 012 | loss 4.751 | ppl 26.92 | wps 21881.6 | ups 0.08 | wpb 262102 | bsz 511.9 | num_updates 81167 | lr 0.000443987 | gnorm 0.374 | clip 0 | loss_scale 4 | train_wall 80980 | gb_free 10.7 | wall 0
2024-04-01 08:23:43 | INFO | fairseq.trainer | loading train data for epoch 13
2024-04-01 08:23:44 | INFO | fairseq.data.data_utils | loaded 52,714,000 examples from: ./data/data-bin/12/train
2024-04-01 08:23:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6774
2024-04-01 08:23:45 | INFO | fairseq.trainer | begin training epoch 13
2024-04-01 08:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2024-04-01 08:30:22 | INFO | train_inner | epoch 013:     33 / 6774 loss=4.745, ppl=26.81, wps=20763.2, ups=0.08, wpb=260178, bsz=508.2, num_updates=81200, lr=0.000443897, gnorm=0.38, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=0
2024-04-01 08:50:32 | INFO | train_inner | epoch 013:    133 / 6774 loss=4.744, ppl=26.8, wps=21648, ups=0.08, wpb=261980, bsz=511.7, num_updates=81300, lr=0.000443624, gnorm=0.37, clip=0, loss_scale=4, train_wall=1210, gb_free=10.7, wall=0
2024-04-01 09:10:43 | INFO | train_inner | epoch 013:    233 / 6774 loss=4.746, ppl=26.83, wps=21645.7, ups=0.08, wpb=262144, bsz=512, num_updates=81400, lr=0.000443351, gnorm=0.374, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=0
2024-04-01 09:30:53 | INFO | train_inner | epoch 013:    333 / 6774 loss=4.745, ppl=26.82, wps=21679.5, ups=0.08, wpb=262144, bsz=512, num_updates=81500, lr=0.000443079, gnorm=0.366, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=0
2024-04-01 09:50:56 | INFO | train_inner | epoch 013:    433 / 6774 loss=4.745, ppl=26.81, wps=21787.2, ups=0.08, wpb=262144, bsz=512, num_updates=81600, lr=0.000442807, gnorm=0.372, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=0
2024-04-01 10:11:08 | INFO | train_inner | epoch 013:    533 / 6774 loss=4.749, ppl=26.89, wps=21630.2, ups=0.08, wpb=262144, bsz=512, num_updates=81700, lr=0.000442536, gnorm=0.379, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-04-01 10:31:10 | INFO | train_inner | epoch 013:    633 / 6774 loss=4.743, ppl=26.78, wps=21809.7, ups=0.08, wpb=262144, bsz=512, num_updates=81800, lr=0.000442266, gnorm=0.379, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 10:51:13 | INFO | train_inner | epoch 013:    733 / 6774 loss=4.746, ppl=26.84, wps=21789.4, ups=0.08, wpb=262144, bsz=512, num_updates=81900, lr=0.000441996, gnorm=0.376, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-04-01 11:11:18 | INFO | train_inner | epoch 013:    833 / 6774 loss=4.746, ppl=26.84, wps=21749.9, ups=0.08, wpb=262144, bsz=512, num_updates=82000, lr=0.000441726, gnorm=0.372, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-04-01 11:31:24 | INFO | train_inner | epoch 013:    933 / 6774 loss=4.745, ppl=26.81, wps=21733.8, ups=0.08, wpb=262144, bsz=512, num_updates=82100, lr=0.000441457, gnorm=0.386, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 11:51:31 | INFO | train_inner | epoch 013:   1033 / 6774 loss=4.744, ppl=26.81, wps=21725.8, ups=0.08, wpb=262144, bsz=512, num_updates=82200, lr=0.000441188, gnorm=0.361, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 12:11:46 | INFO | train_inner | epoch 013:   1133 / 6774 loss=4.748, ppl=26.87, wps=21571.2, ups=0.08, wpb=262144, bsz=512, num_updates=82300, lr=0.00044092, gnorm=0.37, clip=0, loss_scale=8, train_wall=1215, gb_free=10.7, wall=0
2024-04-01 12:31:53 | INFO | train_inner | epoch 013:   1233 / 6774 loss=4.745, ppl=26.82, wps=21719.7, ups=0.08, wpb=262144, bsz=512, num_updates=82400, lr=0.000440653, gnorm=0.379, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-04-01 12:52:02 | INFO | train_inner | epoch 013:   1333 / 6774 loss=4.74, ppl=26.73, wps=21691, ups=0.08, wpb=262144, bsz=512, num_updates=82500, lr=0.000440386, gnorm=0.374, clip=0, loss_scale=8, train_wall=1208, gb_free=10.7, wall=0
2024-04-01 13:12:20 | INFO | train_inner | epoch 013:   1433 / 6774 loss=4.747, ppl=26.86, wps=21515.6, ups=0.08, wpb=262144, bsz=512, num_updates=82600, lr=0.000440119, gnorm=0.375, clip=0, loss_scale=8, train_wall=1218, gb_free=10.7, wall=0
2024-04-01 13:32:26 | INFO | train_inner | epoch 013:   1533 / 6774 loss=4.743, ppl=26.79, wps=21732.7, ups=0.08, wpb=262144, bsz=512, num_updates=82700, lr=0.000439853, gnorm=0.378, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 13:52:29 | INFO | train_inner | epoch 013:   1633 / 6774 loss=4.742, ppl=26.77, wps=21796.3, ups=0.08, wpb=262144, bsz=512, num_updates=82800, lr=0.000439587, gnorm=0.378, clip=0, loss_scale=8, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 14:12:41 | INFO | train_inner | epoch 013:   1733 / 6774 loss=4.743, ppl=26.78, wps=21630.2, ups=0.08, wpb=262144, bsz=512, num_updates=82900, lr=0.000439322, gnorm=0.384, clip=0, loss_scale=8, train_wall=1212, gb_free=10.7, wall=0
2024-04-01 14:32:47 | INFO | train_inner | epoch 013:   1833 / 6774 loss=4.747, ppl=26.85, wps=21727.5, ups=0.08, wpb=262144, bsz=512, num_updates=83000, lr=0.000439057, gnorm=0.384, clip=0, loss_scale=8, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 14:53:02 | INFO | train_inner | epoch 013:   1933 / 6774 loss=4.745, ppl=26.82, wps=21583.4, ups=0.08, wpb=262144, bsz=512, num_updates=83100, lr=0.000438793, gnorm=0.385, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-04-01 15:13:09 | INFO | train_inner | epoch 013:   2033 / 6774 loss=4.748, ppl=26.87, wps=21713.7, ups=0.08, wpb=262144, bsz=512, num_updates=83200, lr=0.000438529, gnorm=0.379, clip=0, loss_scale=8, train_wall=1207, gb_free=10.7, wall=0
2024-04-01 15:33:18 | INFO | train_inner | epoch 013:   2133 / 6774 loss=4.739, ppl=26.7, wps=21678.7, ups=0.08, wpb=262144, bsz=512, num_updates=83300, lr=0.000438266, gnorm=0.376, clip=0, loss_scale=8, train_wall=1209, gb_free=10.7, wall=0
2024-04-01 15:53:30 | INFO | train_inner | epoch 013:   2233 / 6774 loss=4.74, ppl=26.72, wps=21637.5, ups=0.08, wpb=262144, bsz=512, num_updates=83400, lr=0.000438003, gnorm=0.385, clip=0, loss_scale=8, train_wall=1211, gb_free=10.7, wall=0
2024-04-01 16:13:30 | INFO | train_inner | epoch 013:   2333 / 6774 loss=4.743, ppl=26.77, wps=21835.9, ups=0.08, wpb=262144, bsz=512, num_updates=83500, lr=0.000437741, gnorm=0.381, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-04-01 16:33:44 | INFO | train_inner | epoch 013:   2433 / 6774 loss=4.745, ppl=26.82, wps=21595.5, ups=0.08, wpb=262144, bsz=512, num_updates=83600, lr=0.000437479, gnorm=0.375, clip=0, loss_scale=8, train_wall=1214, gb_free=10.7, wall=0
2024-04-01 16:53:57 | INFO | train_inner | epoch 013:   2533 / 6774 loss=4.738, ppl=26.69, wps=21612.3, ups=0.08, wpb=262144, bsz=512, num_updates=83700, lr=0.000437217, gnorm=0.377, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-04-01 17:14:10 | INFO | train_inner | epoch 013:   2633 / 6774 loss=4.746, ppl=26.83, wps=21616.5, ups=0.08, wpb=262144, bsz=512, num_updates=83800, lr=0.000436956, gnorm=0.378, clip=0, loss_scale=8, train_wall=1213, gb_free=10.7, wall=0
2024-04-01 17:34:15 | INFO | train_inner | epoch 013:   2733 / 6774 loss=4.742, ppl=26.76, wps=21749.7, ups=0.08, wpb=262144, bsz=512, num_updates=83900, lr=0.000436696, gnorm=0.369, clip=0, loss_scale=8, train_wall=1205, gb_free=10.7, wall=0
2024-04-01 17:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-04-01 17:54:35 | INFO | train_inner | epoch 013:   2834 / 6774 loss=4.741, ppl=26.74, wps=21493.8, ups=0.08, wpb=262144, bsz=512, num_updates=84000, lr=0.000436436, gnorm=0.379, clip=0, loss_scale=4, train_wall=1219, gb_free=10.7, wall=0
2024-04-01 18:14:47 | INFO | train_inner | epoch 013:   2934 / 6774 loss=4.749, ppl=26.89, wps=21635.1, ups=0.08, wpb=262144, bsz=512, num_updates=84100, lr=0.000436176, gnorm=0.386, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=0
2024-04-01 18:34:59 | INFO | train_inner | epoch 013:   3034 / 6774 loss=4.742, ppl=26.75, wps=21616, ups=0.08, wpb=262144, bsz=512, num_updates=84200, lr=0.000435917, gnorm=0.371, clip=0, loss_scale=4, train_wall=1213, gb_free=10.7, wall=0
2024-04-01 18:55:01 | INFO | train_inner | epoch 013:   3134 / 6774 loss=4.743, ppl=26.78, wps=21808.4, ups=0.08, wpb=262144, bsz=512, num_updates=84300, lr=0.000435659, gnorm=0.38, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-01 19:15:05 | INFO | train_inner | epoch 013:   3234 / 6774 loss=4.742, ppl=26.75, wps=21771.1, ups=0.08, wpb=262144, bsz=512, num_updates=84400, lr=0.0004354, gnorm=0.378, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=0
2024-04-01 19:35:14 | INFO | train_inner | epoch 013:   3334 / 6774 loss=4.747, ppl=26.84, wps=21684.1, ups=0.08, wpb=262144, bsz=512, num_updates=84500, lr=0.000435143, gnorm=0.388, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=0
2024-04-01 19:55:23 | INFO | train_inner | epoch 013:   3434 / 6774 loss=4.742, ppl=26.75, wps=21693.2, ups=0.08, wpb=262144, bsz=512, num_updates=84600, lr=0.000434885, gnorm=0.374, clip=0, loss_scale=4, train_wall=1208, gb_free=10.7, wall=0
2024-04-01 20:15:30 | INFO | train_inner | epoch 013:   3534 / 6774 loss=4.745, ppl=26.81, wps=21719.9, ups=0.08, wpb=262144, bsz=512, num_updates=84700, lr=0.000434629, gnorm=0.379, clip=0, loss_scale=4, train_wall=1207, gb_free=10.7, wall=0
2024-04-01 20:35:44 | INFO | train_inner | epoch 013:   3634 / 6774 loss=4.739, ppl=26.71, wps=21588.2, ups=0.08, wpb=262144, bsz=512, num_updates=84800, lr=0.000434372, gnorm=0.381, clip=0, loss_scale=4, train_wall=1214, gb_free=10.7, wall=0
2024-04-01 20:55:56 | INFO | train_inner | epoch 013:   3734 / 6774 loss=4.743, ppl=26.79, wps=21619.7, ups=0.08, wpb=262144, bsz=512, num_updates=84900, lr=0.000434116, gnorm=0.368, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=0
2024-04-01 21:16:09 | INFO | train_inner | epoch 013:   3834 / 6774 loss=4.744, ppl=26.79, wps=21616.7, ups=0.08, wpb=262144, bsz=512, num_updates=85000, lr=0.000433861, gnorm=0.371, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=0
2024-04-01 21:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 85000 updates
2024-04-01 21:16:09 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_13_85000.pt
2024-04-01 21:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_13_85000.pt
2024-04-01 21:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_13_85000.pt (epoch 13 @ 85000 updates, score None) (writing took 44.29384169075638 seconds)
2024-04-01 21:36:57 | INFO | train_inner | epoch 013:   3934 / 6774 loss=4.741, ppl=26.74, wps=21001.1, ups=0.08, wpb=262144, bsz=512, num_updates=85100, lr=0.000433606, gnorm=0.381, clip=0, loss_scale=4, train_wall=1204, gb_free=10.7, wall=0
2024-04-01 21:57:10 | INFO | train_inner | epoch 013:   4034 / 6774 loss=4.74, ppl=26.73, wps=21609.6, ups=0.08, wpb=262144, bsz=512, num_updates=85200, lr=0.000433351, gnorm=0.367, clip=0, loss_scale=4, train_wall=1213, gb_free=10.7, wall=0
2024-04-01 22:17:23 | INFO | train_inner | epoch 013:   4134 / 6774 loss=4.74, ppl=26.73, wps=21628, ups=0.08, wpb=262144, bsz=512, num_updates=85300, lr=0.000433097, gnorm=0.387, clip=0, loss_scale=4, train_wall=1212, gb_free=10.7, wall=0
2024-04-01 22:37:34 | INFO | train_inner | epoch 013:   4234 / 6774 loss=4.743, ppl=26.78, wps=21640.8, ups=0.08, wpb=262144, bsz=512, num_updates=85400, lr=0.000432844, gnorm=0.381, clip=0, loss_scale=4, train_wall=1211, gb_free=10.7, wall=0
2024-04-01 22:57:40 | INFO | train_inner | epoch 013:   4334 / 6774 loss=4.74, ppl=26.73, wps=21729.3, ups=0.08, wpb=262144, bsz=512, num_updates=85500, lr=0.00043259, gnorm=0.384, clip=0, loss_scale=4, train_wall=1206, gb_free=10.7, wall=0
2024-04-01 23:17:36 | INFO | train_inner | epoch 013:   4434 / 6774 loss=4.741, ppl=26.75, wps=21916.9, ups=0.08, wpb=262144, bsz=512, num_updates=85600, lr=0.000432338, gnorm=0.372, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=0
2024-04-01 23:37:31 | INFO | train_inner | epoch 013:   4534 / 6774 loss=4.737, ppl=26.67, wps=21943.1, ups=0.08, wpb=262144, bsz=512, num_updates=85700, lr=0.000432085, gnorm=0.381, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=0
2024-04-01 23:57:34 | INFO | train_inner | epoch 013:   4634 / 6774 loss=4.741, ppl=26.74, wps=21789.7, ups=0.08, wpb=262144, bsz=512, num_updates=85800, lr=0.000431834, gnorm=0.376, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=0
2024-04-02 00:17:34 | INFO | train_inner | epoch 013:   4734 / 6774 loss=4.742, ppl=26.76, wps=21856.2, ups=0.08, wpb=262144, bsz=512, num_updates=85900, lr=0.000431582, gnorm=0.371, clip=0, loss_scale=4, train_wall=1199, gb_free=10.7, wall=0
2024-04-02 00:37:30 | INFO | train_inner | epoch 013:   4834 / 6774 loss=4.74, ppl=26.72, wps=21903.4, ups=0.08, wpb=262144, bsz=512, num_updates=86000, lr=0.000431331, gnorm=0.379, clip=0, loss_scale=4, train_wall=1197, gb_free=10.7, wall=0
2024-04-02 00:57:26 | INFO | train_inner | epoch 013:   4934 / 6774 loss=4.746, ppl=26.83, wps=21928, ups=0.08, wpb=262144, bsz=512, num_updates=86100, lr=0.000431081, gnorm=0.377, clip=0, loss_scale=4, train_wall=1195, gb_free=10.7, wall=0
2024-04-02 01:17:28 | INFO | train_inner | epoch 013:   5034 / 6774 loss=4.75, ppl=26.91, wps=21798.7, ups=0.08, wpb=262144, bsz=512, num_updates=86200, lr=0.00043083, gnorm=0.392, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-02 01:37:37 | INFO | train_inner | epoch 013:   5134 / 6774 loss=4.743, ppl=26.78, wps=21681.6, ups=0.08, wpb=262144, bsz=512, num_updates=86300, lr=0.000430581, gnorm=0.367, clip=0, loss_scale=4, train_wall=1209, gb_free=10.7, wall=0
2024-04-02 01:57:37 | INFO | train_inner | epoch 013:   5234 / 6774 loss=4.736, ppl=26.65, wps=21796.4, ups=0.08, wpb=261514, bsz=510.8, num_updates=86400, lr=0.000430331, gnorm=0.388, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-02 02:17:34 | INFO | train_inner | epoch 013:   5334 / 6774 loss=4.743, ppl=26.79, wps=21906.8, ups=0.08, wpb=262144, bsz=512, num_updates=86500, lr=0.000430083, gnorm=0.379, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=0
2024-04-02 02:37:38 | INFO | train_inner | epoch 013:   5434 / 6774 loss=4.743, ppl=26.77, wps=21779.4, ups=0.08, wpb=262144, bsz=512, num_updates=86600, lr=0.000429834, gnorm=0.379, clip=0, loss_scale=4, train_wall=1203, gb_free=10.7, wall=0
2024-04-02 02:57:34 | INFO | train_inner | epoch 013:   5534 / 6774 loss=4.746, ppl=26.84, wps=21918.5, ups=0.08, wpb=262144, bsz=512, num_updates=86700, lr=0.000429586, gnorm=0.386, clip=0, loss_scale=4, train_wall=1196, gb_free=10.7, wall=0
2024-04-02 03:17:34 | INFO | train_inner | epoch 013:   5634 / 6774 loss=4.74, ppl=26.72, wps=21834.5, ups=0.08, wpb=262144, bsz=512, num_updates=86800, lr=0.000429339, gnorm=0.361, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-02 03:37:34 | INFO | train_inner | epoch 013:   5734 / 6774 loss=4.74, ppl=26.71, wps=21844.3, ups=0.08, wpb=262144, bsz=512, num_updates=86900, lr=0.000429092, gnorm=0.387, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-02 03:57:37 | INFO | train_inner | epoch 013:   5834 / 6774 loss=4.737, ppl=26.66, wps=21801.3, ups=0.08, wpb=262144, bsz=512, num_updates=87000, lr=0.000428845, gnorm=0.38, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-02 04:17:42 | INFO | train_inner | epoch 013:   5934 / 6774 loss=4.743, ppl=26.78, wps=21743.4, ups=0.08, wpb=262144, bsz=512, num_updates=87100, lr=0.000428599, gnorm=0.377, clip=0, loss_scale=4, train_wall=1205, gb_free=10.7, wall=0
2024-04-02 04:37:37 | INFO | train_inner | epoch 013:   6034 / 6774 loss=4.739, ppl=26.71, wps=21948, ups=0.08, wpb=262144, bsz=512, num_updates=87200, lr=0.000428353, gnorm=0.374, clip=0, loss_scale=4, train_wall=1194, gb_free=10.7, wall=0
2024-04-02 04:57:34 | INFO | train_inner | epoch 013:   6134 / 6774 loss=4.738, ppl=26.68, wps=21884, ups=0.08, wpb=262144, bsz=512, num_updates=87300, lr=0.000428108, gnorm=0.374, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=0
2024-04-02 05:17:36 | INFO | train_inner | epoch 013:   6234 / 6774 loss=4.734, ppl=26.61, wps=21813.2, ups=0.08, wpb=262144, bsz=512, num_updates=87400, lr=0.000427863, gnorm=0.386, clip=0, loss_scale=4, train_wall=1202, gb_free=10.7, wall=0
2024-04-02 05:37:28 | INFO | train_inner | epoch 013:   6334 / 6774 loss=4.737, ppl=26.67, wps=21992.7, ups=0.08, wpb=262144, bsz=512, num_updates=87500, lr=0.000427618, gnorm=0.375, clip=0, loss_scale=4, train_wall=1192, gb_free=10.7, wall=0
2024-04-02 05:57:17 | INFO | train_inner | epoch 013:   6434 / 6774 loss=4.738, ppl=26.69, wps=22046.4, ups=0.08, wpb=262144, bsz=512, num_updates=87600, lr=0.000427374, gnorm=0.375, clip=0, loss_scale=4, train_wall=1189, gb_free=10.7, wall=0
2024-04-02 06:17:18 | INFO | train_inner | epoch 013:   6534 / 6774 loss=4.742, ppl=26.76, wps=21830.3, ups=0.08, wpb=262144, bsz=512, num_updates=87700, lr=0.00042713, gnorm=0.382, clip=0, loss_scale=4, train_wall=1201, gb_free=10.7, wall=0
2024-04-02 06:37:16 | INFO | train_inner | epoch 013:   6634 / 6774 loss=4.741, ppl=26.74, wps=21877.7, ups=0.08, wpb=262144, bsz=512, num_updates=87800, lr=0.000426887, gnorm=0.375, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=0
2024-04-02 06:57:17 | INFO | train_inner | epoch 013:   6734 / 6774 loss=4.734, ppl=26.62, wps=21836.4, ups=0.08, wpb=262144, bsz=512, num_updates=87900, lr=0.000426644, gnorm=0.374, clip=0, loss_scale=4, train_wall=1200, gb_free=10.7, wall=0
2024-04-02 07:05:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 87940 updates
2024-04-02 07:05:12 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint13.pt
2024-04-02 07:05:28 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint13.pt
2024-04-02 07:06:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint13.pt (epoch 13 @ 87940 updates, score None) (writing took 72.98701063729823 seconds)
2024-04-02 07:06:25 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-04-02 07:06:25 | INFO | train | epoch 013 | loss 4.743 | ppl 26.77 | wps 21712 | ups 0.08 | wpb 262103 | bsz 511.9 | num_updates 87940 | lr 0.000426547 | gnorm 0.377 | clip 0 | loss_scale 4 | train_wall 81629 | gb_free 10.7 | wall 0
2024-04-02 07:06:25 | INFO | fairseq.trainer | loading train data for epoch 14
2024-04-02 07:06:27 | INFO | fairseq.data.data_utils | loaded 52,483,000 examples from: ./data/data-bin/13/train
2024-04-02 07:06:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6745
2024-04-02 07:06:28 | INFO | fairseq.trainer | begin training epoch 14
2024-04-02 07:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2024-04-02 07:18:30 | INFO | train_inner | epoch 014:     60 / 6745 loss=4.739, ppl=26.7, wps=20436.5, ups=0.08, wpb=260178, bsz=508.2, num_updates=88000, lr=0.000426401, gnorm=0.389, clip=0, loss_scale=4, train_wall=1198, gb_free=10.7, wall=0
2024-04-02 07:38:30 | INFO | train_inner | epoch 014:    160 / 6745 loss=4.74, ppl=26.72, wps=21843.3, ups=0.08, wpb=262144, bsz=512, num_updates=88100, lr=0.000426159, gnorm=0.376, clip=0, loss_scale=8, train_wall=1200, gb_free=10.7, wall=0
2024-04-02 07:58:33 | INFO | train_inner | epoch 014:    260 / 6745 loss=4.742, ppl=26.76, wps=21789, ups=0.08, wpb=262144, bsz=512, num_updates=88200, lr=0.000425918, gnorm=0.39, clip=0, loss_scale=8, train_wall=1203, gb_free=10.7, wall=0
2024-04-02 08:09:37 | INFO | fairseq_cli.train | Stopping training due to num_updates: 88255 >= max_update: 88255
2024-04-02 08:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 88255 updates
2024-04-02 08:09:37 | INFO | fairseq.trainer | Saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_last.pt
2024-04-02 08:09:53 | INFO | fairseq.trainer | Finished saving checkpoint to ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_last.pt
2024-04-02 08:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./CHECKPOINTS/checkpoint_valmA100_40600upd_lrx4_more/checkpoint_last.pt (epoch 14 @ 88255 updates, score None) (writing took 15.328000085428357 seconds)
2024-04-02 08:09:53 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-04-02 08:09:53 | INFO | train | epoch 014 | loss 4.742 | ppl 26.76 | wps 21688.7 | ups 0.08 | wpb 262144 | bsz 512 | num_updates 88255 | lr 0.000425785 | gnorm 0.387 | clip 0 | loss_scale 8 | train_wall 3789 | gb_free 10.7 | wall 0
2024-04-02 08:09:53 | INFO | fairseq_cli.train | done training in 574598.2 seconds
Amaitu da
