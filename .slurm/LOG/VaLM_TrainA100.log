Hasi da
2024-01-16 17:18:00 | INFO | fairseq.distributed.utils | setting CUDA device=1 on rank 1
2024-01-16 17:18:00 | INFO | fairseq.distributed.utils | setting CUDA device=3 on rank 3
2024-01-16 17:18:00 | INFO | fairseq.distributed.utils | setting CUDA device=2 on rank 2
2024-01-16 17:18:00 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://
2024-01-16 17:18:00 | INFO | fairseq.distributed.utils | initialized host tximista as rank 0
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | distributed init (rank 3): env://
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | distributed init (rank 2): env://
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | initialized host tximista as rank 3
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | initialized host tximista as rank 2
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | distributed init (rank 1): env://
2024-01-16 17:18:01 | INFO | fairseq.distributed.utils | initialized host tximista as rank 1
NCCL version 2.18.1+cuda12.1
2024-01-16 17:18:13 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'VaLM-baseline', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 65536, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 65536, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 34000, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoint_valmA100', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 12, 'decoder_attention_heads': 12, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False, 'use_knn_datastore': True, 'load_knn_datastore': False, 'dstore_fp16': False, 'use_gpu_to_search': False, 'move_dstore_to_mem': False, 'dstore_size': 10000000, 'k': 8, 'probe': 32, 'dstore_filename': 'data/datastore', 'use_joint_attention': True, 'joint_layer_index': 2}, 'task': {'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
{'_name': 'language_modeling', 'data': './data/data-bin/0:./data/data-bin/1:./data/data-bin/2:./data/data-bin/3:./data/data-bin/4:./data/data-bin/5', 'sample_break_mode': none, 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': none, 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}
2024-01-16 17:18:13 | INFO | fairseq.tasks.language_modeling | dictionary: 49412 types
2024-01-16 17:18:31 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(49412, 768, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-9): 10 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerwithJointAttention(
        (dropout_module): FairseqDropout()
        (self_attn): JointMultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_k_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_v_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
          (img_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=49412, bias=False)
  )
)
2024-01-16 17:18:31 | INFO | fairseq_cli.train | task: LanguageModelingTask
2024-01-16 17:18:31 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2024-01-16 17:18:31 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2024-01-16 17:18:31 | INFO | fairseq_cli.train | num. shared model params: 124,187,136 (num. trained: 124,187,136)
2024-01-16 17:18:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-01-16 17:18:31 | INFO | fairseq.data.data_utils | loaded 5,000 examples from: ./data/data-bin/0/valid
2024-01-16 17:18:31 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-01-16 17:18:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-01-16 17:18:40 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.151 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-01-16 17:18:40 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.151 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-01-16 17:18:40 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.151 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-01-16 17:18:40 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.151 GB ; name = NVIDIA A100-SXM4-80GB                   
2024-01-16 17:18:40 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2024-01-16 17:18:40 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2024-01-16 17:18:40 | INFO | fairseq_cli.train | max tokens per device = 65536 and max sentences per device = None
2024-01-16 17:18:40 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoint_valmA100/checkpoint_last.pt
2024-01-16 17:18:40 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoint_valmA100/checkpoint_last.pt
2024-01-16 17:18:40 | INFO | fairseq.trainer | loading train data for epoch 1
2024-01-16 17:19:18 | INFO | fairseq.data.data_utils | loaded 52,891,000 examples from: ./data/data-bin/0/train
2024-01-16 17:19:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6796
2024-01-16 17:19:22 | INFO | fairseq.trainer | begin training epoch 1
2024-01-16 17:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-16 17:19:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2024-01-16 17:19:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2024-01-16 17:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2024-01-16 17:20:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2024-01-16 17:20:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-16 17:42:25 | INFO | train_inner | epoch 001:    105 / 6796 loss=12.437, ppl=5545.04, wps=20164.3, ups=0.08, wpb=262144, bsz=512, num_updates=100, lr=0.000125098, gnorm=10.364, clip=75, loss_scale=4, train_wall=1383, gb_free=10.5, wall=1425
2024-01-16 18:04:05 | INFO | train_inner | epoch 001:    205 / 6796 loss=9, ppl=512.03, wps=20163.1, ups=0.08, wpb=262144, bsz=512, num_updates=200, lr=0.000250095, gnorm=1.759, clip=26, loss_scale=4, train_wall=1300, gb_free=10.5, wall=2725
2024-01-16 18:25:38 | INFO | train_inner | epoch 001:    305 / 6796 loss=8.251, ppl=304.6, wps=20279.2, ups=0.08, wpb=262144, bsz=512, num_updates=300, lr=0.000375093, gnorm=2.107, clip=44, loss_scale=4, train_wall=1292, gb_free=10.5, wall=4018
2024-01-16 18:46:53 | INFO | train_inner | epoch 001:    405 / 6796 loss=7.771, ppl=218.42, wps=20555.3, ups=0.08, wpb=262144, bsz=512, num_updates=400, lr=0.00050009, gnorm=1.689, clip=23, loss_scale=4, train_wall=1275, gb_free=10.5, wall=5293
2024-01-16 19:08:15 | INFO | train_inner | epoch 001:    505 / 6796 loss=7.337, ppl=161.65, wps=20447.5, ups=0.08, wpb=262144, bsz=512, num_updates=500, lr=0.000625087, gnorm=1.571, clip=12, loss_scale=4, train_wall=1282, gb_free=10.5, wall=6575
2024-01-16 19:29:28 | INFO | train_inner | epoch 001:    605 / 6796 loss=6.977, ppl=125.96, wps=20591.6, ups=0.08, wpb=262144, bsz=512, num_updates=600, lr=0.000750085, gnorm=1.345, clip=2, loss_scale=4, train_wall=1273, gb_free=10.5, wall=7848
2024-01-16 19:50:38 | INFO | train_inner | epoch 001:    705 / 6796 loss=6.701, ppl=104.01, wps=20593.3, ups=0.08, wpb=261530, bsz=510.8, num_updates=700, lr=0.000875082, gnorm=1.256, clip=0, loss_scale=4, train_wall=1270, gb_free=10.5, wall=9118
2024-01-16 20:11:48 | INFO | train_inner | epoch 001:    805 / 6796 loss=6.479, ppl=89.2, wps=20643.8, ups=0.08, wpb=262144, bsz=512, num_updates=800, lr=0.00100008, gnorm=1.123, clip=1, loss_scale=4, train_wall=1270, gb_free=10.5, wall=10388
2024-01-16 20:32:53 | INFO | train_inner | epoch 001:    905 / 6796 loss=6.289, ppl=78.19, wps=20726.8, ups=0.08, wpb=262144, bsz=512, num_updates=900, lr=0.00112508, gnorm=1.058, clip=0, loss_scale=4, train_wall=1265, gb_free=10.5, wall=11653
2024-01-16 20:54:02 | INFO | train_inner | epoch 001:   1005 / 6796 loss=6.13, ppl=70.03, wps=20661.3, ups=0.08, wpb=262144, bsz=512, num_updates=1000, lr=0.00125008, gnorm=0.942, clip=0, loss_scale=4, train_wall=1269, gb_free=10.5, wall=12922
2024-01-16 21:15:08 | INFO | train_inner | epoch 001:   1105 / 6796 loss=6.011, ppl=64.51, wps=20708.5, ups=0.08, wpb=262144, bsz=512, num_updates=1100, lr=0.00137507, gnorm=0.883, clip=0, loss_scale=4, train_wall=1266, gb_free=10.5, wall=14187
2024-01-16 21:36:22 | INFO | train_inner | epoch 001:   1205 / 6796 loss=5.956, ppl=62.07, wps=20571.3, ups=0.08, wpb=262144, bsz=512, num_updates=1200, lr=0.00150007, gnorm=0.961, clip=4, loss_scale=4, train_wall=1274, gb_free=10.5, wall=15462
2024-01-16 21:57:30 | INFO | train_inner | epoch 001:   1305 / 6796 loss=5.864, ppl=58.24, wps=20679.5, ups=0.08, wpb=262144, bsz=512, num_updates=1300, lr=0.00162507, gnorm=0.805, clip=0, loss_scale=4, train_wall=1267, gb_free=10.5, wall=16729
2024-01-16 22:18:41 | INFO | train_inner | epoch 001:   1405 / 6796 loss=5.797, ppl=55.59, wps=20619.8, ups=0.08, wpb=262144, bsz=512, num_updates=1400, lr=0.00175007, gnorm=0.757, clip=0, loss_scale=4, train_wall=1271, gb_free=10.5, wall=18001
2024-01-16 22:39:53 | INFO | train_inner | epoch 001:   1505 / 6796 loss=5.745, ppl=53.65, wps=20611.2, ups=0.08, wpb=262144, bsz=512, num_updates=1500, lr=0.00187506, gnorm=0.755, clip=0, loss_scale=4, train_wall=1272, gb_free=10.5, wall=19273
2024-01-16 23:01:01 | INFO | train_inner | epoch 001:   1605 / 6796 loss=5.708, ppl=52.27, wps=20667, ups=0.08, wpb=262144, bsz=512, num_updates=1600, lr=0.00200006, gnorm=0.771, clip=1, loss_scale=4, train_wall=1268, gb_free=10.5, wall=20541
2024-01-16 23:22:32 | INFO | train_inner | epoch 001:   1705 / 6796 loss=5.685, ppl=51.45, wps=20305.6, ups=0.08, wpb=262144, bsz=512, num_updates=1700, lr=0.00212506, gnorm=0.738, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=21832
2024-01-16 23:44:10 | INFO | train_inner | epoch 001:   1805 / 6796 loss=5.636, ppl=49.73, wps=20194.8, ups=0.08, wpb=262144, bsz=512, num_updates=1800, lr=0.00225005, gnorm=0.696, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=23130
2024-01-17 00:05:50 | INFO | train_inner | epoch 001:   1905 / 6796 loss=5.615, ppl=49.02, wps=20171.6, ups=0.08, wpb=262144, bsz=512, num_updates=1900, lr=0.00237505, gnorm=0.738, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=24430
2024-01-17 00:27:33 | INFO | train_inner | epoch 001:   2005 / 6796 loss=5.575, ppl=47.69, wps=20116.2, ups=0.08, wpb=262144, bsz=512, num_updates=2000, lr=0.00250005, gnorm=0.638, clip=0, loss_scale=4, train_wall=1303, gb_free=10.5, wall=25733
2024-01-17 00:49:11 | INFO | train_inner | epoch 001:   2105 / 6796 loss=5.553, ppl=46.95, wps=20192.9, ups=0.08, wpb=262144, bsz=512, num_updates=2100, lr=0.00262505, gnorm=0.644, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=27031
2024-01-17 01:10:51 | INFO | train_inner | epoch 001:   2205 / 6796 loss=5.534, ppl=46.33, wps=20168.7, ups=0.08, wpb=262144, bsz=512, num_updates=2200, lr=0.00275005, gnorm=0.618, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=28331
2024-01-17 01:32:37 | INFO | train_inner | epoch 001:   2305 / 6796 loss=5.515, ppl=45.71, wps=20071.4, ups=0.08, wpb=262144, bsz=512, num_updates=2300, lr=0.00287504, gnorm=0.602, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=29637
2024-01-17 01:54:34 | INFO | train_inner | epoch 001:   2405 / 6796 loss=5.493, ppl=45.02, wps=19908.2, ups=0.08, wpb=262144, bsz=512, num_updates=2400, lr=0.00300004, gnorm=0.576, clip=0, loss_scale=4, train_wall=1317, gb_free=10.5, wall=30954
2024-01-17 02:16:30 | INFO | train_inner | epoch 001:   2505 / 6796 loss=5.475, ppl=44.48, wps=19918.9, ups=0.08, wpb=262144, bsz=512, num_updates=2500, lr=0.00312504, gnorm=0.549, clip=0, loss_scale=4, train_wall=1316, gb_free=10.5, wall=32270
2024-01-17 02:38:34 | INFO | train_inner | epoch 001:   2605 / 6796 loss=5.46, ppl=44.03, wps=19802.7, ups=0.08, wpb=262144, bsz=512, num_updates=2600, lr=0.00325004, gnorm=0.519, clip=0, loss_scale=4, train_wall=1324, gb_free=10.5, wall=33593
2024-01-17 03:00:35 | INFO | train_inner | epoch 001:   2705 / 6796 loss=5.446, ppl=43.58, wps=19838.3, ups=0.08, wpb=262144, bsz=512, num_updates=2700, lr=0.00337503, gnorm=0.512, clip=0, loss_scale=4, train_wall=1321, gb_free=10.5, wall=34915
2024-01-17 03:22:37 | INFO | train_inner | epoch 001:   2805 / 6796 loss=5.436, ppl=43.3, wps=19830, ups=0.08, wpb=262144, bsz=512, num_updates=2800, lr=0.00350003, gnorm=0.482, clip=0, loss_scale=4, train_wall=1322, gb_free=10.5, wall=36237
2024-01-17 03:44:49 | INFO | train_inner | epoch 001:   2905 / 6796 loss=5.419, ppl=42.77, wps=19674, ups=0.08, wpb=262144, bsz=512, num_updates=2900, lr=0.00362503, gnorm=0.462, clip=0, loss_scale=4, train_wall=1332, gb_free=10.5, wall=37569
2024-01-17 04:06:52 | INFO | train_inner | epoch 001:   3005 / 6796 loss=5.404, ppl=42.33, wps=19822.4, ups=0.08, wpb=262144, bsz=512, num_updates=3000, lr=0.00375003, gnorm=0.446, clip=0, loss_scale=4, train_wall=1322, gb_free=10.5, wall=38892
2024-01-17 04:28:46 | INFO | train_inner | epoch 001:   3105 / 6796 loss=5.395, ppl=42.07, wps=19950.5, ups=0.08, wpb=262144, bsz=512, num_updates=3100, lr=0.00387502, gnorm=0.441, clip=0, loss_scale=4, train_wall=1314, gb_free=10.5, wall=40206
2024-01-17 04:50:39 | INFO | train_inner | epoch 001:   3205 / 6796 loss=5.383, ppl=41.73, wps=19965.9, ups=0.08, wpb=262144, bsz=512, num_updates=3200, lr=0.00400002, gnorm=0.421, clip=0, loss_scale=4, train_wall=1313, gb_free=10.5, wall=41519
2024-01-17 05:12:32 | INFO | train_inner | epoch 001:   3305 / 6796 loss=5.369, ppl=41.31, wps=19967.2, ups=0.08, wpb=262144, bsz=512, num_updates=3300, lr=0.00412502, gnorm=0.409, clip=0, loss_scale=4, train_wall=1313, gb_free=10.5, wall=42831
2024-01-17 05:34:25 | INFO | train_inner | epoch 001:   3405 / 6796 loss=5.362, ppl=41.11, wps=19960, ups=0.08, wpb=262144, bsz=512, num_updates=3400, lr=0.00425002, gnorm=0.405, clip=0, loss_scale=4, train_wall=1313, gb_free=10.5, wall=44145
2024-01-17 05:56:06 | INFO | train_inner | epoch 001:   3505 / 6796 loss=5.358, ppl=41, wps=20156.4, ups=0.08, wpb=262144, bsz=512, num_updates=3500, lr=0.00437501, gnorm=0.395, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=45445
2024-01-17 06:17:28 | INFO | train_inner | epoch 001:   3605 / 6796 loss=5.347, ppl=40.7, wps=20435.2, ups=0.08, wpb=262144, bsz=512, num_updates=3600, lr=0.00450001, gnorm=0.399, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=46728
2024-01-17 06:38:44 | INFO | train_inner | epoch 001:   3705 / 6796 loss=5.336, ppl=40.38, wps=20549.6, ups=0.08, wpb=262144, bsz=512, num_updates=3700, lr=0.00462501, gnorm=0.381, clip=0, loss_scale=4, train_wall=1275, gb_free=10.5, wall=48004
2024-01-17 07:00:07 | INFO | train_inner | epoch 001:   3805 / 6796 loss=5.328, ppl=40.18, wps=20440, ups=0.08, wpb=262141, bsz=512, num_updates=3800, lr=0.00475001, gnorm=0.373, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=49286
2024-01-17 07:21:26 | INFO | train_inner | epoch 001:   3905 / 6796 loss=5.323, ppl=40.03, wps=20491.4, ups=0.08, wpb=262144, bsz=512, num_updates=3900, lr=0.004875, gnorm=0.408, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=50566
2024-01-17 07:43:07 | INFO | train_inner | epoch 001:   4005 / 6796 loss=5.311, ppl=39.7, wps=20146.8, ups=0.08, wpb=262144, bsz=512, num_updates=4000, lr=0.005, gnorm=0.404, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=51867
2024-01-17 08:04:38 | INFO | train_inner | epoch 001:   4105 / 6796 loss=5.298, ppl=39.33, wps=20302.4, ups=0.08, wpb=262144, bsz=512, num_updates=4100, lr=0.00493865, gnorm=0.386, clip=0, loss_scale=8, train_wall=1291, gb_free=10.5, wall=53158
2024-01-17 08:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-17 08:26:08 | INFO | train_inner | epoch 001:   4206 / 6796 loss=5.288, ppl=39.07, wps=20318.9, ups=0.08, wpb=262144, bsz=512, num_updates=4200, lr=0.0048795, gnorm=0.39, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=54448
2024-01-17 08:47:32 | INFO | train_inner | epoch 001:   4306 / 6796 loss=5.276, ppl=38.73, wps=20416.7, ups=0.08, wpb=262144, bsz=512, num_updates=4300, lr=0.00482243, gnorm=0.371, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=55732
2024-01-17 09:08:56 | INFO | train_inner | epoch 001:   4406 / 6796 loss=5.262, ppl=38.37, wps=20414.8, ups=0.08, wpb=262144, bsz=512, num_updates=4400, lr=0.00476731, gnorm=0.376, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=57016
2024-01-17 09:30:17 | INFO | train_inner | epoch 001:   4506 / 6796 loss=5.248, ppl=37.99, wps=20475.4, ups=0.08, wpb=262144, bsz=512, num_updates=4500, lr=0.00471405, gnorm=0.408, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=58297
2024-01-17 09:51:30 | INFO | train_inner | epoch 001:   4606 / 6796 loss=5.242, ppl=37.85, wps=20582.6, ups=0.08, wpb=262144, bsz=512, num_updates=4600, lr=0.00466252, gnorm=0.39, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=59570
2024-01-17 10:12:49 | INFO | train_inner | epoch 001:   4706 / 6796 loss=5.233, ppl=37.61, wps=20506.6, ups=0.08, wpb=262144, bsz=512, num_updates=4700, lr=0.00461266, gnorm=0.387, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=60848
2024-01-17 10:34:09 | INFO | train_inner | epoch 001:   4806 / 6796 loss=5.22, ppl=37.27, wps=20473.4, ups=0.08, wpb=262144, bsz=512, num_updates=4800, lr=0.00456435, gnorm=0.358, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=62129
2024-01-17 10:55:41 | INFO | train_inner | epoch 001:   4906 / 6796 loss=5.214, ppl=37.11, wps=20292.2, ups=0.08, wpb=262144, bsz=512, num_updates=4900, lr=0.00451754, gnorm=0.39, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=63421
2024-01-17 11:17:11 | INFO | train_inner | epoch 001:   5006 / 6796 loss=5.199, ppl=36.74, wps=20317, ups=0.08, wpb=262144, bsz=512, num_updates=5000, lr=0.00447214, gnorm=0.394, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=64711
2024-01-17 11:17:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 5000 updates
2024-01-17 11:17:11 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_1_5000.pt
2024-01-17 11:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_1_5000.pt
2024-01-17 11:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score None) (writing took 43.58025847199315 seconds)
2024-01-17 11:39:31 | INFO | train_inner | epoch 001:   5106 / 6796 loss=5.19, ppl=36.51, wps=19565.3, ups=0.07, wpb=262144, bsz=512, num_updates=5100, lr=0.00442807, gnorm=0.385, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=66051
2024-01-17 12:01:08 | INFO | train_inner | epoch 001:   5206 / 6796 loss=5.185, ppl=36.38, wps=20211.3, ups=0.08, wpb=262144, bsz=512, num_updates=5200, lr=0.00438529, gnorm=0.367, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=67348
2024-01-17 12:22:56 | INFO | train_inner | epoch 001:   5306 / 6796 loss=5.176, ppl=36.14, wps=20047.3, ups=0.08, wpb=262144, bsz=512, num_updates=5300, lr=0.00434372, gnorm=0.399, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=68655
2024-01-17 12:44:44 | INFO | train_inner | epoch 001:   5406 / 6796 loss=5.176, ppl=36.15, wps=20032.7, ups=0.08, wpb=262144, bsz=512, num_updates=5400, lr=0.00430331, gnorm=0.387, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=69964
2024-01-17 13:06:31 | INFO | train_inner | epoch 001:   5506 / 6796 loss=5.162, ppl=35.79, wps=20069.8, ups=0.08, wpb=262144, bsz=512, num_updates=5500, lr=0.00426401, gnorm=0.405, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=71270
2024-01-17 13:28:15 | INFO | train_inner | epoch 001:   5606 / 6796 loss=5.158, ppl=35.7, wps=20099.3, ups=0.08, wpb=262144, bsz=512, num_updates=5600, lr=0.00422577, gnorm=0.409, clip=0, loss_scale=4, train_wall=1304, gb_free=10.5, wall=72574
2024-01-17 13:49:41 | INFO | train_inner | epoch 001:   5706 / 6796 loss=5.149, ppl=35.49, wps=20387.5, ups=0.08, wpb=262144, bsz=512, num_updates=5700, lr=0.00418854, gnorm=0.38, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=73860
2024-01-17 14:10:58 | INFO | train_inner | epoch 001:   5806 / 6796 loss=5.144, ppl=35.36, wps=20475.1, ups=0.08, wpb=261524, bsz=510.8, num_updates=5800, lr=0.00415227, gnorm=0.368, clip=0, loss_scale=4, train_wall=1277, gb_free=10.5, wall=75138
2024-01-17 14:32:38 | INFO | train_inner | epoch 001:   5906 / 6796 loss=5.137, ppl=35.2, wps=20156.4, ups=0.08, wpb=262144, bsz=512, num_updates=5900, lr=0.00411693, gnorm=0.369, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=76438
2024-01-17 14:54:24 | INFO | train_inner | epoch 001:   6006 / 6796 loss=5.132, ppl=35.08, wps=20083.2, ups=0.08, wpb=262144, bsz=512, num_updates=6000, lr=0.00408248, gnorm=0.4, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=77743
2024-01-17 15:15:59 | INFO | train_inner | epoch 001:   6106 / 6796 loss=5.125, ppl=34.9, wps=20241.6, ups=0.08, wpb=262144, bsz=512, num_updates=6100, lr=0.00404888, gnorm=0.425, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=79038
2024-01-17 15:37:15 | INFO | train_inner | epoch 001:   6206 / 6796 loss=5.12, ppl=34.77, wps=20534.2, ups=0.08, wpb=262144, bsz=512, num_updates=6200, lr=0.0040161, gnorm=0.401, clip=0, loss_scale=4, train_wall=1276, gb_free=10.5, wall=80315
2024-01-17 15:58:28 | INFO | train_inner | epoch 001:   6306 / 6796 loss=5.118, ppl=34.72, wps=20591.4, ups=0.08, wpb=262144, bsz=512, num_updates=6300, lr=0.0039841, gnorm=0.408, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=81588
2024-01-17 16:19:42 | INFO | train_inner | epoch 001:   6406 / 6796 loss=5.106, ppl=34.44, wps=20584.9, ups=0.08, wpb=262144, bsz=512, num_updates=6400, lr=0.00395285, gnorm=0.404, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=82862
2024-01-17 16:41:04 | INFO | train_inner | epoch 001:   6506 / 6796 loss=5.101, ppl=34.32, wps=20442.6, ups=0.08, wpb=262144, bsz=512, num_updates=6500, lr=0.00392232, gnorm=0.426, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=84144
2024-01-17 17:02:31 | INFO | train_inner | epoch 001:   6606 / 6796 loss=5.103, ppl=34.36, wps=20378.5, ups=0.08, wpb=262144, bsz=512, num_updates=6600, lr=0.00389249, gnorm=0.408, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=85430
2024-01-17 17:23:57 | INFO | train_inner | epoch 001:   6706 / 6796 loss=5.097, ppl=34.23, wps=20386.1, ups=0.08, wpb=262144, bsz=512, num_updates=6700, lr=0.00386334, gnorm=0.379, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=86716
2024-01-17 17:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 6790 updates
2024-01-17 17:43:42 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint1.pt
2024-01-17 17:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint1.pt
2024-01-17 17:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint1.pt (epoch 1 @ 6790 updates, score None) (writing took 75.64092267699016 seconds)
2024-01-17 17:44:58 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-01-17 17:44:58 | INFO | train | epoch 001 | loss 5.709 | ppl 52.31 | wps 20258.6 | ups 0.08 | wpb 262116 | bsz 511.9 | num_updates 6790 | lr 0.00383765 | gnorm 0.756 | clip 2.8 | loss_scale 4 | train_wall 87803 | gb_free 10.5 | wall 87978
2024-01-17 17:44:58 | INFO | fairseq.trainer | loading train data for epoch 2
2024-01-17 17:44:58 | INFO | fairseq.data.data_utils | loaded 52,734,000 examples from: ./data/data-bin/1/train
2024-01-17 17:44:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6776
2024-01-17 17:44:59 | INFO | fairseq.trainer | begin training epoch 2
2024-01-17 17:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-17 17:47:10 | INFO | train_inner | epoch 002:     10 / 6776 loss=5.093, ppl=34.12, wps=18761, ups=0.07, wpb=261489, bsz=510.7, num_updates=6800, lr=0.00383482, gnorm=0.418, clip=0, loss_scale=4, train_wall=1317, gb_free=10.5, wall=88110
2024-01-17 18:08:46 | INFO | train_inner | epoch 002:    110 / 6776 loss=5.087, ppl=33.99, wps=20234.5, ups=0.08, wpb=262144, bsz=512, num_updates=6900, lr=0.00380693, gnorm=0.405, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=89406
2024-01-17 18:30:31 | INFO | train_inner | epoch 002:    210 / 6776 loss=5.084, ppl=33.91, wps=20082, ups=0.08, wpb=262144, bsz=512, num_updates=7000, lr=0.00377964, gnorm=0.396, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=90711
2024-01-17 18:52:14 | INFO | train_inner | epoch 002:    310 / 6776 loss=5.078, ppl=33.77, wps=20124.4, ups=0.08, wpb=262144, bsz=512, num_updates=7100, lr=0.00375293, gnorm=0.425, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=92014
2024-01-17 19:13:55 | INFO | train_inner | epoch 002:    410 / 6776 loss=5.074, ppl=33.69, wps=20154.3, ups=0.08, wpb=262144, bsz=512, num_updates=7200, lr=0.00372678, gnorm=0.41, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=93314
2024-01-17 19:35:19 | INFO | train_inner | epoch 002:    510 / 6776 loss=5.076, ppl=33.73, wps=20403.3, ups=0.08, wpb=262144, bsz=512, num_updates=7300, lr=0.00370117, gnorm=0.417, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=94599
2024-01-17 19:56:39 | INFO | train_inner | epoch 002:    610 / 6776 loss=5.068, ppl=33.55, wps=20487, ups=0.08, wpb=262144, bsz=512, num_updates=7400, lr=0.00367607, gnorm=0.416, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=95879
2024-01-17 20:17:53 | INFO | train_inner | epoch 002:    710 / 6776 loss=5.061, ppl=33.39, wps=20583.2, ups=0.08, wpb=262144, bsz=512, num_updates=7500, lr=0.00365148, gnorm=0.419, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=97152
2024-01-17 20:39:13 | INFO | train_inner | epoch 002:    810 / 6776 loss=5.057, ppl=33.28, wps=20479.1, ups=0.08, wpb=262144, bsz=512, num_updates=7600, lr=0.00362738, gnorm=0.41, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=98432
2024-01-17 21:00:32 | INFO | train_inner | epoch 002:    910 / 6776 loss=5.054, ppl=33.22, wps=20497, ups=0.08, wpb=262144, bsz=512, num_updates=7700, lr=0.00360375, gnorm=0.403, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=99711
2024-01-17 21:22:04 | INFO | train_inner | epoch 002:   1010 / 6776 loss=5.053, ppl=33.2, wps=20287.4, ups=0.08, wpb=262144, bsz=512, num_updates=7800, lr=0.00358057, gnorm=0.471, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=101003
2024-01-17 21:43:37 | INFO | train_inner | epoch 002:   1110 / 6776 loss=5.05, ppl=33.12, wps=20276.3, ups=0.08, wpb=262144, bsz=512, num_updates=7900, lr=0.00355784, gnorm=0.404, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=102296
2024-01-17 22:05:06 | INFO | train_inner | epoch 002:   1210 / 6776 loss=5.044, ppl=33, wps=20331.5, ups=0.08, wpb=262144, bsz=512, num_updates=8000, lr=0.00353553, gnorm=0.444, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=103586
2024-01-17 22:26:42 | INFO | train_inner | epoch 002:   1310 / 6776 loss=5.041, ppl=32.93, wps=20232.2, ups=0.08, wpb=262144, bsz=512, num_updates=8100, lr=0.00351364, gnorm=0.399, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=104881
2024-01-17 22:48:11 | INFO | train_inner | epoch 002:   1410 / 6776 loss=5.038, ppl=32.85, wps=20324.5, ups=0.08, wpb=262144, bsz=512, num_updates=8200, lr=0.00349215, gnorm=0.405, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=106171
2024-01-17 23:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-17 23:09:54 | INFO | train_inner | epoch 002:   1511 / 6776 loss=5.037, ppl=32.84, wps=20120, ups=0.08, wpb=262144, bsz=512, num_updates=8300, lr=0.00347105, gnorm=0.441, clip=0, loss_scale=4, train_wall=1303, gb_free=10.5, wall=107474
2024-01-17 23:31:14 | INFO | train_inner | epoch 002:   1611 / 6776 loss=5.035, ppl=32.78, wps=20476.8, ups=0.08, wpb=262144, bsz=512, num_updates=8400, lr=0.00345033, gnorm=0.427, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=108754
2024-01-17 23:52:32 | INFO | train_inner | epoch 002:   1711 / 6776 loss=5.034, ppl=32.75, wps=20526.5, ups=0.08, wpb=262144, bsz=512, num_updates=8500, lr=0.00342997, gnorm=0.431, clip=0, loss_scale=4, train_wall=1277, gb_free=10.5, wall=110031
2024-01-18 00:14:04 | INFO | train_inner | epoch 002:   1811 / 6776 loss=5.029, ppl=32.65, wps=20282.9, ups=0.08, wpb=262144, bsz=512, num_updates=8600, lr=0.00340997, gnorm=0.423, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=111324
2024-01-18 00:35:30 | INFO | train_inner | epoch 002:   1911 / 6776 loss=5.031, ppl=32.7, wps=20382.7, ups=0.08, wpb=262144, bsz=512, num_updates=8700, lr=0.00339032, gnorm=0.41, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=112610
2024-01-18 00:56:57 | INFO | train_inner | epoch 002:   2011 / 6776 loss=5.024, ppl=32.54, wps=20370.1, ups=0.08, wpb=262144, bsz=512, num_updates=8800, lr=0.003371, gnorm=0.42, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=113897
2024-01-18 01:18:24 | INFO | train_inner | epoch 002:   2111 / 6776 loss=5.022, ppl=32.5, wps=20376.5, ups=0.08, wpb=262144, bsz=512, num_updates=8900, lr=0.00335201, gnorm=0.435, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=115183
2024-01-18 01:39:46 | INFO | train_inner | epoch 002:   2211 / 6776 loss=5.019, ppl=32.43, wps=20435.7, ups=0.08, wpb=262144, bsz=512, num_updates=9000, lr=0.00333333, gnorm=0.418, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=116466
2024-01-18 02:01:22 | INFO | train_inner | epoch 002:   2311 / 6776 loss=5.014, ppl=32.32, wps=20231.8, ups=0.08, wpb=262144, bsz=512, num_updates=9100, lr=0.00331497, gnorm=0.41, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=117762
2024-01-18 02:22:48 | INFO | train_inner | epoch 002:   2411 / 6776 loss=5.012, ppl=32.26, wps=20381.2, ups=0.08, wpb=262144, bsz=512, num_updates=9200, lr=0.0032969, gnorm=0.424, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=119048
2024-01-18 02:44:11 | INFO | train_inner | epoch 002:   2511 / 6776 loss=5.01, ppl=32.22, wps=20432.4, ups=0.08, wpb=262144, bsz=512, num_updates=9300, lr=0.00327913, gnorm=0.428, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=120331
2024-01-18 03:05:34 | INFO | train_inner | epoch 002:   2611 / 6776 loss=5.009, ppl=32.2, wps=20438.1, ups=0.08, wpb=262144, bsz=512, num_updates=9400, lr=0.00326164, gnorm=0.404, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=121614
2024-01-18 03:26:57 | INFO | train_inner | epoch 002:   2711 / 6776 loss=5.009, ppl=32.2, wps=20427.4, ups=0.08, wpb=262144, bsz=512, num_updates=9500, lr=0.00324443, gnorm=0.441, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=122897
2024-01-18 03:48:21 | INFO | train_inner | epoch 002:   2811 / 6776 loss=5.005, ppl=32.12, wps=20414.3, ups=0.08, wpb=262144, bsz=512, num_updates=9600, lr=0.00322749, gnorm=0.443, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=124181
2024-01-18 04:09:49 | INFO | train_inner | epoch 002:   2911 / 6776 loss=5.004, ppl=32.08, wps=20363.5, ups=0.08, wpb=262144, bsz=512, num_updates=9700, lr=0.00321081, gnorm=0.408, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=125468
2024-01-18 04:31:14 | INFO | train_inner | epoch 002:   3011 / 6776 loss=5, ppl=32, wps=20389.1, ups=0.08, wpb=262144, bsz=512, num_updates=9800, lr=0.00319438, gnorm=0.434, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=126754
2024-01-18 04:52:34 | INFO | train_inner | epoch 002:   3111 / 6776 loss=5.003, ppl=32.07, wps=20489.1, ups=0.08, wpb=262144, bsz=512, num_updates=9900, lr=0.00317821, gnorm=0.394, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=128033
2024-01-18 05:14:07 | INFO | train_inner | epoch 002:   3211 / 6776 loss=5, ppl=32, wps=20267.6, ups=0.08, wpb=262144, bsz=512, num_updates=10000, lr=0.00316228, gnorm=0.41, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=129327
2024-01-18 05:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 10000 updates
2024-01-18 05:14:07 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_2_10000.pt
2024-01-18 05:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_2_10000.pt
2024-01-18 05:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score None) (writing took 44.03700099102571 seconds)
2024-01-18 05:36:27 | INFO | train_inner | epoch 002:   3311 / 6776 loss=4.993, ppl=31.85, wps=19570.1, ups=0.07, wpb=262144, bsz=512, num_updates=10100, lr=0.00314658, gnorm=0.423, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=130666
2024-01-18 05:58:01 | INFO | train_inner | epoch 002:   3411 / 6776 loss=4.99, ppl=31.78, wps=20255.2, ups=0.08, wpb=262144, bsz=512, num_updates=10200, lr=0.00313112, gnorm=0.432, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=131961
2024-01-18 06:19:31 | INFO | train_inner | epoch 002:   3511 / 6776 loss=4.992, ppl=31.82, wps=20325.4, ups=0.08, wpb=262144, bsz=512, num_updates=10300, lr=0.00311588, gnorm=0.445, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=133250
2024-01-18 06:40:47 | INFO | train_inner | epoch 002:   3611 / 6776 loss=4.991, ppl=31.8, wps=20544.9, ups=0.08, wpb=262144, bsz=512, num_updates=10400, lr=0.00310087, gnorm=0.434, clip=0, loss_scale=4, train_wall=1276, gb_free=10.5, wall=134526
2024-01-18 07:01:57 | INFO | train_inner | epoch 002:   3711 / 6776 loss=4.987, ppl=31.71, wps=20631.1, ups=0.08, wpb=262142, bsz=512, num_updates=10500, lr=0.00308607, gnorm=0.406, clip=0, loss_scale=4, train_wall=1270, gb_free=10.5, wall=135797
2024-01-18 07:23:07 | INFO | train_inner | epoch 002:   3811 / 6776 loss=4.989, ppl=31.76, wps=20635.9, ups=0.08, wpb=262144, bsz=512, num_updates=10600, lr=0.00307148, gnorm=0.436, clip=0, loss_scale=4, train_wall=1270, gb_free=10.5, wall=137067
2024-01-18 07:44:24 | INFO | train_inner | epoch 002:   3911 / 6776 loss=4.984, ppl=31.65, wps=20541.7, ups=0.08, wpb=262144, bsz=512, num_updates=10700, lr=0.00305709, gnorm=0.434, clip=0, loss_scale=4, train_wall=1276, gb_free=10.5, wall=138343
2024-01-18 08:05:43 | INFO | train_inner | epoch 002:   4011 / 6776 loss=4.984, ppl=31.65, wps=20495.9, ups=0.08, wpb=262144, bsz=512, num_updates=10800, lr=0.0030429, gnorm=0.447, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=139622
2024-01-18 08:26:58 | INFO | train_inner | epoch 002:   4111 / 6776 loss=4.977, ppl=31.49, wps=20551.4, ups=0.08, wpb=262144, bsz=512, num_updates=10900, lr=0.00302891, gnorm=0.407, clip=0, loss_scale=4, train_wall=1275, gb_free=10.5, wall=140898
2024-01-18 08:48:09 | INFO | train_inner | epoch 002:   4211 / 6776 loss=4.983, ppl=31.62, wps=20623.7, ups=0.08, wpb=262144, bsz=512, num_updates=11000, lr=0.00301511, gnorm=0.411, clip=0, loss_scale=4, train_wall=1271, gb_free=10.5, wall=142169
2024-01-18 09:09:29 | INFO | train_inner | epoch 002:   4311 / 6776 loss=4.975, ppl=31.44, wps=20490.4, ups=0.08, wpb=262144, bsz=512, num_updates=11100, lr=0.0030015, gnorm=0.414, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=143448
2024-01-18 09:30:55 | INFO | train_inner | epoch 002:   4411 / 6776 loss=4.974, ppl=31.43, wps=20374.6, ups=0.08, wpb=262144, bsz=512, num_updates=11200, lr=0.00298807, gnorm=0.439, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=144735
2024-01-18 09:52:19 | INFO | train_inner | epoch 002:   4511 / 6776 loss=4.969, ppl=31.31, wps=20424.4, ups=0.08, wpb=262144, bsz=512, num_updates=11300, lr=0.00297482, gnorm=0.449, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=146018
2024-01-18 10:13:41 | INFO | train_inner | epoch 002:   4611 / 6776 loss=4.967, ppl=31.28, wps=20442.7, ups=0.08, wpb=262144, bsz=512, num_updates=11400, lr=0.00296174, gnorm=0.444, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=147301
2024-01-18 10:35:07 | INFO | train_inner | epoch 002:   4711 / 6776 loss=4.967, ppl=31.27, wps=20383.2, ups=0.08, wpb=262144, bsz=512, num_updates=11500, lr=0.00294884, gnorm=0.444, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=148587
2024-01-18 10:56:27 | INFO | train_inner | epoch 002:   4811 / 6776 loss=4.97, ppl=31.34, wps=20478.8, ups=0.08, wpb=262144, bsz=512, num_updates=11600, lr=0.0029361, gnorm=0.404, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=149867
2024-01-18 11:17:45 | INFO | train_inner | epoch 002:   4911 / 6776 loss=4.963, ppl=31.18, wps=20511.7, ups=0.08, wpb=262144, bsz=512, num_updates=11700, lr=0.00292353, gnorm=0.395, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=151145
2024-01-18 11:39:04 | INFO | train_inner | epoch 002:   5011 / 6776 loss=4.963, ppl=31.19, wps=20506.7, ups=0.08, wpb=262144, bsz=512, num_updates=11800, lr=0.00291111, gnorm=0.462, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=152423
2024-01-18 12:00:22 | INFO | train_inner | epoch 002:   5111 / 6776 loss=4.964, ppl=31.22, wps=20505.2, ups=0.08, wpb=262144, bsz=512, num_updates=11900, lr=0.00289886, gnorm=0.433, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=153702
2024-01-18 12:21:46 | INFO | train_inner | epoch 002:   5211 / 6776 loss=4.962, ppl=31.17, wps=20422.1, ups=0.08, wpb=262144, bsz=512, num_updates=12000, lr=0.00288675, gnorm=0.473, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=154985
2024-01-18 12:43:03 | INFO | train_inner | epoch 002:   5311 / 6776 loss=4.964, ppl=31.21, wps=20524.7, ups=0.08, wpb=262144, bsz=512, num_updates=12100, lr=0.0028748, gnorm=0.465, clip=0, loss_scale=4, train_wall=1277, gb_free=10.5, wall=156263
2024-01-18 13:04:24 | INFO | train_inner | epoch 002:   5411 / 6776 loss=4.96, ppl=31.12, wps=20462.9, ups=0.08, wpb=262144, bsz=512, num_updates=12200, lr=0.00286299, gnorm=0.434, clip=0, loss_scale=4, train_wall=1281, gb_free=10.5, wall=157544
2024-01-18 13:25:42 | INFO | train_inner | epoch 002:   5511 / 6776 loss=4.956, ppl=31.04, wps=20512.3, ups=0.08, wpb=262144, bsz=512, num_updates=12300, lr=0.00285133, gnorm=0.426, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=158822
2024-01-18 13:44:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-18 13:47:18 | INFO | train_inner | epoch 002:   5612 / 6776 loss=4.954, ppl=31, wps=20233, ups=0.08, wpb=262144, bsz=512, num_updates=12400, lr=0.00283981, gnorm=0.445, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=160117
2024-01-18 14:08:32 | INFO | train_inner | epoch 002:   5712 / 6776 loss=4.953, ppl=30.98, wps=20572.4, ups=0.08, wpb=262144, bsz=512, num_updates=12500, lr=0.00282843, gnorm=0.427, clip=0, loss_scale=4, train_wall=1274, gb_free=10.5, wall=161392
2024-01-18 14:30:01 | INFO | train_inner | epoch 002:   5812 / 6776 loss=4.954, ppl=30.99, wps=20333.5, ups=0.08, wpb=262144, bsz=512, num_updates=12600, lr=0.00281718, gnorm=0.434, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=162681
2024-01-18 14:51:31 | INFO | train_inner | epoch 002:   5912 / 6776 loss=4.954, ppl=30.99, wps=20323.9, ups=0.08, wpb=262144, bsz=512, num_updates=12700, lr=0.00280607, gnorm=0.427, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=163971
2024-01-18 15:12:55 | INFO | train_inner | epoch 002:   6012 / 6776 loss=4.946, ppl=30.82, wps=20411.6, ups=0.08, wpb=262144, bsz=512, num_updates=12800, lr=0.00279508, gnorm=0.455, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=165255
2024-01-18 15:34:32 | INFO | train_inner | epoch 002:   6112 / 6776 loss=4.947, ppl=30.85, wps=20220.1, ups=0.08, wpb=262144, bsz=512, num_updates=12900, lr=0.00278423, gnorm=0.445, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=166551
2024-01-18 15:56:05 | INFO | train_inner | epoch 002:   6212 / 6776 loss=4.948, ppl=30.86, wps=20252, ups=0.08, wpb=262021, bsz=511.8, num_updates=13000, lr=0.0027735, gnorm=0.455, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=167845
2024-01-18 16:17:31 | INFO | train_inner | epoch 002:   6312 / 6776 loss=4.95, ppl=30.9, wps=20335.2, ups=0.08, wpb=261524, bsz=510.8, num_updates=13100, lr=0.00276289, gnorm=0.398, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=169131
2024-01-18 16:39:07 | INFO | train_inner | epoch 002:   6412 / 6776 loss=4.944, ppl=30.78, wps=20234.6, ups=0.08, wpb=262144, bsz=512, num_updates=13200, lr=0.00275241, gnorm=0.463, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=170427
2024-01-18 17:00:44 | INFO | train_inner | epoch 002:   6512 / 6776 loss=4.94, ppl=30.7, wps=20215.1, ups=0.08, wpb=262144, bsz=512, num_updates=13300, lr=0.00274204, gnorm=0.455, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=171723
2024-01-18 17:22:16 | INFO | train_inner | epoch 002:   6612 / 6776 loss=4.942, ppl=30.75, wps=20284, ups=0.08, wpb=262144, bsz=512, num_updates=13400, lr=0.00273179, gnorm=0.44, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=173016
2024-01-18 17:43:53 | INFO | train_inner | epoch 002:   6712 / 6776 loss=4.942, ppl=30.74, wps=20210.7, ups=0.08, wpb=262144, bsz=512, num_updates=13500, lr=0.00272166, gnorm=0.446, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=174313
2024-01-18 17:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 13564 updates
2024-01-18 17:57:42 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint2.pt
2024-01-18 17:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint2.pt
2024-01-18 17:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint2.pt (epoch 2 @ 13564 updates, score None) (writing took 72.97530686997925 seconds)
2024-01-18 17:58:55 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-01-18 17:58:55 | INFO | train | epoch 002 | loss 4.999 | ppl 31.98 | wps 20352.6 | ups 0.08 | wpb 262104 | bsz 511.9 | num_updates 13564 | lr 0.00271523 | gnorm 0.428 | clip 0 | loss_scale 4 | train_wall 87104 | gb_free 10.5 | wall 175214
2024-01-18 17:58:55 | INFO | fairseq.trainer | loading train data for epoch 3
2024-01-18 17:58:55 | INFO | fairseq.data.data_utils | loaded 52,350,000 examples from: ./data/data-bin/2/train
2024-01-18 17:58:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6724
2024-01-18 17:58:56 | INFO | fairseq.trainer | begin training epoch 3
2024-01-18 17:58:56 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-18 18:06:47 | INFO | train_inner | epoch 003:     36 / 6724 loss=4.936, ppl=30.62, wps=18937.1, ups=0.07, wpb=260178, bsz=508.2, num_updates=13600, lr=0.00271163, gnorm=0.459, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=175687
2024-01-18 18:28:25 | INFO | train_inner | epoch 003:    136 / 6724 loss=4.942, ppl=30.73, wps=20202.5, ups=0.08, wpb=262144, bsz=512, num_updates=13700, lr=0.00270172, gnorm=0.427, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=176984
2024-01-18 18:49:59 | INFO | train_inner | epoch 003:    236 / 6724 loss=4.942, ppl=30.74, wps=20252.9, ups=0.08, wpb=262144, bsz=512, num_updates=13800, lr=0.00269191, gnorm=0.45, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=178279
2024-01-18 19:11:19 | INFO | train_inner | epoch 003:    336 / 6724 loss=4.935, ppl=30.6, wps=20473.2, ups=0.08, wpb=262144, bsz=512, num_updates=13900, lr=0.00268221, gnorm=0.459, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=179559
2024-01-18 19:32:53 | INFO | train_inner | epoch 003:    436 / 6724 loss=4.934, ppl=30.57, wps=20272.2, ups=0.08, wpb=262144, bsz=512, num_updates=14000, lr=0.00267261, gnorm=0.45, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=180852
2024-01-18 19:54:21 | INFO | train_inner | epoch 003:    536 / 6724 loss=4.932, ppl=30.53, wps=20343.8, ups=0.08, wpb=262140, bsz=512, num_updates=14100, lr=0.00266312, gnorm=0.433, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=182141
2024-01-18 20:15:54 | INFO | train_inner | epoch 003:    636 / 6724 loss=4.93, ppl=30.49, wps=20274.1, ups=0.08, wpb=262144, bsz=512, num_updates=14200, lr=0.00265372, gnorm=0.433, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=183434
2024-01-18 20:37:12 | INFO | train_inner | epoch 003:    736 / 6724 loss=4.931, ppl=30.52, wps=20513.3, ups=0.08, wpb=262144, bsz=512, num_updates=14300, lr=0.00264443, gnorm=0.428, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=184712
2024-01-18 20:58:46 | INFO | train_inner | epoch 003:    836 / 6724 loss=4.934, ppl=30.57, wps=20262.6, ups=0.08, wpb=262144, bsz=512, num_updates=14400, lr=0.00263523, gnorm=0.444, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=186006
2024-01-18 21:20:23 | INFO | train_inner | epoch 003:    936 / 6724 loss=4.93, ppl=30.49, wps=20213.9, ups=0.08, wpb=262144, bsz=512, num_updates=14500, lr=0.00262613, gnorm=0.433, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=187302
2024-01-18 21:42:02 | INFO | train_inner | epoch 003:   1036 / 6724 loss=4.929, ppl=30.45, wps=20180.4, ups=0.08, wpb=262144, bsz=512, num_updates=14600, lr=0.00261712, gnorm=0.473, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=188601
2024-01-18 22:03:43 | INFO | train_inner | epoch 003:   1136 / 6724 loss=4.93, ppl=30.47, wps=20142, ups=0.08, wpb=262144, bsz=512, num_updates=14700, lr=0.0026082, gnorm=0.437, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=189903
2024-01-18 22:25:19 | INFO | train_inner | epoch 003:   1236 / 6724 loss=4.929, ppl=30.46, wps=20225.8, ups=0.08, wpb=262144, bsz=512, num_updates=14800, lr=0.00259938, gnorm=0.408, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=191199
2024-01-18 22:46:50 | INFO | train_inner | epoch 003:   1336 / 6724 loss=4.928, ppl=30.45, wps=20304.1, ups=0.08, wpb=262144, bsz=512, num_updates=14900, lr=0.00259064, gnorm=0.462, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=192490
2024-01-18 23:08:32 | INFO | train_inner | epoch 003:   1436 / 6724 loss=4.927, ppl=30.43, wps=20136.9, ups=0.08, wpb=262144, bsz=512, num_updates=15000, lr=0.00258199, gnorm=0.451, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=193792
2024-01-18 23:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 15000 updates
2024-01-18 23:08:32 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_3_15000.pt
2024-01-18 23:08:48 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_3_15000.pt
2024-01-18 23:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_3_15000.pt (epoch 3 @ 15000 updates, score None) (writing took 44.94388670200715 seconds)
2024-01-18 23:30:59 | INFO | train_inner | epoch 003:   1536 / 6724 loss=4.923, ppl=30.34, wps=19457.2, ups=0.07, wpb=262144, bsz=512, num_updates=15100, lr=0.00257343, gnorm=0.412, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=195139
2024-01-18 23:52:37 | INFO | train_inner | epoch 003:   1636 / 6724 loss=4.924, ppl=30.36, wps=20199.3, ups=0.08, wpb=262144, bsz=512, num_updates=15200, lr=0.00256495, gnorm=0.426, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=196437
2024-01-19 00:14:14 | INFO | train_inner | epoch 003:   1736 / 6724 loss=4.922, ppl=30.32, wps=20222.7, ups=0.08, wpb=262144, bsz=512, num_updates=15300, lr=0.00255655, gnorm=0.416, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=197733
2024-01-19 00:35:49 | INFO | train_inner | epoch 003:   1836 / 6724 loss=4.922, ppl=30.31, wps=20232.7, ups=0.08, wpb=262144, bsz=512, num_updates=15400, lr=0.00254824, gnorm=0.474, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=199029
2024-01-19 00:57:27 | INFO | train_inner | epoch 003:   1936 / 6724 loss=4.921, ppl=30.3, wps=20192.7, ups=0.08, wpb=262144, bsz=512, num_updates=15500, lr=0.00254, gnorm=0.427, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=200327
2024-01-19 01:19:06 | INFO | train_inner | epoch 003:   2036 / 6724 loss=4.923, ppl=30.33, wps=20183.8, ups=0.08, wpb=262144, bsz=512, num_updates=15600, lr=0.00253185, gnorm=0.419, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=201626
2024-01-19 01:40:35 | INFO | train_inner | epoch 003:   2136 / 6724 loss=4.923, ppl=30.33, wps=20339.8, ups=0.08, wpb=262144, bsz=512, num_updates=15700, lr=0.00252377, gnorm=0.428, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=202915
2024-01-19 02:01:58 | INFO | train_inner | epoch 003:   2236 / 6724 loss=4.916, ppl=30.19, wps=20438, ups=0.08, wpb=262144, bsz=512, num_updates=15800, lr=0.00251577, gnorm=0.446, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=204197
2024-01-19 02:23:37 | INFO | train_inner | epoch 003:   2336 / 6724 loss=4.916, ppl=30.2, wps=20177.1, ups=0.08, wpb=262144, bsz=512, num_updates=15900, lr=0.00250785, gnorm=0.418, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=205497
2024-01-19 02:45:29 | INFO | train_inner | epoch 003:   2436 / 6724 loss=4.913, ppl=30.13, wps=19985.3, ups=0.08, wpb=262144, bsz=512, num_updates=16000, lr=0.0025, gnorm=0.425, clip=0, loss_scale=4, train_wall=1311, gb_free=10.5, wall=206808
2024-01-19 03:07:15 | INFO | train_inner | epoch 003:   2536 / 6724 loss=4.913, ppl=30.12, wps=20066.2, ups=0.08, wpb=262144, bsz=512, num_updates=16100, lr=0.00249222, gnorm=0.423, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=208115
2024-01-19 03:28:55 | INFO | train_inner | epoch 003:   2636 / 6724 loss=4.911, ppl=30.09, wps=20163.5, ups=0.08, wpb=262144, bsz=512, num_updates=16200, lr=0.00248452, gnorm=0.435, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=209415
2024-01-19 03:50:27 | INFO | train_inner | epoch 003:   2736 / 6724 loss=4.91, ppl=30.07, wps=20295.6, ups=0.08, wpb=262144, bsz=512, num_updates=16300, lr=0.00247689, gnorm=0.439, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=210706
2024-01-19 04:12:08 | INFO | train_inner | epoch 003:   2836 / 6724 loss=4.909, ppl=30.04, wps=20144.9, ups=0.08, wpb=262144, bsz=512, num_updates=16400, lr=0.00246932, gnorm=0.418, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=212008
2024-01-19 04:30:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-19 04:33:58 | INFO | train_inner | epoch 003:   2937 / 6724 loss=4.91, ppl=30.07, wps=20014.9, ups=0.08, wpb=262144, bsz=512, num_updates=16500, lr=0.00246183, gnorm=0.419, clip=0, loss_scale=4, train_wall=1310, gb_free=10.5, wall=213317
2024-01-19 04:55:29 | INFO | train_inner | epoch 003:   3037 / 6724 loss=4.911, ppl=30.09, wps=20298.2, ups=0.08, wpb=262144, bsz=512, num_updates=16600, lr=0.0024544, gnorm=0.416, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=214609
2024-01-19 05:17:15 | INFO | train_inner | epoch 003:   3137 / 6724 loss=4.907, ppl=30.01, wps=20079.2, ups=0.08, wpb=262144, bsz=512, num_updates=16700, lr=0.00244704, gnorm=0.475, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=215914
2024-01-19 05:39:03 | INFO | train_inner | epoch 003:   3237 / 6724 loss=4.909, ppl=30.05, wps=20037.1, ups=0.08, wpb=262144, bsz=512, num_updates=16800, lr=0.00243975, gnorm=0.412, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=217223
2024-01-19 06:00:41 | INFO | train_inner | epoch 003:   3337 / 6724 loss=4.909, ppl=30.04, wps=20193.4, ups=0.08, wpb=262144, bsz=512, num_updates=16900, lr=0.00243252, gnorm=0.48, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=218521
2024-01-19 06:22:18 | INFO | train_inner | epoch 003:   3437 / 6724 loss=4.907, ppl=30, wps=20164.6, ups=0.08, wpb=261519, bsz=510.8, num_updates=17000, lr=0.00242536, gnorm=0.435, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=219818
2024-01-19 06:43:50 | INFO | train_inner | epoch 003:   3537 / 6724 loss=4.905, ppl=29.96, wps=20288.1, ups=0.08, wpb=262144, bsz=512, num_updates=17100, lr=0.00241825, gnorm=0.433, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=221110
2024-01-19 07:05:17 | INFO | train_inner | epoch 003:   3637 / 6724 loss=4.906, ppl=29.98, wps=20364.1, ups=0.08, wpb=262144, bsz=512, num_updates=17200, lr=0.00241121, gnorm=0.429, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=222397
2024-01-19 07:26:39 | INFO | train_inner | epoch 003:   3737 / 6724 loss=4.903, ppl=29.93, wps=20458.2, ups=0.08, wpb=262144, bsz=512, num_updates=17300, lr=0.00240424, gnorm=0.434, clip=0, loss_scale=4, train_wall=1281, gb_free=10.5, wall=223679
2024-01-19 07:48:00 | INFO | train_inner | epoch 003:   3837 / 6724 loss=4.905, ppl=29.95, wps=20462.4, ups=0.08, wpb=262144, bsz=512, num_updates=17400, lr=0.00239732, gnorm=0.439, clip=0, loss_scale=4, train_wall=1281, gb_free=10.5, wall=224960
2024-01-19 08:09:39 | INFO | train_inner | epoch 003:   3937 / 6724 loss=4.899, ppl=29.84, wps=20181.5, ups=0.08, wpb=262144, bsz=512, num_updates=17500, lr=0.00239046, gnorm=0.436, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=226259
2024-01-19 08:31:12 | INFO | train_inner | epoch 003:   4037 / 6724 loss=4.897, ppl=29.8, wps=20264.7, ups=0.08, wpb=262144, bsz=512, num_updates=17600, lr=0.00238366, gnorm=0.433, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=227552
2024-01-19 08:52:42 | INFO | train_inner | epoch 003:   4137 / 6724 loss=4.905, ppl=29.96, wps=20330.9, ups=0.08, wpb=262144, bsz=512, num_updates=17700, lr=0.00237691, gnorm=0.439, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=228842
2024-01-19 09:14:16 | INFO | train_inner | epoch 003:   4237 / 6724 loss=4.901, ppl=29.87, wps=20252.3, ups=0.08, wpb=262144, bsz=512, num_updates=17800, lr=0.00237023, gnorm=0.422, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=230136
2024-01-19 09:35:56 | INFO | train_inner | epoch 003:   4337 / 6724 loss=4.898, ppl=29.82, wps=20173.2, ups=0.08, wpb=262144, bsz=512, num_updates=17900, lr=0.0023636, gnorm=0.445, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=231435
2024-01-19 09:57:44 | INFO | train_inner | epoch 003:   4437 / 6724 loss=4.902, ppl=29.9, wps=20044.3, ups=0.08, wpb=262144, bsz=512, num_updates=18000, lr=0.00235702, gnorm=0.432, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=232743
2024-01-19 10:19:21 | INFO | train_inner | epoch 003:   4537 / 6724 loss=4.894, ppl=29.73, wps=20210, ups=0.08, wpb=262144, bsz=512, num_updates=18100, lr=0.0023505, gnorm=0.412, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=234040
2024-01-19 10:40:52 | INFO | train_inner | epoch 003:   4637 / 6724 loss=4.896, ppl=29.78, wps=20302, ups=0.08, wpb=262144, bsz=512, num_updates=18200, lr=0.00234404, gnorm=0.444, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=235332
2024-01-19 11:02:24 | INFO | train_inner | epoch 003:   4737 / 6724 loss=4.892, ppl=29.69, wps=20283.4, ups=0.08, wpb=262144, bsz=512, num_updates=18300, lr=0.00233762, gnorm=0.41, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=236624
2024-01-19 11:23:35 | INFO | train_inner | epoch 003:   4837 / 6724 loss=4.895, ppl=29.76, wps=20622.3, ups=0.08, wpb=262144, bsz=512, num_updates=18400, lr=0.00233126, gnorm=0.444, clip=0, loss_scale=4, train_wall=1271, gb_free=10.5, wall=237895
2024-01-19 11:44:47 | INFO | train_inner | epoch 003:   4937 / 6724 loss=4.898, ppl=29.81, wps=20609.8, ups=0.08, wpb=262144, bsz=512, num_updates=18500, lr=0.00232495, gnorm=0.432, clip=0, loss_scale=4, train_wall=1272, gb_free=10.5, wall=239167
2024-01-19 12:06:12 | INFO | train_inner | epoch 003:   5037 / 6724 loss=4.894, ppl=29.73, wps=20400.5, ups=0.08, wpb=262144, bsz=512, num_updates=18600, lr=0.00231869, gnorm=0.407, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=240452
2024-01-19 12:27:25 | INFO | train_inner | epoch 003:   5137 / 6724 loss=4.892, ppl=29.7, wps=20602.5, ups=0.08, wpb=262144, bsz=512, num_updates=18700, lr=0.00231249, gnorm=0.448, clip=0, loss_scale=4, train_wall=1272, gb_free=10.5, wall=241724
2024-01-19 12:48:27 | INFO | train_inner | epoch 003:   5237 / 6724 loss=4.898, ppl=29.82, wps=20766.7, ups=0.08, wpb=262144, bsz=512, num_updates=18800, lr=0.00230633, gnorm=0.444, clip=0, loss_scale=4, train_wall=1262, gb_free=10.5, wall=242987
2024-01-19 13:09:29 | INFO | train_inner | epoch 003:   5337 / 6724 loss=4.892, ppl=29.69, wps=20780.2, ups=0.08, wpb=262144, bsz=512, num_updates=18900, lr=0.00230022, gnorm=0.442, clip=0, loss_scale=4, train_wall=1261, gb_free=10.5, wall=244248
2024-01-19 13:30:47 | INFO | train_inner | epoch 003:   5437 / 6724 loss=4.891, ppl=29.68, wps=20497.7, ups=0.08, wpb=262144, bsz=512, num_updates=19000, lr=0.00229416, gnorm=0.478, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=245527
2024-01-19 13:52:05 | INFO | train_inner | epoch 003:   5537 / 6724 loss=4.889, ppl=29.63, wps=20519.4, ups=0.08, wpb=262144, bsz=512, num_updates=19100, lr=0.00228814, gnorm=0.425, clip=0, loss_scale=4, train_wall=1277, gb_free=10.5, wall=246805
2024-01-19 14:13:24 | INFO | train_inner | epoch 003:   5637 / 6724 loss=4.89, ppl=29.65, wps=20502.5, ups=0.08, wpb=262144, bsz=512, num_updates=19200, lr=0.00228218, gnorm=0.424, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=248083
2024-01-19 14:34:48 | INFO | train_inner | epoch 003:   5737 / 6724 loss=4.888, ppl=29.61, wps=20409.5, ups=0.08, wpb=262144, bsz=512, num_updates=19300, lr=0.00227626, gnorm=0.431, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=249368
2024-01-19 14:56:08 | INFO | train_inner | epoch 003:   5837 / 6724 loss=4.886, ppl=29.57, wps=20487.3, ups=0.08, wpb=262144, bsz=512, num_updates=19400, lr=0.00227038, gnorm=0.417, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=250647
2024-01-19 15:17:26 | INFO | train_inner | epoch 003:   5937 / 6724 loss=4.885, ppl=29.56, wps=20509.4, ups=0.08, wpb=262144, bsz=512, num_updates=19500, lr=0.00226455, gnorm=0.417, clip=0, loss_scale=4, train_wall=1278, gb_free=10.5, wall=251925
2024-01-19 15:38:38 | INFO | train_inner | epoch 003:   6037 / 6724 loss=4.886, ppl=29.57, wps=20601.2, ups=0.08, wpb=262144, bsz=512, num_updates=19600, lr=0.00225877, gnorm=0.472, clip=0, loss_scale=4, train_wall=1272, gb_free=10.5, wall=253198
2024-01-19 15:59:51 | INFO | train_inner | epoch 003:   6137 / 6724 loss=4.885, ppl=29.55, wps=20591.6, ups=0.08, wpb=262144, bsz=512, num_updates=19700, lr=0.00225303, gnorm=0.431, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=254471
2024-01-19 16:20:57 | INFO | train_inner | epoch 003:   6237 / 6724 loss=4.884, ppl=29.52, wps=20714.2, ups=0.08, wpb=262144, bsz=512, num_updates=19800, lr=0.00224733, gnorm=0.425, clip=0, loss_scale=4, train_wall=1265, gb_free=10.5, wall=255737
2024-01-19 16:42:11 | INFO | train_inner | epoch 003:   6337 / 6724 loss=4.882, ppl=29.48, wps=20568.6, ups=0.08, wpb=262144, bsz=512, num_updates=19900, lr=0.00224168, gnorm=0.409, clip=0, loss_scale=4, train_wall=1274, gb_free=10.5, wall=257011
2024-01-19 17:03:22 | INFO | train_inner | epoch 003:   6437 / 6724 loss=4.885, ppl=29.55, wps=20628.4, ups=0.08, wpb=262144, bsz=512, num_updates=20000, lr=0.00223607, gnorm=0.423, clip=0, loss_scale=4, train_wall=1271, gb_free=10.5, wall=258282
2024-01-19 17:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20000 updates
2024-01-19 17:03:22 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_3_20000.pt
2024-01-19 17:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_3_20000.pt
2024-01-19 17:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_3_20000.pt (epoch 3 @ 20000 updates, score None) (writing took 44.085504160029814 seconds)
2024-01-19 17:25:27 | INFO | train_inner | epoch 003:   6537 / 6724 loss=4.883, ppl=29.5, wps=19792, ups=0.08, wpb=262144, bsz=512, num_updates=20100, lr=0.0022305, gnorm=0.442, clip=0, loss_scale=4, train_wall=1280, gb_free=10.5, wall=259606
2024-01-19 17:46:51 | INFO | train_inner | epoch 003:   6637 / 6724 loss=4.883, ppl=29.51, wps=20415.4, ups=0.08, wpb=262144, bsz=512, num_updates=20200, lr=0.00222497, gnorm=0.419, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=260890
2024-01-19 18:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 20287 updates
2024-01-19 18:05:29 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint3.pt
2024-01-19 18:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint3.pt
2024-01-19 18:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint3.pt (epoch 3 @ 20287 updates, score None) (writing took 71.26332686300157 seconds)
2024-01-19 18:06:40 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-01-19 18:06:40 | INFO | train | epoch 003 | loss 4.908 | ppl 30.02 | wps 20286.5 | ups 0.08 | wpb 262115 | bsz 511.9 | num_updates 20287 | lr 0.00222019 | gnorm 0.434 | clip 0 | loss_scale 4 | train_wall 86689 | gb_free 10.5 | wall 262080
2024-01-19 18:06:40 | INFO | fairseq.trainer | loading train data for epoch 4
2024-01-19 18:06:41 | INFO | fairseq.data.data_utils | loaded 52,445,000 examples from: ./data/data-bin/3/train
2024-01-19 18:06:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6739
2024-01-19 18:06:42 | INFO | fairseq.trainer | begin training epoch 4
2024-01-19 18:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-19 18:09:29 | INFO | train_inner | epoch 004:     13 / 6739 loss=4.886, ppl=29.57, wps=19205.9, ups=0.07, wpb=260833, bsz=509.4, num_updates=20300, lr=0.00221948, gnorm=0.41, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=262248
2024-01-19 18:31:07 | INFO | train_inner | epoch 004:    113 / 6739 loss=4.881, ppl=29.46, wps=20184.5, ups=0.08, wpb=262144, bsz=512, num_updates=20400, lr=0.00221404, gnorm=0.437, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=263547
2024-01-19 18:52:36 | INFO | train_inner | epoch 004:    213 / 6739 loss=4.874, ppl=29.31, wps=20350.3, ups=0.08, wpb=262144, bsz=512, num_updates=20500, lr=0.00220863, gnorm=0.429, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=264835
2024-01-19 19:14:10 | INFO | train_inner | epoch 004:    313 / 6739 loss=4.879, ppl=29.42, wps=20247.6, ups=0.08, wpb=262144, bsz=512, num_updates=20600, lr=0.00220326, gnorm=0.447, clip=0, loss_scale=8, train_wall=1294, gb_free=10.5, wall=266130
2024-01-19 19:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-19 19:36:05 | INFO | train_inner | epoch 004:    414 / 6739 loss=4.877, ppl=29.38, wps=19935.7, ups=0.08, wpb=262144, bsz=512, num_updates=20700, lr=0.00219793, gnorm=0.445, clip=0, loss_scale=4, train_wall=1315, gb_free=10.5, wall=267445
2024-01-19 19:57:45 | INFO | train_inner | epoch 004:    514 / 6739 loss=4.874, ppl=29.33, wps=20166.8, ups=0.08, wpb=262144, bsz=512, num_updates=20800, lr=0.00219265, gnorm=0.428, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=268745
2024-01-19 20:19:30 | INFO | train_inner | epoch 004:    614 / 6739 loss=4.873, ppl=29.31, wps=20085.4, ups=0.08, wpb=262144, bsz=512, num_updates=20900, lr=0.00218739, gnorm=0.406, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=270050
2024-01-19 20:41:08 | INFO | train_inner | epoch 004:    714 / 6739 loss=4.873, ppl=29.3, wps=20193.4, ups=0.08, wpb=262144, bsz=512, num_updates=21000, lr=0.00218218, gnorm=0.411, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=271348
2024-01-19 21:02:45 | INFO | train_inner | epoch 004:    814 / 6739 loss=4.878, ppl=29.41, wps=20213.3, ups=0.08, wpb=262144, bsz=512, num_updates=21100, lr=0.002177, gnorm=0.461, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=272645
2024-01-19 21:24:18 | INFO | train_inner | epoch 004:    914 / 6739 loss=4.872, ppl=29.29, wps=20283.5, ups=0.08, wpb=262144, bsz=512, num_updates=21200, lr=0.00217186, gnorm=0.456, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=273938
2024-01-19 21:45:45 | INFO | train_inner | epoch 004:   1014 / 6739 loss=4.87, ppl=29.24, wps=20360.9, ups=0.08, wpb=262144, bsz=512, num_updates=21300, lr=0.00216676, gnorm=0.403, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=275225
2024-01-19 22:07:25 | INFO | train_inner | epoch 004:   1114 / 6739 loss=4.872, ppl=29.29, wps=20169.6, ups=0.08, wpb=262144, bsz=512, num_updates=21400, lr=0.00216169, gnorm=0.448, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=276525
2024-01-19 22:28:53 | INFO | train_inner | epoch 004:   1214 / 6739 loss=4.872, ppl=29.28, wps=20358.8, ups=0.08, wpb=262144, bsz=512, num_updates=21500, lr=0.00215666, gnorm=0.432, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=277812
2024-01-19 22:50:20 | INFO | train_inner | epoch 004:   1314 / 6739 loss=4.866, ppl=29.15, wps=20356.6, ups=0.08, wpb=262144, bsz=512, num_updates=21600, lr=0.00215166, gnorm=0.43, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=279100
2024-01-19 23:11:50 | INFO | train_inner | epoch 004:   1414 / 6739 loss=4.876, ppl=29.37, wps=20332.6, ups=0.08, wpb=262144, bsz=512, num_updates=21700, lr=0.00214669, gnorm=0.418, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=280389
2024-01-19 23:33:16 | INFO | train_inner | epoch 004:   1514 / 6739 loss=4.877, ppl=29.39, wps=20381.3, ups=0.08, wpb=262144, bsz=512, num_updates=21800, lr=0.00214176, gnorm=0.441, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=281676
2024-01-19 23:54:55 | INFO | train_inner | epoch 004:   1614 / 6739 loss=4.873, ppl=29.3, wps=20183.3, ups=0.08, wpb=262144, bsz=512, num_updates=21900, lr=0.00213687, gnorm=0.419, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=282974
2024-01-20 00:16:50 | INFO | train_inner | epoch 004:   1714 / 6739 loss=4.871, ppl=29.27, wps=19927.6, ups=0.08, wpb=262144, bsz=512, num_updates=22000, lr=0.00213201, gnorm=0.418, clip=0, loss_scale=4, train_wall=1315, gb_free=10.5, wall=284290
2024-01-20 00:38:38 | INFO | train_inner | epoch 004:   1814 / 6739 loss=4.867, ppl=29.19, wps=20044.8, ups=0.08, wpb=262144, bsz=512, num_updates=22100, lr=0.00212718, gnorm=0.434, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=285598
2024-01-20 01:00:33 | INFO | train_inner | epoch 004:   1914 / 6739 loss=4.868, ppl=29.2, wps=19933.7, ups=0.08, wpb=262144, bsz=512, num_updates=22200, lr=0.00212238, gnorm=0.459, clip=0, loss_scale=4, train_wall=1315, gb_free=10.5, wall=286913
2024-01-20 01:22:17 | INFO | train_inner | epoch 004:   2014 / 6739 loss=4.866, ppl=29.17, wps=20109.9, ups=0.08, wpb=262144, bsz=512, num_updates=22300, lr=0.00211762, gnorm=0.439, clip=0, loss_scale=4, train_wall=1303, gb_free=10.5, wall=288216
2024-01-20 01:43:54 | INFO | train_inner | epoch 004:   2114 / 6739 loss=4.87, ppl=29.24, wps=20204.1, ups=0.08, wpb=262144, bsz=512, num_updates=22400, lr=0.00211289, gnorm=0.425, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=289514
2024-01-20 02:05:31 | INFO | train_inner | epoch 004:   2214 / 6739 loss=4.867, ppl=29.19, wps=20213.8, ups=0.08, wpb=262144, bsz=512, num_updates=22500, lr=0.00210819, gnorm=0.439, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=290811
2024-01-20 02:27:11 | INFO | train_inner | epoch 004:   2314 / 6739 loss=4.869, ppl=29.23, wps=20164.3, ups=0.08, wpb=262144, bsz=512, num_updates=22600, lr=0.00210352, gnorm=0.417, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=292111
2024-01-20 02:48:59 | INFO | train_inner | epoch 004:   2414 / 6739 loss=4.869, ppl=29.22, wps=20047.6, ups=0.08, wpb=262144, bsz=512, num_updates=22700, lr=0.00209888, gnorm=0.416, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=293418
2024-01-20 03:10:53 | INFO | train_inner | epoch 004:   2514 / 6739 loss=4.866, ppl=29.16, wps=19938.5, ups=0.08, wpb=262144, bsz=512, num_updates=22800, lr=0.00209427, gnorm=0.444, clip=0, loss_scale=4, train_wall=1315, gb_free=10.5, wall=294733
2024-01-20 03:32:36 | INFO | train_inner | epoch 004:   2614 / 6739 loss=4.864, ppl=29.12, wps=20122.8, ups=0.08, wpb=262144, bsz=512, num_updates=22900, lr=0.00208969, gnorm=0.444, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=296036
2024-01-20 03:54:00 | INFO | train_inner | epoch 004:   2714 / 6739 loss=4.864, ppl=29.11, wps=20411.7, ups=0.08, wpb=262144, bsz=512, num_updates=23000, lr=0.00208514, gnorm=0.451, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=297320
2024-01-20 04:15:32 | INFO | train_inner | epoch 004:   2814 / 6739 loss=4.861, ppl=29.07, wps=20289.7, ups=0.08, wpb=262144, bsz=512, num_updates=23100, lr=0.00208063, gnorm=0.502, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=298612
2024-01-20 04:37:11 | INFO | train_inner | epoch 004:   2914 / 6739 loss=4.863, ppl=29.11, wps=20192.2, ups=0.08, wpb=262142, bsz=512, num_updates=23200, lr=0.00207614, gnorm=0.426, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=299910
2024-01-20 04:58:41 | INFO | train_inner | epoch 004:   3014 / 6739 loss=4.865, ppl=29.13, wps=20315, ups=0.08, wpb=262144, bsz=512, num_updates=23300, lr=0.00207168, gnorm=0.417, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=301201
2024-01-20 05:20:09 | INFO | train_inner | epoch 004:   3114 / 6739 loss=4.863, ppl=29.11, wps=20351.5, ups=0.08, wpb=262144, bsz=512, num_updates=23400, lr=0.00206725, gnorm=0.418, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=302489
2024-01-20 05:41:34 | INFO | train_inner | epoch 004:   3214 / 6739 loss=4.863, ppl=29.11, wps=20395.2, ups=0.08, wpb=262144, bsz=512, num_updates=23500, lr=0.00206284, gnorm=0.414, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=303774
2024-01-20 06:02:57 | INFO | train_inner | epoch 004:   3314 / 6739 loss=4.86, ppl=29.05, wps=20440.9, ups=0.08, wpb=262144, bsz=512, num_updates=23600, lr=0.00205847, gnorm=0.426, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=305057
2024-01-20 06:24:23 | INFO | train_inner | epoch 004:   3414 / 6739 loss=4.863, ppl=29.1, wps=20380.8, ups=0.08, wpb=262144, bsz=512, num_updates=23700, lr=0.00205412, gnorm=0.444, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=306343
2024-01-20 06:45:59 | INFO | train_inner | epoch 004:   3514 / 6739 loss=4.861, ppl=29.05, wps=20227.1, ups=0.08, wpb=262144, bsz=512, num_updates=23800, lr=0.0020498, gnorm=0.432, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=307639
2024-01-20 07:07:34 | INFO | train_inner | epoch 004:   3614 / 6739 loss=4.859, ppl=29.03, wps=20236.3, ups=0.08, wpb=262144, bsz=512, num_updates=23900, lr=0.00204551, gnorm=0.43, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=308934
2024-01-20 07:29:12 | INFO | train_inner | epoch 004:   3714 / 6739 loss=4.858, ppl=29.01, wps=20199.9, ups=0.08, wpb=262144, bsz=512, num_updates=24000, lr=0.00204124, gnorm=0.423, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=310232
2024-01-20 07:50:50 | INFO | train_inner | epoch 004:   3814 / 6739 loss=4.861, ppl=29.07, wps=20206.2, ups=0.08, wpb=262144, bsz=512, num_updates=24100, lr=0.002037, gnorm=0.473, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=311529
2024-01-20 08:12:17 | INFO | train_inner | epoch 004:   3914 / 6739 loss=4.859, ppl=29.02, wps=20368.9, ups=0.08, wpb=262144, bsz=512, num_updates=24200, lr=0.00203279, gnorm=0.415, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=312816
2024-01-20 08:33:44 | INFO | train_inner | epoch 004:   4014 / 6739 loss=4.853, ppl=28.9, wps=20360.5, ups=0.08, wpb=262144, bsz=512, num_updates=24300, lr=0.0020286, gnorm=0.447, clip=0, loss_scale=4, train_wall=1287, gb_free=10.5, wall=314104
2024-01-20 08:55:08 | INFO | train_inner | epoch 004:   4114 / 6739 loss=4.857, ppl=28.98, wps=20419.2, ups=0.08, wpb=262144, bsz=512, num_updates=24400, lr=0.00202444, gnorm=0.404, clip=0, loss_scale=4, train_wall=1284, gb_free=10.5, wall=315388
2024-01-20 09:16:25 | INFO | train_inner | epoch 004:   4214 / 6739 loss=4.86, ppl=29.04, wps=20527.9, ups=0.08, wpb=262144, bsz=512, num_updates=24500, lr=0.00202031, gnorm=0.438, clip=0, loss_scale=4, train_wall=1277, gb_free=10.5, wall=316665
2024-01-20 09:37:38 | INFO | train_inner | epoch 004:   4314 / 6739 loss=4.858, ppl=29, wps=20589, ups=0.08, wpb=262144, bsz=512, num_updates=24600, lr=0.00201619, gnorm=0.419, clip=0, loss_scale=4, train_wall=1273, gb_free=10.5, wall=317938
2024-01-20 09:58:59 | INFO | train_inner | epoch 004:   4414 / 6739 loss=4.853, ppl=28.91, wps=20461.9, ups=0.08, wpb=262144, bsz=512, num_updates=24700, lr=0.00201211, gnorm=0.455, clip=0, loss_scale=8, train_wall=1281, gb_free=10.5, wall=319219
2024-01-20 09:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-20 10:20:25 | INFO | train_inner | epoch 004:   4515 / 6739 loss=4.858, ppl=29, wps=20395.7, ups=0.08, wpb=262144, bsz=512, num_updates=24800, lr=0.00200805, gnorm=0.433, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=320504
2024-01-20 10:41:40 | INFO | train_inner | epoch 004:   4615 / 6739 loss=4.856, ppl=28.96, wps=20559.2, ups=0.08, wpb=262144, bsz=512, num_updates=24900, lr=0.00200401, gnorm=0.472, clip=0, loss_scale=4, train_wall=1275, gb_free=10.5, wall=321779
2024-01-20 11:02:59 | INFO | train_inner | epoch 004:   4715 / 6739 loss=4.855, ppl=28.94, wps=20488, ups=0.08, wpb=262144, bsz=512, num_updates=25000, lr=0.002, gnorm=0.421, clip=0, loss_scale=4, train_wall=1279, gb_free=10.5, wall=323059
2024-01-20 11:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 25000 updates
2024-01-20 11:02:59 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_4_25000.pt
2024-01-20 11:03:15 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_4_25000.pt
2024-01-20 11:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_4_25000.pt (epoch 4 @ 25000 updates, score None) (writing took 44.94727503298782 seconds)
2024-01-20 11:25:07 | INFO | train_inner | epoch 004:   4815 / 6739 loss=4.852, ppl=28.89, wps=19740.7, ups=0.08, wpb=262144, bsz=512, num_updates=25100, lr=0.00199601, gnorm=0.477, clip=0, loss_scale=4, train_wall=1283, gb_free=10.5, wall=324387
2024-01-20 11:46:40 | INFO | train_inner | epoch 004:   4915 / 6739 loss=4.852, ppl=28.88, wps=20276.6, ups=0.08, wpb=262103, bsz=511.9, num_updates=25200, lr=0.00199205, gnorm=0.428, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=325679
2024-01-20 12:08:31 | INFO | train_inner | epoch 004:   5015 / 6739 loss=4.849, ppl=28.83, wps=19990.5, ups=0.08, wpb=262144, bsz=512, num_updates=25300, lr=0.00198811, gnorm=0.466, clip=0, loss_scale=4, train_wall=1311, gb_free=10.5, wall=326991
2024-01-20 12:30:17 | INFO | train_inner | epoch 004:   5115 / 6739 loss=4.851, ppl=28.86, wps=20070.4, ups=0.08, wpb=262144, bsz=512, num_updates=25400, lr=0.00198419, gnorm=0.416, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=328297
2024-01-20 12:51:47 | INFO | train_inner | epoch 004:   5215 / 6739 loss=4.856, ppl=28.97, wps=20328.9, ups=0.08, wpb=262144, bsz=512, num_updates=25500, lr=0.0019803, gnorm=0.43, clip=0, loss_scale=4, train_wall=1289, gb_free=10.5, wall=329586
2024-01-20 13:13:32 | INFO | train_inner | epoch 004:   5315 / 6739 loss=4.855, ppl=28.93, wps=20081.3, ups=0.08, wpb=262144, bsz=512, num_updates=25600, lr=0.00197642, gnorm=0.476, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=330892
2024-01-20 13:35:06 | INFO | train_inner | epoch 004:   5415 / 6739 loss=4.849, ppl=28.83, wps=20263.4, ups=0.08, wpb=262144, bsz=512, num_updates=25700, lr=0.00197257, gnorm=0.443, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=332186
2024-01-20 13:56:38 | INFO | train_inner | epoch 004:   5515 / 6739 loss=4.852, ppl=28.88, wps=20293.7, ups=0.08, wpb=262144, bsz=512, num_updates=25800, lr=0.00196875, gnorm=0.444, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=333477
2024-01-20 14:18:12 | INFO | train_inner | epoch 004:   5615 / 6739 loss=4.853, ppl=28.89, wps=20245.3, ups=0.08, wpb=262144, bsz=512, num_updates=25900, lr=0.00196494, gnorm=0.474, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=334772
2024-01-20 14:39:46 | INFO | train_inner | epoch 004:   5715 / 6739 loss=4.852, ppl=28.89, wps=20257.7, ups=0.08, wpb=262144, bsz=512, num_updates=26000, lr=0.00196116, gnorm=0.46, clip=0, loss_scale=4, train_wall=1294, gb_free=10.5, wall=336066
2024-01-20 15:01:09 | INFO | train_inner | epoch 004:   5815 / 6739 loss=4.85, ppl=28.84, wps=20440.3, ups=0.08, wpb=262144, bsz=512, num_updates=26100, lr=0.0019574, gnorm=0.451, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=337349
2024-01-20 15:22:40 | INFO | train_inner | epoch 004:   5915 / 6739 loss=4.848, ppl=28.79, wps=20301.3, ups=0.08, wpb=262144, bsz=512, num_updates=26200, lr=0.00195366, gnorm=0.419, clip=0, loss_scale=4, train_wall=1291, gb_free=10.5, wall=338640
2024-01-20 15:44:17 | INFO | train_inner | epoch 004:   6015 / 6739 loss=4.849, ppl=28.81, wps=20219.7, ups=0.08, wpb=262144, bsz=512, num_updates=26300, lr=0.00194994, gnorm=0.419, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=339936
2024-01-20 16:05:56 | INFO | train_inner | epoch 004:   6115 / 6739 loss=4.847, ppl=28.79, wps=20171.2, ups=0.08, wpb=262144, bsz=512, num_updates=26400, lr=0.00194625, gnorm=0.442, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=341236
2024-01-20 16:27:36 | INFO | train_inner | epoch 004:   6215 / 6739 loss=4.846, ppl=28.77, wps=20166.6, ups=0.08, wpb=262144, bsz=512, num_updates=26500, lr=0.00194257, gnorm=0.461, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=342536
2024-01-20 16:49:21 | INFO | train_inner | epoch 004:   6315 / 6739 loss=4.845, ppl=28.74, wps=20084, ups=0.08, wpb=262144, bsz=512, num_updates=26600, lr=0.00193892, gnorm=0.433, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=343841
2024-01-20 17:11:06 | INFO | train_inner | epoch 004:   6415 / 6739 loss=4.845, ppl=28.74, wps=20099, ups=0.08, wpb=262144, bsz=512, num_updates=26700, lr=0.00193528, gnorm=0.468, clip=0, loss_scale=4, train_wall=1304, gb_free=10.5, wall=345145
2024-01-20 17:32:55 | INFO | train_inner | epoch 004:   6515 / 6739 loss=4.849, ppl=28.82, wps=20025.4, ups=0.08, wpb=262144, bsz=512, num_updates=26800, lr=0.00193167, gnorm=0.455, clip=0, loss_scale=4, train_wall=1309, gb_free=10.5, wall=346454
2024-01-20 17:54:45 | INFO | train_inner | epoch 004:   6615 / 6739 loss=4.849, ppl=28.81, wps=20007.7, ups=0.08, wpb=262144, bsz=512, num_updates=26900, lr=0.00192807, gnorm=0.439, clip=0, loss_scale=4, train_wall=1310, gb_free=10.5, wall=347765
2024-01-20 18:16:31 | INFO | train_inner | epoch 004:   6715 / 6739 loss=4.846, ppl=28.75, wps=20072.6, ups=0.08, wpb=262144, bsz=512, num_updates=27000, lr=0.0019245, gnorm=0.445, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=349071
2024-01-20 18:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 27024 updates
2024-01-20 18:21:46 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint4.pt
2024-01-20 18:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint4.pt
2024-01-20 18:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint4.pt (epoch 4 @ 27024 updates, score None) (writing took 76.69818112696521 seconds)
2024-01-20 18:23:02 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-01-20 18:23:02 | INFO | train | epoch 004 | loss 4.861 | ppl 29.07 | wps 20210 | ups 0.08 | wpb 262134 | bsz 512 | num_updates 27024 | lr 0.00192365 | gnorm 0.438 | clip 0 | loss_scale 4 | train_wall 87244 | gb_free 10.5 | wall 349462
2024-01-20 18:23:02 | INFO | fairseq.trainer | loading train data for epoch 5
2024-01-20 18:23:03 | INFO | fairseq.data.data_utils | loaded 52,822,000 examples from: ./data/data-bin/4/train
2024-01-20 18:23:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6784
2024-01-20 18:23:04 | INFO | fairseq.trainer | begin training epoch 5
2024-01-20 18:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-20 18:39:43 | INFO | train_inner | epoch 005:     76 / 6784 loss=4.85, ppl=28.85, wps=18784, ups=0.07, wpb=261489, bsz=510.7, num_updates=27100, lr=0.00192095, gnorm=0.454, clip=0, loss_scale=4, train_wall=1313, gb_free=10.5, wall=350463
2024-01-20 19:01:43 | INFO | train_inner | epoch 005:    176 / 6784 loss=4.851, ppl=28.85, wps=19866.2, ups=0.08, wpb=262144, bsz=512, num_updates=27200, lr=0.00191741, gnorm=0.417, clip=0, loss_scale=4, train_wall=1319, gb_free=10.5, wall=351782
2024-01-20 19:23:29 | INFO | train_inner | epoch 005:    276 / 6784 loss=4.848, ppl=28.79, wps=20068.1, ups=0.08, wpb=262144, bsz=512, num_updates=27300, lr=0.0019139, gnorm=0.439, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=353089
2024-01-20 19:45:16 | INFO | train_inner | epoch 005:    376 / 6784 loss=4.853, ppl=28.9, wps=20057.9, ups=0.08, wpb=262144, bsz=512, num_updates=27400, lr=0.0019104, gnorm=0.428, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=354396
2024-01-20 20:06:56 | INFO | train_inner | epoch 005:    476 / 6784 loss=4.845, ppl=28.74, wps=20167.3, ups=0.08, wpb=262144, bsz=512, num_updates=27500, lr=0.00190693, gnorm=0.438, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=355695
2024-01-20 20:28:43 | INFO | train_inner | epoch 005:    576 / 6784 loss=4.842, ppl=28.68, wps=20046.8, ups=0.08, wpb=262144, bsz=512, num_updates=27600, lr=0.00190347, gnorm=0.459, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=357003
2024-01-20 20:50:26 | INFO | train_inner | epoch 005:    676 / 6784 loss=4.85, ppl=28.83, wps=20125.4, ups=0.08, wpb=262144, bsz=512, num_updates=27700, lr=0.00190003, gnorm=0.41, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=358306
2024-01-20 21:12:08 | INFO | train_inner | epoch 005:    776 / 6784 loss=4.842, ppl=28.67, wps=20133.8, ups=0.08, wpb=262144, bsz=512, num_updates=27800, lr=0.00189661, gnorm=0.471, clip=0, loss_scale=4, train_wall=1302, gb_free=10.5, wall=359608
2024-01-20 21:34:01 | INFO | train_inner | epoch 005:    876 / 6784 loss=4.848, ppl=28.81, wps=19969.1, ups=0.08, wpb=262144, bsz=512, num_updates=27900, lr=0.00189321, gnorm=0.447, clip=0, loss_scale=4, train_wall=1313, gb_free=10.5, wall=360920
2024-01-20 21:55:50 | INFO | train_inner | epoch 005:    976 / 6784 loss=4.843, ppl=28.7, wps=19966.7, ups=0.08, wpb=261519, bsz=510.8, num_updates=28000, lr=0.00188982, gnorm=0.462, clip=0, loss_scale=4, train_wall=1310, gb_free=10.5, wall=362230
2024-01-20 22:17:38 | INFO | train_inner | epoch 005:   1076 / 6784 loss=4.843, ppl=28.7, wps=20046.1, ups=0.08, wpb=262144, bsz=512, num_updates=28100, lr=0.00188646, gnorm=0.469, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=363538
2024-01-20 22:39:27 | INFO | train_inner | epoch 005:   1176 / 6784 loss=4.84, ppl=28.65, wps=20031.4, ups=0.08, wpb=262144, bsz=512, num_updates=28200, lr=0.00188311, gnorm=0.455, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=364847
2024-01-20 23:01:13 | INFO | train_inner | epoch 005:   1276 / 6784 loss=4.843, ppl=28.7, wps=20061.9, ups=0.08, wpb=262144, bsz=512, num_updates=28300, lr=0.00187978, gnorm=0.437, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=366153
2024-01-20 23:23:01 | INFO | train_inner | epoch 005:   1376 / 6784 loss=4.84, ppl=28.65, wps=20052.3, ups=0.08, wpb=262144, bsz=512, num_updates=28400, lr=0.00187647, gnorm=0.411, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=367460
2024-01-20 23:44:40 | INFO | train_inner | epoch 005:   1476 / 6784 loss=4.843, ppl=28.71, wps=20175.5, ups=0.08, wpb=262144, bsz=512, num_updates=28500, lr=0.00187317, gnorm=0.459, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=368760
2024-01-21 00:06:20 | INFO | train_inner | epoch 005:   1576 / 6784 loss=4.832, ppl=28.48, wps=20168.2, ups=0.08, wpb=262144, bsz=512, num_updates=28600, lr=0.00186989, gnorm=0.466, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=370060
2024-01-21 00:28:07 | INFO | train_inner | epoch 005:   1676 / 6784 loss=4.844, ppl=28.71, wps=20052.6, ups=0.08, wpb=262144, bsz=512, num_updates=28700, lr=0.00186663, gnorm=0.455, clip=0, loss_scale=4, train_wall=1307, gb_free=10.5, wall=371367
2024-01-21 00:49:45 | INFO | train_inner | epoch 005:   1776 / 6784 loss=4.841, ppl=28.65, wps=20199.6, ups=0.08, wpb=262144, bsz=512, num_updates=28800, lr=0.00186339, gnorm=0.458, clip=0, loss_scale=8, train_wall=1298, gb_free=10.5, wall=372665
2024-01-21 00:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-21 01:11:36 | INFO | train_inner | epoch 005:   1877 / 6784 loss=4.842, ppl=28.68, wps=19989.9, ups=0.08, wpb=262144, bsz=512, num_updates=28900, lr=0.00186016, gnorm=0.459, clip=0, loss_scale=4, train_wall=1311, gb_free=10.5, wall=373976
2024-01-21 01:33:01 | INFO | train_inner | epoch 005:   1977 / 6784 loss=4.844, ppl=28.72, wps=20401.4, ups=0.08, wpb=262144, bsz=512, num_updates=29000, lr=0.00185695, gnorm=0.453, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=375261
2024-01-21 01:54:26 | INFO | train_inner | epoch 005:   2077 / 6784 loss=4.843, ppl=28.7, wps=20401.4, ups=0.08, wpb=262144, bsz=512, num_updates=29100, lr=0.00185376, gnorm=0.444, clip=0, loss_scale=4, train_wall=1285, gb_free=10.5, wall=376546
2024-01-21 02:15:58 | INFO | train_inner | epoch 005:   2177 / 6784 loss=4.842, ppl=28.68, wps=20291.6, ups=0.08, wpb=262144, bsz=512, num_updates=29200, lr=0.00185058, gnorm=0.453, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=377838
2024-01-21 02:37:33 | INFO | train_inner | epoch 005:   2277 / 6784 loss=4.837, ppl=28.59, wps=20242.2, ups=0.08, wpb=262144, bsz=512, num_updates=29300, lr=0.00184742, gnorm=0.458, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=379133
2024-01-21 02:59:14 | INFO | train_inner | epoch 005:   2377 / 6784 loss=4.842, ppl=28.68, wps=20150.9, ups=0.08, wpb=262144, bsz=512, num_updates=29400, lr=0.00184428, gnorm=0.44, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=380434
2024-01-21 03:21:00 | INFO | train_inner | epoch 005:   2477 / 6784 loss=4.841, ppl=28.67, wps=20072.3, ups=0.08, wpb=262144, bsz=512, num_updates=29500, lr=0.00184115, gnorm=0.431, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=381740
2024-01-21 03:42:33 | INFO | train_inner | epoch 005:   2577 / 6784 loss=4.837, ppl=28.59, wps=20276.2, ups=0.08, wpb=262144, bsz=512, num_updates=29600, lr=0.00183804, gnorm=0.438, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=383033
2024-01-21 04:04:09 | INFO | train_inner | epoch 005:   2677 / 6784 loss=4.839, ppl=28.63, wps=20227.8, ups=0.08, wpb=262144, bsz=512, num_updates=29700, lr=0.00183494, gnorm=0.424, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=384329
2024-01-21 04:25:40 | INFO | train_inner | epoch 005:   2777 / 6784 loss=4.835, ppl=28.55, wps=20310.2, ups=0.08, wpb=262144, bsz=512, num_updates=29800, lr=0.00183186, gnorm=0.447, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=385619
2024-01-21 04:47:08 | INFO | train_inner | epoch 005:   2877 / 6784 loss=4.836, ppl=28.56, wps=20342.2, ups=0.08, wpb=262144, bsz=512, num_updates=29900, lr=0.00182879, gnorm=0.469, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=386908
2024-01-21 05:08:48 | INFO | train_inner | epoch 005:   2977 / 6784 loss=4.836, ppl=28.57, wps=20166.3, ups=0.08, wpb=262144, bsz=512, num_updates=30000, lr=0.00182574, gnorm=0.455, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=388208
2024-01-21 05:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 30000 updates
2024-01-21 05:08:48 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_5_30000.pt
2024-01-21 05:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_5_30000.pt
2024-01-21 05:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_5_30000.pt (epoch 5 @ 30000 updates, score None) (writing took 44.62792915099999 seconds)
2024-01-21 05:31:11 | INFO | train_inner | epoch 005:   3077 / 6784 loss=4.835, ppl=28.53, wps=19514.3, ups=0.07, wpb=262144, bsz=512, num_updates=30100, lr=0.00182271, gnorm=0.435, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=389551
2024-01-21 05:52:53 | INFO | train_inner | epoch 005:   3177 / 6784 loss=4.838, ppl=28.61, wps=20145.5, ups=0.08, wpb=262144, bsz=512, num_updates=30200, lr=0.00181969, gnorm=0.415, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=390852
2024-01-21 06:14:21 | INFO | train_inner | epoch 005:   3277 / 6784 loss=4.831, ppl=28.47, wps=20352.8, ups=0.08, wpb=262144, bsz=512, num_updates=30300, lr=0.00181668, gnorm=0.474, clip=0, loss_scale=4, train_wall=1288, gb_free=10.5, wall=392140
2024-01-21 06:36:02 | INFO | train_inner | epoch 005:   3377 / 6784 loss=4.833, ppl=28.49, wps=20150.6, ups=0.08, wpb=262144, bsz=512, num_updates=30400, lr=0.00181369, gnorm=0.488, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=393441
2024-01-21 06:57:42 | INFO | train_inner | epoch 005:   3477 / 6784 loss=4.833, ppl=28.5, wps=20156.4, ups=0.08, wpb=262144, bsz=512, num_updates=30500, lr=0.00181071, gnorm=0.479, clip=0, loss_scale=4, train_wall=1300, gb_free=10.5, wall=394742
2024-01-21 07:19:14 | INFO | train_inner | epoch 005:   3577 / 6784 loss=4.828, ppl=28.41, wps=20291.1, ups=0.08, wpb=262144, bsz=512, num_updates=30600, lr=0.00180775, gnorm=0.431, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=396034
2024-01-21 07:40:52 | INFO | train_inner | epoch 005:   3677 / 6784 loss=4.834, ppl=28.52, wps=20195.8, ups=0.08, wpb=262144, bsz=512, num_updates=30700, lr=0.00180481, gnorm=0.538, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=397332
2024-01-21 08:02:30 | INFO | train_inner | epoch 005:   3777 / 6784 loss=4.833, ppl=28.49, wps=20197.8, ups=0.08, wpb=262144, bsz=512, num_updates=30800, lr=0.00180187, gnorm=0.422, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=398630
2024-01-21 08:24:15 | INFO | train_inner | epoch 005:   3877 / 6784 loss=4.831, ppl=28.46, wps=20093, ups=0.08, wpb=262144, bsz=512, num_updates=30900, lr=0.00179896, gnorm=0.46, clip=0, loss_scale=4, train_wall=1304, gb_free=10.5, wall=399934
2024-01-21 08:45:52 | INFO | train_inner | epoch 005:   3977 / 6784 loss=4.829, ppl=28.43, wps=20211.9, ups=0.08, wpb=262144, bsz=512, num_updates=31000, lr=0.00179605, gnorm=0.437, clip=0, loss_scale=4, train_wall=1297, gb_free=10.5, wall=401231
2024-01-21 09:07:26 | INFO | train_inner | epoch 005:   4077 / 6784 loss=4.833, ppl=28.51, wps=20245.6, ups=0.08, wpb=262144, bsz=512, num_updates=31100, lr=0.00179316, gnorm=0.432, clip=0, loss_scale=4, train_wall=1295, gb_free=10.5, wall=402526
2024-01-21 09:29:05 | INFO | train_inner | epoch 005:   4177 / 6784 loss=4.832, ppl=28.48, wps=20195.6, ups=0.08, wpb=262144, bsz=512, num_updates=31200, lr=0.00179029, gnorm=0.426, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=403824
2024-01-21 09:50:43 | INFO | train_inner | epoch 005:   4277 / 6784 loss=4.831, ppl=28.47, wps=20184.6, ups=0.08, wpb=262144, bsz=512, num_updates=31300, lr=0.00178743, gnorm=0.45, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=405123
2024-01-21 10:12:19 | INFO | train_inner | epoch 005:   4377 / 6784 loss=4.833, ppl=28.49, wps=20223.4, ups=0.08, wpb=262144, bsz=512, num_updates=31400, lr=0.00178458, gnorm=0.437, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=406419
2024-01-21 10:33:56 | INFO | train_inner | epoch 005:   4477 / 6784 loss=4.831, ppl=28.46, wps=20216.6, ups=0.08, wpb=262144, bsz=512, num_updates=31500, lr=0.00178174, gnorm=0.456, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=407716
2024-01-21 10:55:35 | INFO | train_inner | epoch 005:   4577 / 6784 loss=4.828, ppl=28.41, wps=20178.9, ups=0.08, wpb=262144, bsz=512, num_updates=31600, lr=0.00177892, gnorm=0.451, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=409015
2024-01-21 11:17:24 | INFO | train_inner | epoch 005:   4677 / 6784 loss=4.826, ppl=28.36, wps=20033.7, ups=0.08, wpb=262144, bsz=512, num_updates=31700, lr=0.00177611, gnorm=0.42, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=410324
2024-01-21 11:39:10 | INFO | train_inner | epoch 005:   4777 / 6784 loss=4.831, ppl=28.47, wps=20070.4, ups=0.08, wpb=262144, bsz=512, num_updates=31800, lr=0.00177332, gnorm=0.447, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=411630
2024-01-21 12:00:49 | INFO | train_inner | epoch 005:   4877 / 6784 loss=4.83, ppl=28.45, wps=20172.7, ups=0.08, wpb=262144, bsz=512, num_updates=31900, lr=0.00177054, gnorm=0.421, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=412929
2024-01-21 12:22:28 | INFO | train_inner | epoch 005:   4977 / 6784 loss=4.829, ppl=28.42, wps=20188.9, ups=0.08, wpb=262144, bsz=512, num_updates=32000, lr=0.00176777, gnorm=0.463, clip=0, loss_scale=4, train_wall=1298, gb_free=10.5, wall=414228
2024-01-21 12:44:16 | INFO | train_inner | epoch 005:   5077 / 6784 loss=4.829, ppl=28.42, wps=20037.1, ups=0.08, wpb=262144, bsz=512, num_updates=32100, lr=0.00176501, gnorm=0.438, clip=0, loss_scale=4, train_wall=1308, gb_free=10.5, wall=415536
2024-01-21 13:05:55 | INFO | train_inner | epoch 005:   5177 / 6784 loss=4.829, ppl=28.43, wps=20176.9, ups=0.08, wpb=262144, bsz=512, num_updates=32200, lr=0.00176227, gnorm=0.446, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=416835
2024-01-21 13:27:40 | INFO | train_inner | epoch 005:   5277 / 6784 loss=4.833, ppl=28.51, wps=20098.2, ups=0.08, wpb=262144, bsz=512, num_updates=32300, lr=0.00175954, gnorm=0.481, clip=0, loss_scale=4, train_wall=1304, gb_free=10.5, wall=418139
2024-01-21 13:49:26 | INFO | train_inner | epoch 005:   5377 / 6784 loss=4.829, ppl=28.41, wps=20063.8, ups=0.08, wpb=262144, bsz=512, num_updates=32400, lr=0.00175682, gnorm=0.474, clip=0, loss_scale=4, train_wall=1306, gb_free=10.5, wall=419446
2024-01-21 14:11:12 | INFO | train_inner | epoch 005:   5477 / 6784 loss=4.826, ppl=28.37, wps=20076.9, ups=0.08, wpb=262144, bsz=512, num_updates=32500, lr=0.00175412, gnorm=0.449, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=420752
2024-01-21 14:32:57 | INFO | train_inner | epoch 005:   5577 / 6784 loss=4.828, ppl=28.41, wps=20081.5, ups=0.08, wpb=262142, bsz=512, num_updates=32600, lr=0.00175142, gnorm=0.435, clip=0, loss_scale=4, train_wall=1305, gb_free=10.5, wall=422057
2024-01-21 14:54:39 | INFO | train_inner | epoch 005:   5677 / 6784 loss=4.825, ppl=28.35, wps=20144.4, ups=0.08, wpb=262144, bsz=512, num_updates=32700, lr=0.00174874, gnorm=0.439, clip=0, loss_scale=4, train_wall=1301, gb_free=10.5, wall=423358
2024-01-21 15:16:05 | INFO | train_inner | epoch 005:   5777 / 6784 loss=4.831, ppl=28.46, wps=20385, ups=0.08, wpb=262144, bsz=512, num_updates=32800, lr=0.00174608, gnorm=0.476, clip=0, loss_scale=4, train_wall=1286, gb_free=10.5, wall=424644
2024-01-21 15:37:37 | INFO | train_inner | epoch 005:   5877 / 6784 loss=4.824, ppl=28.33, wps=20286, ups=0.08, wpb=262144, bsz=512, num_updates=32900, lr=0.00174342, gnorm=0.46, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=425937
2024-01-21 15:46:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2024-01-21 15:59:10 | INFO | train_inner | epoch 005:   5978 / 6784 loss=4.826, ppl=28.37, wps=20278.4, ups=0.08, wpb=262144, bsz=512, num_updates=33000, lr=0.00174078, gnorm=0.45, clip=0, loss_scale=4, train_wall=1293, gb_free=10.5, wall=427229
2024-01-21 16:21:00 | INFO | train_inner | epoch 005:   6078 / 6784 loss=4.824, ppl=28.32, wps=20004.9, ups=0.08, wpb=262144, bsz=512, num_updates=33100, lr=0.00173814, gnorm=0.472, clip=0, loss_scale=4, train_wall=1310, gb_free=10.5, wall=428540
2024-01-21 16:42:52 | INFO | train_inner | epoch 005:   6178 / 6784 loss=4.822, ppl=28.29, wps=19976.7, ups=0.08, wpb=262144, bsz=512, num_updates=33200, lr=0.00173553, gnorm=0.429, clip=0, loss_scale=4, train_wall=1312, gb_free=10.5, wall=429852
2024-01-21 17:04:15 | INFO | train_inner | epoch 005:   6278 / 6784 loss=4.824, ppl=28.32, wps=20441.4, ups=0.08, wpb=262144, bsz=512, num_updates=33300, lr=0.00173292, gnorm=0.456, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=431134
2024-01-21 17:25:45 | INFO | train_inner | epoch 005:   6378 / 6784 loss=4.825, ppl=28.34, wps=20272.9, ups=0.08, wpb=261571, bsz=510.9, num_updates=33400, lr=0.00173032, gnorm=0.447, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=432425
2024-01-21 17:47:07 | INFO | train_inner | epoch 005:   6478 / 6784 loss=4.821, ppl=28.27, wps=20439.2, ups=0.08, wpb=262144, bsz=512, num_updates=33500, lr=0.00172774, gnorm=0.45, clip=0, loss_scale=4, train_wall=1282, gb_free=10.5, wall=433707
2024-01-21 18:08:46 | INFO | train_inner | epoch 005:   6578 / 6784 loss=4.824, ppl=28.32, wps=20181.6, ups=0.08, wpb=262144, bsz=512, num_updates=33600, lr=0.00172516, gnorm=0.447, clip=0, loss_scale=4, train_wall=1299, gb_free=10.5, wall=435006
2024-01-21 18:30:19 | INFO | train_inner | epoch 005:   6678 / 6784 loss=4.817, ppl=28.19, wps=20279.5, ups=0.08, wpb=262144, bsz=512, num_updates=33700, lr=0.0017226, gnorm=0.425, clip=0, loss_scale=4, train_wall=1292, gb_free=10.5, wall=436299
2024-01-21 18:51:50 | INFO | train_inner | epoch 005:   6778 / 6784 loss=4.822, ppl=28.29, wps=20312.4, ups=0.08, wpb=262144, bsz=512, num_updates=33800, lr=0.00172005, gnorm=0.424, clip=0, loss_scale=4, train_wall=1290, gb_free=10.5, wall=437589
2024-01-21 18:53:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 33806 updates
2024-01-21 18:53:07 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint5.pt
2024-01-21 18:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint5.pt
2024-01-21 18:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint5.pt (epoch 5 @ 33806 updates, score None) (writing took 74.10830375395017 seconds)
2024-01-21 18:54:21 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-01-21 18:54:21 | INFO | train | epoch 005 | loss 4.835 | ppl 28.53 | wps 20137.8 | ups 0.08 | wpb 262126 | bsz 512 | num_updates 33806 | lr 0.0017199 | gnorm 0.449 | clip 0 | loss_scale 4 | train_wall 88143 | gb_free 10.5 | wall 437741
2024-01-21 18:54:21 | INFO | fairseq.trainer | loading train data for epoch 6
2024-01-21 18:54:22 | INFO | fairseq.data.data_utils | loaded 52,348,000 examples from: ./data/data-bin/5/train
2024-01-21 18:54:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 6735
2024-01-21 18:54:23 | INFO | fairseq.trainer | begin training epoch 6
2024-01-21 18:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-21 19:14:43 | INFO | train_inner | epoch 006:     94 / 6735 loss=4.826, ppl=28.37, wps=19093.1, ups=0.07, wpb=262144, bsz=512, num_updates=33900, lr=0.00171751, gnorm=0.449, clip=0, loss_scale=4, train_wall=1296, gb_free=10.5, wall=438962
2024-01-21 19:36:26 | INFO | train_inner | epoch 006:    194 / 6735 loss=4.821, ppl=28.27, wps=20113.3, ups=0.08, wpb=262144, bsz=512, num_updates=34000, lr=0.00171499, gnorm=0.458, clip=0, loss_scale=4, train_wall=1303, gb_free=10.5, wall=440266
2024-01-21 19:36:26 | INFO | fairseq_cli.train | Stopping training due to num_updates: 34000 >= max_update: 34000
2024-01-21 19:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 34000 updates
2024-01-21 19:36:26 | INFO | fairseq.trainer | Saving checkpoint to ./checkpoint_valmA100/checkpoint_last.pt
2024-01-21 19:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to ./checkpoint_valmA100/checkpoint_last.pt
2024-01-21 19:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoint_valmA100/checkpoint_last.pt (epoch 6 @ 34000 updates, score None) (writing took 16.51184526999714 seconds)
2024-01-21 19:36:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-01-21 19:36:42 | INFO | train | epoch 006 | loss 4.823 | ppl 28.31 | wps 20010.3 | ups 0.08 | wpb 262144 | bsz 512 | num_updates 34000 | lr 0.00171499 | gnorm 0.451 | clip 0 | loss_scale 4 | train_wall 2522 | gb_free 10.5 | wall 440282
2024-01-21 19:36:42 | INFO | fairseq_cli.train | done training in 440243.8 seconds
Amaitu da
