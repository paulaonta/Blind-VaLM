[2024-04-21 01:53:46,674] torch.distributed.run: [WARNING] 
[2024-04-21 01:53:46,674] torch.distributed.run: [WARNING] *****************************************
[2024-04-21 01:53:46,674] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-21 01:53:46,674] torch.distributed.run: [WARNING] *****************************************
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
wandb: Currently logged in as: paula-ontalvilla (paulaixa). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /ikerlariak/pontalvilla001/VaLM/wandb/run-20240421_015419-y0i9pv9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run checkpoint_valmA100_40600upd_lrx4_more_finetune4
wandb: ⭐️ View project at https://wandb.ai/paulaixa/VaLM-baseline
wandb: 🚀 View run at https://wandb.ai/paulaixa/VaLM-baseline/runs/y0i9pv9o
/ikerlariak/pontalvilla001/VaLM/VaLM_ve_image/lib/python3.9/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/ikerlariak/pontalvilla001/VaLM/VaLM_ve_image/lib/python3.9/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
wandb: 
wandb: Run history:
wandb:              train/bsz ▁███▇
wandb:             train/clip █▁▁▁▁
wandb:          train/gb_free ▁▁▁▁▁
wandb:            train/gnorm █▂▁▁▁
wandb:             train/loss █▅▃▂▁
wandb:       train/loss_scale ▁▁▁▁▁
wandb:               train/lr ▁▃▅▆█
wandb:              train/ppl █▅▃▂▁
wandb:       train/train_wall █▇▅▇▁
wandb:              train/ups ▁▁▁▁▁
wandb:             train/wall ▁▃▅▆█
wandb:              train/wpb ▁███▆
wandb:              train/wps ▁▂▄▂█
wandb:        train_inner/bsz ▁▁
wandb:       train_inner/clip █▁
wandb:    train_inner/gb_free ▁▁
wandb:      train_inner/gnorm █▁
wandb:       train_inner/loss █▁
wandb: train_inner/loss_scale ▁▁
wandb:         train_inner/lr ▁█
wandb:        train_inner/ppl █▁
wandb: train_inner/train_wall █▁
wandb:        train_inner/ups ▁▁
wandb:       train_inner/wall ▁█
wandb:        train_inner/wpb █▁
wandb:        train_inner/wps █▁
wandb: 
wandb: Run summary:
wandb:              train/bsz 505.9
wandb:             train/clip 0.0
wandb:          train/gb_free 10.7
wandb:            train/gnorm 0.278
wandb:             train/loss 3.9
wandb:       train/loss_scale 8.0
wandb:               train/lr 0.0001
wandb:              train/ppl 14.93
wandb:       train/train_wall 961.0
wandb:              train/ups 0.04
wandb:             train/wall 5084.0
wandb:              train/wpb 259004.8
wandb:              train/wps 10608.2
wandb:        train_inner/bsz 505.9
wandb:       train_inner/clip 0.0
wandb:    train_inner/gb_free 10.7
wandb:      train_inner/gnorm 0.282
wandb:       train_inner/loss 3.981
wandb: train_inner/loss_scale 8.0
wandb:         train_inner/lr 0.0001
wandb:        train_inner/ppl 15.79
wandb: train_inner/train_wall 2397.0
wandb:        train_inner/ups 0.04
wandb:       train_inner/wall 5068.0
wandb:        train_inner/wpb 258991.3
wandb:        train_inner/wps 10421.1
wandb: 
wandb: 🚀 View run checkpoint_valmA100_40600upd_lrx4_more_finetune4 at: https://wandb.ai/paulaixa/VaLM-baseline/runs/y0i9pv9o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240421_015419-y0i9pv9o/logs
[2024-04-21 03:19:16,235] torch.distributed.run: [WARNING] 
[2024-04-21 03:19:16,235] torch.distributed.run: [WARNING] *****************************************
[2024-04-21 03:19:16,235] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-21 03:19:16,235] torch.distributed.run: [WARNING] *****************************************
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
/ikerlariak/pontalvilla001/VaLM/fairseq/fairseq/distributed/utils.py:620: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  all_gather_list._buffer = torch.cuda.ByteTensor(buffer_size)
wandb: Currently logged in as: paula-ontalvilla (paulaixa). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.1
wandb: Run data is saved locally in /ikerlariak/pontalvilla001/VaLM/wandb/run-20240421_031946-2fz5z7tr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run checkpoint_gpt_blind_lrx4_40600upd_more_finetune4
wandb: ⭐️ View project at https://wandb.ai/paulaixa/VaLM-baseline
wandb: 🚀 View run at https://wandb.ai/paulaixa/VaLM-baseline/runs/2fz5z7tr
/ikerlariak/pontalvilla001/VaLM/VaLM_ve_image/lib/python3.9/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/ikerlariak/pontalvilla001/VaLM/VaLM_ve_image/lib/python3.9/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
wandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.016 MB of 0.016 MB uploadedwandb: | 0.016 MB of 0.016 MB uploadedwandb: / 0.016 MB of 0.016 MB uploadedwandb: - 0.016 MB of 0.016 MB uploadedwandb: 
wandb: Run history:
wandb:              train/bsz ▁████
wandb:             train/clip █▁▁▁▁
wandb:          train/gb_free ▁▁▁▁▁
wandb:            train/gnorm █▂▁▁▁
wandb:             train/loss █▅▃▂▁
wandb:       train/loss_scale ▁▁▁▁▁
wandb:               train/lr ▁▃▅▆█
wandb:              train/ppl █▅▃▂▁
wandb:       train/train_wall █▁▁▁▁
wandb:              train/ups ▁█▆██
wandb:             train/wall ▁▃▅▆█
wandb:              train/wpb ▁████
wandb:              train/wps ▁█▆██
wandb:        train_inner/bsz ▁▁
wandb:       train_inner/clip █▁
wandb:    train_inner/gb_free ▁▁
wandb:      train_inner/gnorm █▁
wandb:       train_inner/loss █▁
wandb: train_inner/loss_scale ▁▁
wandb:         train_inner/lr ▁█
wandb:        train_inner/ppl █▁
wandb: train_inner/train_wall █▁
wandb:        train_inner/ups ▁█
wandb:       train_inner/wall ▁█
wandb:        train_inner/wpb █▁
wandb:        train_inner/wps ▁█
wandb: 
wandb: Run summary:
wandb:              train/bsz 506.0
wandb:             train/clip 0.0
wandb:          train/gb_free 12.8
wandb:            train/gnorm 0.27
wandb:             train/loss 3.898
wandb:       train/loss_scale 4.0
wandb:               train/lr 0.0001
wandb:              train/ppl 14.91
wandb:       train/train_wall 24.0
wandb:              train/ups 0.6
wandb:             train/wall 359.0
wandb:              train/wpb 259081.3
wandb:              train/wps 156029.7
wandb:        train_inner/bsz 505.9
wandb:       train_inner/clip 0.0
wandb:    train_inner/gb_free 12.8
wandb:      train_inner/gnorm 0.273
wandb:       train_inner/loss 3.978
wandb: train_inner/loss_scale 4.0
wandb:         train_inner/lr 0.0001
wandb:        train_inner/ppl 15.76
wandb: train_inner/train_wall 59.0
wandb:        train_inner/ups 0.68
wandb:       train_inner/wall 316.0
wandb:        train_inner/wpb 258991.3
wandb:        train_inner/wps 176381.0
wandb: 
wandb: 🚀 View run checkpoint_gpt_blind_lrx4_40600upd_more_finetune4 at: https://wandb.ai/paulaixa/VaLM-baseline/runs/2fz5z7tr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240421_031946-2fz5z7tr/logs
